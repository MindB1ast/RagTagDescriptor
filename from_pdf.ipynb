{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecb466c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liali\\database_redact\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d78b3e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('GEMENI_API_KEY')\n",
    "#print(api_key)\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a765563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for m in genai.list_models():\n",
    "    if 'embedContent' in m.supported_generation_methods:\n",
    "        print(m.name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0af37a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитан файл: page_1.txt\n",
      "Прочитан файл: page_10.txt\n",
      "Прочитан файл: page_100.txt\n",
      "Прочитан файл: page_101.txt\n",
      "Прочитан файл: page_102.txt\n",
      "Прочитан файл: page_103.txt\n",
      "Прочитан файл: page_104.txt\n",
      "Прочитан файл: page_105.txt\n",
      "Прочитан файл: page_106.txt\n",
      "Прочитан файл: page_107.txt\n",
      "Прочитан файл: page_108.txt\n",
      "Прочитан файл: page_109.txt\n",
      "Прочитан файл: page_11.txt\n",
      "Прочитан файл: page_110.txt\n",
      "Прочитан файл: page_111.txt\n",
      "Прочитан файл: page_112.txt\n",
      "Прочитан файл: page_113.txt\n",
      "Прочитан файл: page_114.txt\n",
      "Прочитан файл: page_115.txt\n",
      "Прочитан файл: page_116.txt\n",
      "Прочитан файл: page_117.txt\n",
      "Прочитан файл: page_118.txt\n",
      "Прочитан файл: page_119.txt\n",
      "Прочитан файл: page_12.txt\n",
      "Прочитан файл: page_120.txt\n",
      "Прочитан файл: page_121.txt\n",
      "Прочитан файл: page_122.txt\n",
      "Прочитан файл: page_123.txt\n",
      "Прочитан файл: page_124.txt\n",
      "Прочитан файл: page_125.txt\n",
      "Прочитан файл: page_126.txt\n",
      "Прочитан файл: page_127.txt\n",
      "Прочитан файл: page_128.txt\n",
      "Прочитан файл: page_129.txt\n",
      "Прочитан файл: page_13.txt\n",
      "Прочитан файл: page_130.txt\n",
      "Прочитан файл: page_14.txt\n",
      "Прочитан файл: page_15.txt\n",
      "Прочитан файл: page_16.txt\n",
      "Прочитан файл: page_17.txt\n",
      "Прочитан файл: page_18.txt\n",
      "Прочитан файл: page_19.txt\n",
      "Прочитан файл: page_2.txt\n",
      "Прочитан файл: page_20.txt\n",
      "Прочитан файл: page_21.txt\n",
      "Прочитан файл: page_22.txt\n",
      "Прочитан файл: page_23.txt\n",
      "Прочитан файл: page_24.txt\n",
      "Прочитан файл: page_25.txt\n",
      "Прочитан файл: page_26.txt\n",
      "Прочитан файл: page_27.txt\n",
      "Прочитан файл: page_28.txt\n",
      "Прочитан файл: page_29.txt\n",
      "Прочитан файл: page_3.txt\n",
      "Прочитан файл: page_30.txt\n",
      "Прочитан файл: page_31.txt\n",
      "Прочитан файл: page_32.txt\n",
      "Прочитан файл: page_33.txt\n",
      "Прочитан файл: page_34.txt\n",
      "Прочитан файл: page_35.txt\n",
      "Прочитан файл: page_36.txt\n",
      "Прочитан файл: page_37.txt\n",
      "Прочитан файл: page_38.txt\n",
      "Прочитан файл: page_39.txt\n",
      "Прочитан файл: page_4.txt\n",
      "Прочитан файл: page_40.txt\n",
      "Прочитан файл: page_41.txt\n",
      "Прочитан файл: page_42.txt\n",
      "Прочитан файл: page_43.txt\n",
      "Прочитан файл: page_44.txt\n",
      "Прочитан файл: page_45.txt\n",
      "Прочитан файл: page_46.txt\n",
      "Прочитан файл: page_47.txt\n",
      "Прочитан файл: page_48.txt\n",
      "Прочитан файл: page_49.txt\n",
      "Прочитан файл: page_5.txt\n",
      "Прочитан файл: page_50.txt\n",
      "Прочитан файл: page_51.txt\n",
      "Прочитан файл: page_52.txt\n",
      "Прочитан файл: page_53.txt\n",
      "Прочитан файл: page_54.txt\n",
      "Прочитан файл: page_55.txt\n",
      "Прочитан файл: page_56.txt\n",
      "Прочитан файл: page_57.txt\n",
      "Прочитан файл: page_58.txt\n",
      "Прочитан файл: page_59.txt\n",
      "Прочитан файл: page_6.txt\n",
      "Прочитан файл: page_60.txt\n",
      "Прочитан файл: page_61.txt\n",
      "Прочитан файл: page_62.txt\n",
      "Прочитан файл: page_63.txt\n",
      "Прочитан файл: page_64.txt\n",
      "Прочитан файл: page_65.txt\n",
      "Прочитан файл: page_66.txt\n",
      "Прочитан файл: page_67.txt\n",
      "Прочитан файл: page_68.txt\n",
      "Прочитан файл: page_69.txt\n",
      "Прочитан файл: page_7.txt\n",
      "Прочитан файл: page_70.txt\n",
      "Прочитан файл: page_71.txt\n",
      "Прочитан файл: page_72.txt\n",
      "Прочитан файл: page_73.txt\n",
      "Прочитан файл: page_74.txt\n",
      "Прочитан файл: page_75.txt\n",
      "Прочитан файл: page_76.txt\n",
      "Прочитан файл: page_77.txt\n",
      "Прочитан файл: page_78.txt\n",
      "Прочитан файл: page_79.txt\n",
      "Прочитан файл: page_8.txt\n",
      "Прочитан файл: page_80.txt\n",
      "Прочитан файл: page_81.txt\n",
      "Прочитан файл: page_82.txt\n",
      "Прочитан файл: page_83.txt\n",
      "Прочитан файл: page_84.txt\n",
      "Прочитан файл: page_85.txt\n",
      "Прочитан файл: page_86.txt\n",
      "Прочитан файл: page_87.txt\n",
      "Прочитан файл: page_88.txt\n",
      "Прочитан файл: page_89.txt\n",
      "Прочитан файл: page_9.txt\n",
      "Прочитан файл: page_90.txt\n",
      "Прочитан файл: page_91.txt\n",
      "Прочитан файл: page_92.txt\n",
      "Прочитан файл: page_93.txt\n",
      "Прочитан файл: page_94.txt\n",
      "Прочитан файл: page_95.txt\n",
      "Прочитан файл: page_96.txt\n",
      "Прочитан файл: page_97.txt\n",
      "Прочитан файл: page_98.txt\n",
      "Прочитан файл: page_99.txt\n",
      "\n",
      "Содержимое файла page_1.txt:\n",
      "('\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Онлайн-учебник по машинному обучению (machine learning). | Машинное и '\n",
      " 'глубокое обучение\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '[IMAGE]\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Перейти к основному содержимому\\n'\n",
      " '[IMAGE]\\n'\n",
      " 'Машинное обучение\\n'\n",
      " 'Глубокое обучение\\n'\n",
      " 'Обозначения\\n'\n",
      " 'Лицензия\\n'\n",
      " 'Машинное обучение\\n'\n",
      " 'Введение\\n'\n",
      " 'Основы машинного обучения\\n'\n",
      " 'Подготовка данных\\n'\n",
      " 'Классификаторы в общем виде\\n'\n",
      " 'Метрические методы прогнозирования\\n'\n",
      " 'Линейная регрессия и её обобщения\\n'\n",
      " 'Оценка качества регрессии\\n'\n",
      " 'Линейная классификация\\n'\n",
      " 'Многоклассовая классификация набором бинарных классификаторов\\n'\n",
      " 'Численная оптимизация\\n'\n",
      " 'Оценка качества классификации\\n'\n",
      " 'Решающие деревья\\n'\n",
      " 'Переобучение и недообучение\\n'\n",
      " 'Ансамбли моделей\\n'\n",
      " 'Бустинг\\n'\n",
      " 'Интерпретация простых моделей\\n'\n",
      " 'Интерпретация сложных моделей\\n'\n",
      " 'Заключение\\n'\n",
      " 'Машинное обучение\\n'\n",
      " 'Машинное обучение\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Виктор Владимирович Китов\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Навигация по темам учебника доступна слева вверху\\n'\n",
      " '(три палочки на мобильных устройствах).\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Почта для обратной связи:\\n'\n",
      " '\\n'\n",
      " 'deepmachinelearning@yandex.ru\\n'\n",
      " '.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Условные обозначения\\n'\n",
      " ' учебника.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Лицензия\\n'\n",
      " ' на использование материалов.\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'Вы можете помочь:\\n'\n",
      " 'Напишите, если учебник помог вам разобраться в какой-то теме, живой отклик '\n",
      " 'всегда ценен!\\n'\n",
      " 'Расскажите об учебнике своим друзьям и коллегам по работе.\\n'\n",
      " 'Напишите обратную связь по материалам учебника.\\n'\n",
      " 'Напишите, если заметите опечатки и ошибки (даже незначительные)\\n'\n",
      " 'в тексте или работе сайта.\\n'\n",
      " 'Следующая страница\\n'\n",
      " 'Введение\\n'\n",
      " '© 2023-25 \\n'\n",
      " 'Виктор Китов.\\n'\n",
      " ' \\n'\n",
      " 'Новости проекта.\\n'\n",
      " '\\n')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "# Папка с TXT-файлами\n",
    "folder_path = r'pages_texts'\n",
    "\n",
    "# Получаем список всех TXT-файлов в папке\n",
    "txt_files = [f for f in os.listdir(folder_path) if f.endswith(\".txt\")]\n",
    "\n",
    "all_texts = {}\n",
    "\n",
    "for file_name in txt_files:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    all_texts[file_name] = text  # Сохраняем текст под именем файла\n",
    "    print(f\"Прочитан файл: {file_name}\")\n",
    "\n",
    "# Пример вывода текста первого файла\n",
    "first_file = txt_files[0]\n",
    "print(f\"\\nСодержимое файла {first_file}:\")\n",
    "pprint(all_texts[first_file])\n",
    "\n",
    "\n",
    "text = '\\n'.join(all_texts[f] for f in txt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f152d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "MATH_PATTERN = re.compile(r'[0-9A-Za-z\\u0370-\\u03FF\\u2200-\\u22FF=+\\-*/^(){}[\\]<>]')\n",
    "\n",
    "def clean_pdf_text_safe(text: str) -> str:\n",
    "    lines = [line.strip() for line in text.splitlines() if line.strip()]\n",
    "    \n",
    "    # Убираем очевидный мусор\n",
    "    lines = [line for line in lines \n",
    "             if not re.search(r'©|~|_|;:;|deepmachinelearning\\.ru', line)\n",
    "             and not re.match(r'^Стр\\.\\s*\\d+\\s*из\\s*\\d+.*\\d{2}\\.\\d{2}\\.\\d{4}', line)]\n",
    "    \n",
    "    # Убираем короткие строки без \"математики\"\n",
    "    lines = [line for line in lines if len(line) >= 5 or MATH_PATTERN.search(line)]\n",
    "    \n",
    "    # Убираем повторяющиеся строки (например меню, заголовки сайта)\n",
    "    counter = Counter(lines)\n",
    "    cleaned = [line for line in lines if counter[line] == 1 or MATH_PATTERN.search(line)]\n",
    "    \n",
    "    return \"\\n\".join(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d3e373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(477181, 728440)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text = clean_pdf_text_safe(text)\n",
    "len(cleaned_text), len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4b589f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Онлайн-учебник по машинному обучению (machine learning). | Машинное и глубокое обучение\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[IMAGE]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Перейти к основному содержимому\n",
      "[IMAGE]\n",
      "Машинное обучение\n",
      "Глубокое обучение\n",
      "Обозначения\n",
      "Лицензия\n",
      "Машинное обучение\n",
      "Введение\n",
      "Основы машинного обучения\n",
      "Подготовка данных\n",
      "Классификаторы в общем виде\n",
      "Метрические методы прогнозирования\n",
      "Линейная регрессия и её обобщения\n",
      "Оценка качества регрессии\n",
      "Линейная классификация\n",
      "Многоклассовая классификация набором бинарных классификаторов\n",
      "Численная оптимизация\n",
      "Оценка качества классификации\n",
      "Решающие деревья\n",
      "Переобучение и недообучение\n",
      "Ансамбли моделей\n",
      "Бустинг\n",
      "Интерпретация простых моделей\n",
      "Интерпретация сложных моделей\n",
      "Заключение\n",
      "Машинное обучение\n",
      "Машинное обучение\n",
      "\n",
      "\n",
      "Виктор Владимирович Китов\n",
      "\n",
      "\n",
      "Навигация по темам учебника доступна слева вверху\n",
      "(три палочки на мобильных устройствах).\n",
      "\n",
      "\n",
      "Почта для обратной связи:\n",
      "\n",
      "deepmachinelearning@yandex.ru\n",
      ".\n",
      "\n",
      "\n",
      "Условные обозначения\n",
      " учебника.\n",
      "\n",
      "\n",
      "Лицензия\n",
      " на использование материалов.\n",
      "\n",
      "\n",
      "Вы можете помочь:\n",
      "Напишите, если учебник помог вам разобраться в какой-то теме, живой отклик всегда ценен!\n",
      "Расскажите об учебнике своим друзьям и коллегам по работе.\n",
      "Напишите обратную связь по материалам учебника.\n",
      "Напишите, если заметите опечатки и ошибки (даже незначительные)\n",
      "в тексте или работе сайта.\n",
      "Следующая страница\n",
      "Введение\n",
      "© 2023-25 \n",
      "Виктор Китов.\n",
      " \n",
      "Новости проекта.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Оценка качества прогнозов | Машинное и глубокое обучение\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[IMAGE]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Перейти к основному содержимому\n",
      "[IMAGE]\n",
      "Машин\n"
     ]
    }
   ],
   "source": [
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3de0bdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Онлайн-учебник по машинному обучению (machine learning). | Машинное и глубокое обучение\n",
      "[IMAGE]\n",
      "[IMAGE]\n",
      "Виктор Владимирович Китов\n",
      "Навигация по темам учебника доступна слева вверху\n",
      "(три палочки на мобильных устройствах).\n",
      "Почта для обратной связи:\n",
      "deepmachinelearning@yandex.ru\n",
      "Условные обозначения\n",
      "на использование материалов.\n",
      "Вы можете помочь:\n",
      "Напишите, если учебник помог вам разобраться в какой-то теме, живой отклик всегда ценен!\n",
      "Расскажите об учебнике своим друзьям и коллегам по работе.\n",
      "Напишите обратную связь по материалам учебника.\n",
      "Напишите, если заметите опечатки и ошибки (даже незначительные)\n",
      "в тексте или работе сайта.\n",
      "Оценка качества прогнозов | Машинное и глубокое обучение\n",
      "[IMAGE]\n",
      "[IMAGE]\n",
      "Мы можем использовать для прогнозирования разные модели или одну и ту же модель, но при разных значениях гиперпараметров. Также для обработки варьируют весь\n",
      "конвейер обработки данных\n",
      "(пайплайн, pipeline), включающий как предобработку данных (заполнение пропущенных значений, отсев аномальных наблюдений, отбор и кодирование признаков), так и итоговое построение прогнозов. Важно уметь оценивать качество модели, чтобы подобрать самую точную модель и её наилучшую конфигурацию, а также знать, на какое качество работы мы можем рассчитывать на новых данных.\n",
      "Как можно было бы оценить качество прогнозов модели? Как мы выяснили раньше, средние потери на обучающих объектах представляют собой необъективную и слишком оптимистическую оценку потерь модели на новых объектах, занижая потери, поскольку её параметры подбираются так, чтобы\n",
      "именно на обучающих объектах\n",
      "модель работала хорошо. Для более объективной оценки модели есть два подхода - использование отложенной\n",
      "кросс-валидация\n",
      "В этом подходе предлагается разбить размеченную выборку случайно на две подвыборки:\n",
      "обучающую\n",
      "$\\mathbf{w}$\n",
      "w\n",
      "валидационную\n",
      "[IMAGE]\n",
      "Таким образом, множество индексов всех объектов\n",
      "$\\{1,2,...N\\}$\n",
      "{\n",
      "1\n",
      "2\n",
      "N\n",
      "}\n",
      "случайным образом разбивается на два подмножества:\n",
      "I\n",
      "t\n",
      "r\n",
      "ain\n",
      "- индексы объектов обучающей выборки;\n",
      "I\n",
      "v\n",
      "a\n",
      "l\n",
      "- индексы объектов валидационной выборки.\n",
      "Настройка параметров производится по обучающим объектам (\n",
      "$|I|$\n",
      "∣\n",
      "I\n",
      "∣\n",
      "- число элементов в множестве\n",
      "$I$\n",
      "I\n",
      "):\n",
      "L\n",
      "(\n",
      "w\n",
      "∣\n",
      "X\n",
      "t\n",
      "r\n",
      "ain\n",
      "Y\n",
      "t\n",
      "r\n",
      "ain\n",
      ")\n",
      "=\n",
      "∣\n",
      "I\n",
      "t\n",
      "r\n",
      "ain\n",
      "∣\n",
      "1\n",
      "i\n",
      "∈\n",
      "I\n",
      "t\n",
      "r\n",
      "ain\n",
      "∑\n",
      "L\n",
      "(\n",
      "f\n",
      "w\n",
      "(\n",
      "x\n",
      "i\n",
      ")\n",
      "y\n",
      "i\n",
      ")\n",
      "w\n",
      "min\n",
      "При желании можно также производить\n",
      "настройку с регуляризацией\n",
      "Оценка качества прогнозов производится по объектам валидационной выборки:\n",
      "L\n",
      "(\n",
      "w\n",
      "∣\n",
      "X\n",
      "v\n",
      "a\n",
      "l\n",
      "Y\n",
      "v\n",
      "a\n",
      "l\n",
      ")\n",
      "=\n",
      "∣\n",
      "I\n",
      "v\n",
      "a\n",
      "l\n",
      "∣\n",
      "1\n",
      "i\n",
      "∈\n",
      "I\n",
      "v\n",
      "a\n",
      "l\n",
      "∑\n",
      "L\n",
      "(\n",
      "f\n",
      "w\n",
      "(\n",
      "x\n",
      "i\n",
      ")\n",
      "y\n",
      "i\n",
      ")\n",
      "В этом случае регуляризация не используется, т.\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_text[:2500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55b3eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=3000,\n",
    "    chunk_overlap=250,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "440be0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "texts = text_splitter.create_documents([cleaned_text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b79f250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [chunk.page_content for chunk in texts] #Функция create_chroma_db(...) ожидает: documents: List[str]  # список строк\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f81bd2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    def __init__(self, model: str = \"models/text-embedding-004\", task_type: str = \"QUESTION_ANSWERING\"):\n",
    "        self.model = model\n",
    "        self.task_type = task_type\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        embeddings = []\n",
    "        for doc in input:\n",
    "            response = genai.embed_content(\n",
    "                model=self.model,\n",
    "                content=doc,\n",
    "                task_type=self.task_type,\n",
    "            )\n",
    "            embeddings.append(response[\"embedding\"])\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ed0da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_chroma_db(documents, name):\n",
    "    chroma_client = chromadb.PersistentClient(path=\"../database/\")\n",
    "\n",
    "    db = chroma_client.get_or_create_collection(\n",
    "        name=name, embedding_function=GeminiEmbeddingFunction())\n",
    "\n",
    "    initiali_size = db.count()\n",
    "    for i, d in tqdm(enumerate(documents), total=len(documents), desc=\"Creating Chroma DB\"):\n",
    "        db.add(\n",
    "            documents=d,\n",
    "            ids=str(i + initiali_size)\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "    return db\n",
    "\n",
    "\n",
    "def get_chroma_db(name):\n",
    "    chroma_client = chromadb.PersistentClient(path=\"../database/\")\n",
    "    return chroma_client.get_collection(name=name, embedding_function=GeminiEmbeddingFunction())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "960d6238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Chroma DB: 100%|██████████| 174/174 [02:50<00:00,  1.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "db = create_chroma_db(documents, \"second_try\")\n",
    "\n",
    "db.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07fd3f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client type: <class 'chromadb.api.rust.RustBindingsAPI'>\n",
      "Database is stored in memory (in-memory) and is not persisted to disk.\n"
     ]
    }
   ],
   "source": [
    "# Get the client from the collection\n",
    "client = db._client\n",
    "\n",
    "# Check client type and settings\n",
    "print(f\"Client type: {type(client)}\")\n",
    "if hasattr(client, \"_settings\") and hasattr(client._settings, \"persist_directory\"):\n",
    "    print(f\"Database is stored on disk at: {client._settings.persist_directory}\")\n",
    "else:\n",
    "    print(\"Database is stored in memory (in-memory) and is not persisted to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33fdfebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ids                                          documents  uris    included  \\\n",
      "0   0  Основы нейросетевых архитектурВыходы нейросети...  None   metadatas   \n",
      "1   1  В качестве функции потерь, по которой мы будем...  None   documents   \n",
      "2   2  • Среднее по модулям отклонений называется mea...  None  embeddings   \n",
      "\n",
      "   data metadatas  \n",
      "0  None      None  \n",
      "1  None      None  \n",
      "2  None      None  \n"
     ]
    }
   ],
   "source": [
    "# Вариант 1: Исключить embeddings\n",
    "data = db.peek(3)\n",
    "data_without_embeddings = {k: v for k, v in data.items() if k != 'embeddings'}\n",
    "df = pd.DataFrame(data_without_embeddings)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed6e298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant_docs(query, db, n_results=2):\n",
    "    passages = db.query(query_texts=[query], n_results=n_results)['documents'][0]\n",
    "    return passages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "501e1cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "обучением с учителем\n",
       "(в котором все объекты обучающей выборки размечены) и\n",
       "обучением без учителя\n",
       "(в которой ни один объект не размечен). В частичном обучении\n",
       "часть объектов имеют разметку, а часть - нет\n",
       ", поэтому обучающая выборка имеет следующий вид:\n",
       "(\n",
       "x\n",
       "1\n",
       "y\n",
       "1\n",
       ")\n",
       "(\n",
       "x\n",
       "2\n",
       "y\n",
       "2\n",
       ")\n",
       "(\n",
       "x\n",
       "N\n",
       "y\n",
       "N\n",
       ")\n",
       "x\n",
       "N\n",
       "+\n",
       "1\n",
       "x\n",
       "N\n",
       "+\n",
       "2\n",
       "x\n",
       "N\n",
       "+\n",
       "M\n",
       "Такая постановка задачи весьма типична, поскольку часто не составляет труда собрать большие наборы неразмеченных данных (изображений, текстов, видео в интернете), однако их корректная разметка требует человеческого труда, поэтому разметить мы можем далеко не все собранные объекты.\n",
       "Упрощенный пример частичного обучения приведён ниже на графике слева для задачи бинарной классификации двумерных объектов, обозначенных квадратами. Изначально в выборке размечено всего два квадрата (в синий и красный класс). Лучшее, что мы можем сделать,\n",
       "используя только размеченные данные\n",
       "- это разделить пространство признаков прямой, равноудалённой от этих двух точек. Однако если мы будем использовать знание о распределении неразмеченных объектов (две концентрических окружности) и предположение о том, что близкие объекты принадлежат одинаковому классу, то мы сможем существенно расширить множество размеченных объектов (график справа), из которого уже естественнее провести границу между классами в форме окружности.\n",
       "[IMAGE]\n",
       "Методы частичного обучения используют предположение о том, что похожие (метрически близкие) объекты должны принадлежать одинаковому классу. Это всего лишь предположение, которое\n",
       "может быть и не выполнено\n",
       ". Тут многое зависит от признаков, которыми мы описываем объекты, а также от функции расстояния, по которой считаем близость. Для верификации предположения необходима проверка на отдельной валидационной выборке!\n",
       "При правильно подобранном признаковом описании объектов и функции вычисления расстояния методы частичного обучения дают эффект, когда число размеченных объектов мало, а неразмеченных - велико. Если же размеченных объектов и так много, то потенциальный эффект от их использования будет минимальным и лучше использовать классическое обучение с учителем.\n",
       "Трансдуктивное обучение\n",
       "трансдуктивного обучения\n",
       "(transductive learning), в которой заранее известны признаковые описания объектов тестовой выборки (на которой мы хотим применить нашу модель), представляет собой частный случай частичного обучения и к ней могут быть применены такие же подходы.\n",
       "Дополнительно о методах обучения без учителя можно прочитать в\n",
       "[1]\n",
       "Geeksforgeeks: semi-supervised learning in ML.\n",
       "[IMAGE]\n",
       "[IMAGE]\n",
       "Как по матрице ошибок посчитать долю ошибочных классификаций?\n",
       "Почему в методе перестановочной важности признаков нужно выдавать усреднённую оценку по разным запускам, а по однократному запуску?\n",
       "Метод перестановочной важности признаков завышает или занижает важность сильно скоррелированных признаков? Почему?E\n",
       "{\n",
       "δ\n",
       "i\n",
       "T\n",
       "w\n",
       "(\n",
       "y\n",
       "i\n",
       "−\n",
       "x\n",
       "i\n",
       "T\n",
       "w\n",
       ")\n",
       "}\n",
       "+\n",
       "E\n",
       "{\n",
       "w\n",
       "T\n",
       "δ\n",
       "i\n",
       "δ\n",
       "i\n",
       "T\n",
       "w\n",
       "}\n",
       "=\n",
       "N\n",
       "1\n",
       "i\n",
       "=\n",
       "1\n",
       "∑\n",
       "N\n",
       "(\n",
       "y\n",
       "i\n",
       "−\n",
       "x\n",
       "i\n",
       "T\n",
       "w\n",
       ")\n",
       "2\n",
       "+\n",
       "λ\n",
       "∥\n",
       "w\n",
       "∥\n",
       "2\n",
       "2\n",
       "где в предпоследней формуле мы использовали линейность мат. ожидания, равенство нулю мат. ожидания шума и его известную ковариационную матрицу.\n",
       "Таким образом, зашумление признаков во время обучения эквивалентно в среднем добавлению L2-регуляризации. О связи зашумления признаков с регуляризацией в более общем случае нелинейных нейросетевых моделей можно прочитать в\n",
       "[1]\n",
       "Документация sklearn: linear models.\n",
       "Bishop C. M. Training with noise is equivalent to Tikhonov regularization //Neural computation. – 1995. – Т. 7. – №. 1. – С. 108-116.\n",
       "Пример запуска в Python\n",
       "Аналитическое решение для гребневой регрессии | Машинное и глубокое обучение\n",
       "[IMAGE]\n",
       "[IMAGE]\n",
       "Orthogonal matching pursuit\n",
       "Локально-линейная регрессия\n",
       "В гребневой регрессии вектор весов\n",
       "$\\mathbf{w}$\n",
       "w\n",
       "находится из условия:\n",
       "L\n",
       "(\n",
       "w\n",
       ")\n",
       "=\n",
       "n\n",
       "=\n",
       "1\n",
       "∑\n",
       "N\n",
       "(\n",
       "x\n",
       "n\n",
       "T\n",
       "w\n",
       "−\n",
       "y\n",
       "n\n",
       ")\n",
       "2\n",
       "+\n",
       "λ\n",
       "w\n",
       "T\n",
       "w\n",
       "w\n",
       "min\n",
       "Поскольку этот критерий выпуклый (докажите!), минимум является глобальным минимумом и находится из условия покомпонентного равенства градиента функции потерь нулю, т.е.\n",
       "$\\nabla L(\\mathbf{w})=0$\n",
       "∇\n",
       "L\n",
       "(\n",
       "w\n",
       ")\n",
       "=\n",
       "0\n",
       "2\n",
       "n\n",
       "=\n",
       "1\n",
       "∑\n",
       "N\n",
       "x\n",
       "n\n",
       "(\n",
       "x\n",
       "n\n",
       "T\n",
       "w\n",
       "−\n",
       "y\n",
       "n\n",
       ")\n",
       "+\n",
       "2\n",
       "λ\n",
       "w\n",
       "=\n",
       "0\n",
       "Отсюда, используя обозначение\n",
       "$I\\in\\mathbb{R}^{D\\times D}$\n",
       "I\n",
       "∈\n",
       "R\n",
       "D\n",
       "D\n",
       "для единичной матрицы, получаем:\n",
       "(\n",
       "n\n",
       "=\n",
       "1\n",
       "∑\n",
       "N\n",
       "x\n",
       "n\n",
       "T\n",
       "x\n",
       "n\n",
       ")\n",
       "w\n",
       "^\n",
       "+\n",
       "λ\n",
       "I\n",
       "w\n",
       "^\n",
       "=\n",
       "n\n",
       "=\n",
       "1\n",
       "∑\n",
       "N\n",
       "x\n",
       "n\n",
       "y\n",
       "n\n",
       "(\n",
       "n\n",
       "=\n",
       "1\n",
       "∑\n",
       "N\n",
       "x\n",
       "n\n",
       "T\n",
       "x\n",
       "n\n",
       "+\n",
       "λ\n",
       "I\n",
       ")\n",
       "w\n",
       "^\n",
       "=\n",
       "n\n",
       "=\n",
       "1\n",
       "∑\n",
       "N\n",
       "x\n",
       "n\n",
       "y\n",
       "n\n",
       "Используя обозначения для матрицы объекты-признаки\n",
       "$X\\in\\mathbb{R}^{N\\times D}$\n",
       "X\n",
       "∈\n",
       "R\n",
       "N\n",
       "D\n",
       "$Y\\in \\mathbb{R}^N$\n",
       "Y\n",
       "∈\n",
       "R\n",
       "N\n",
       ", это можно переписать в виде:\n",
       "$\\left(X^{T}X+\\lambda I\\right)\\widehat{\\mathbf{w}}=X^{T}Y,$\n",
       "(\n",
       "X\n",
       "T\n",
       "X\n",
       "+\n",
       "λ\n",
       "I\n",
       ")\n",
       "w\n",
       "=\n",
       "X\n",
       "T\n",
       "Y\n",
       "откуда получим итоговый вид аналитического решения:\n",
       "$\\widehat{\\mathbf{w}}=(X^{T}X+\\lambda I)^{-1}X^{T}Y$\n",
       "w\n",
       "=\n",
       "(\n",
       "X\n",
       "T\n",
       "X\n",
       "+\n",
       "λ\n",
       "I\n",
       ")\n",
       "−\n",
       "1\n",
       "X\n",
       "T\n",
       "Y\n",
       "Существование решения\n",
       "Обратим внимание, что матрица\n",
       "$X^{T}X+\\lambda I$\n",
       "X\n",
       "T\n",
       "X\n",
       "+\n",
       "λ\n",
       "I\n",
       "положительно определена (докажите!), поэтому всегда невырождена для любых\n",
       "$\\lambda>0$\n",
       "λ\n",
       ">\n",
       "0\n",
       ". Поэтому решение всегда существует - в отличие от линейной регрессии без регуляризации. Интуитивно решение существует, поскольку даже в случае линейной зависимости признаков регуляризация привносит в него однозначность - среди всех решений необходимо найти то, которое обладает максимальной простотой (минимизирует\n",
       "∥\n",
       "w\n",
       "∥\n",
       "2\n",
       "2\n",
       ").\n",
       "Настройка параметров модели | Машинное и глубокое обучение\n",
       "[IMAGE]\n",
       "[IMAGE]\n",
       "Можно вручную задать функцию соответствия\n",
       "$\\hat{y}=f(\\mathbf{x})$\n",
       "y\n",
       "^\n",
       "=\n",
       "f\n",
       "(\n",
       "x\n",
       ")\n",
       "(которую называют\n",
       "прогностической\n",
       "прогнозной\n",
       "функцией), которая бы выдавала прогнозы отклика\n",
       "$\\hat{y}$\n",
       "y\n",
       "^\n",
       "по известным признакам, однако зачастую это сложно сделать из-за многообразия объектов и сложных зависимостей между признаками и откликом. Поэтому в машинном обучении с учителем соответствие между признаками и откликом ищется в некотором классе функций\n",
       "f\n",
       "w\n",
       "(\n",
       "x\n",
       ")\n",
       ", параметризованном\n",
       "вектором параметров\n",
       "$\\mathbf{w}$\n",
       "w\n",
       ", которые подбираются по обучающей выборке, состоящей из\n",
       "$N$\n",
       "N\n",
       "объектов:\n",
       "(\n",
       "x\n",
       "1\n",
       "y\n",
       "1\n",
       ")\n",
       "(\n",
       "x\n",
       "2\n",
       "y\n",
       "2\n",
       ")\n",
       "(\n",
       "x\n",
       "N\n",
       "y\n",
       "N\n",
       ")"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question= \"Структура книги Виктор Китова Машинное обучение\"\n",
    "passages= relevant_docs(question, db, 2)\n",
    "\n",
    "Markdown(''.join(passages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3868e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(query, relevant_passage):\n",
    "    escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\")\n",
    "\n",
    "    # === Variant 1: Minimal ===\n",
    "    # Question only, no context\n",
    "    # prompt = f\"\"\"Question: {query}.\\n\n",
    "    # Your answer:\n",
    "    # \"\"\"\n",
    "\n",
    "    # === Variant 2: Standard with context and OUT OF CONTEXT option ===\n",
    "    prompt = f\"\"\"\n",
    "    You are a data science assistant. You should answer the question. You also gonna be provided with some context witch could be usiful.\n",
    "\n",
    "    Question: {query}\n",
    "\n",
    "    Context:\\n{escaped}\n",
    "\n",
    "    Your answer:\n",
    "    \"\"\"\n",
    "\n",
    "    # === Variant 3: Clarify if out of context, but still answer ===\n",
    "    # prompt = f\"\"\"Question: {query}.\\n\n",
    "    # Additional information:\\n {escaped}\\n\n",
    "    # If you find that the question has no relation to the additional information, you can ignore it and respond with 'OUT OF CONTEXT' if the question is unrelated in the first place, and then still answer the question, even if it's out of context, by clarifying to the user that the answer has no relation to the context.\\n\n",
    "    # Your answer:\n",
    "    # \"\"\"\n",
    "\n",
    "    # === Variant 4: Environmental management system context ===\n",
    "    # prompt = f\"\"\"The following questions are related to the environmental management system. Here is the question: {query}.\\nTry to answer the question using the following additional information, which may help you formulate your answer.\\nAdditional information:\\n {escaped}\n",
    "    # Your answer:\n",
    "    # \"\"\"\n",
    "\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f46ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_passage_to_str(passages:list):\n",
    "    return ''.join([string+\"\\n\" for string in passages])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db9f8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " '    You are a data science assistant. You should answer the question. You '\n",
      " 'also gonna be provided with some context witch could be usiful.\\n'\n",
      " '\\n'\n",
      " '    Question: Вероятность отрицательного класса в бинарной класификации\\n'\n",
      " '\\n'\n",
      " '    Context:\\n'\n",
      " 'Бинарная классификация Для бинарной классификации выходной слой содержит '\n",
      " 'один выход с сигмоидной функцией активации, которая принимает значения на '\n",
      " 'интервале , а её выход интерпретируется как вероятность положительного '\n",
      " 'класса: Вероятность отрицательного класса считается как Настройка '\n",
      " 'архитектуры производится методом максимального правдоподобия '\n",
      " '(максимизируются модельные вероятности пронаблюдать фактические отклики в '\n",
      " 'обучающей выборке): где - число объектов выборки, а вероятность всех '\n",
      " 'откликов факторизуется (представляется в виде произведения вероятностей) при '\n",
      " 'предположении, что наблюдения отдельных объектов независимы (iid '\n",
      " 'assumption).\\n'\n",
      " 'Максимизация (1) численно неудобна, поскольку приходится перемножать много '\n",
      " 'малых чисел. Из-за ограничений в точности вычисления быстро сходятся к '\n",
      " 'машинному нулю.\\n'\n",
      " 'Какая из представленных функций наименее устойчива к\\n'\n",
      " 'нетипичным объектам-выбросам\\n'\n",
      " 'Объект-выброс лежит далеко от основной массы объектов и, соответственно, '\n",
      " 'будет, скорее всего, лежать далеко от разделяющей гиперплоскости и иметь '\n",
      " 'высокий отступ по абсолютной величине. А если он неверно классифицируется, '\n",
      " 'то отступ будет большим по модулю и отрицательным. Сильнее всего это будет '\n",
      " 'штрафоваться\\n'\n",
      " 'экспоненциальной функцией потерь\\n'\n",
      " '. Поэтому эта функция потерь не рекомендуется на практике, если в выборке '\n",
      " 'могут быть нетипичные объекты-выбросы.\\n'\n",
      " 'Как и\\n'\n",
      " 'в случае линейной регрессии\\n'\n",
      " ', при настройке линейных классификаторов рекомендуется использовать '\n",
      " 'регуляризацию:\\n'\n",
      " 'N\\n'\n",
      " '1\\n'\n",
      " 'n\\n'\n",
      " '=\\n'\n",
      " '1\\n'\n",
      " '∑\\n'\n",
      " 'N\\n'\n",
      " 'L\\n'\n",
      " '(\\n'\n",
      " 'M\\n'\n",
      " '(\\n'\n",
      " 'x\\n'\n",
      " 'n\\n'\n",
      " 'y\\n'\n",
      " 'n\\n'\n",
      " '))\\n'\n",
      " '+\\n'\n",
      " 'λ\\n'\n",
      " 'R\\n'\n",
      " '(\\n'\n",
      " 'w\\n'\n",
      " ')\\n'\n",
      " 'w\\n'\n",
      " '0\\n'\n",
      " 'w\\n'\n",
      " 'min\\n'\n",
      " '$\\\\lambda>0$\\n'\n",
      " 'λ\\n'\n",
      " '>\\n'\n",
      " '0\\n'\n",
      " 'контролирует сложность (гибкость) модели. L1- и ElasticNet-регуляризации '\n",
      " 'способны отбирать признаки, зануляя часть коэффициентов при признаках, а '\n",
      " 'L2-регуляризация - нет. Однако L2-регуляризация равномернее распределяет '\n",
      " 'влияние на отклик похожих признаков.\\n'\n",
      " 'Прогнозы линейного классификатора без регуляризации не зависят от '\n",
      " 'масштабирования признаков (при последующей перенастройке модели). Но если '\n",
      " 'использовать регуляризацию, то больший эффект начинают оказывать признаки с '\n",
      " 'большим разбросом значений.\\n'\n",
      " 'Потому что признакам с малым разбросом будут соответствовать более высокие '\n",
      " 'по модулю значения весов, которые будут сильнее подвергаться регуляризации и '\n",
      " 'прижиматься к нулю. Поэтому соответствующие признаки будут влиять на прогноз '\n",
      " 'слабее.\\n'\n",
      " 'В связи с этим рекомендуется предварительное приведение всех вещественных '\n",
      " 'признаков к одному масштабу одним из\\n'\n",
      " 'методов нормализации признаков\\n'\n",
      " 'Далее мы рассмотрим частные случаи бинарного классификатора -\\n'\n",
      " 'метод опорных векторов\\n'\n",
      " 'логистическую регрессию\\n'\n",
      " ', после чего обобщим логистическую регрессию\\n'\n",
      " 'на многоклассовый случай\\n'\n",
      " '. В отдельном разделе учебника будут рассмотрены методы\\n'\n",
      " 'численной настройки\\n'\n",
      " 'параметров моделей.\\n'\n",
      " 'Дополнительно погрузиться в тему вы можете, прочитав соответствующие главы '\n",
      " 'учебника ШАД\\n'\n",
      " '[1]\\n'\n",
      " 'и учебника А.Г. Дьяконова\\n'\n",
      " '[2]\\n'\n",
      " 'Бинарная логистическая регрессия | Машинное и глубокое обучение\\n'\n",
      " '[IMAGE]\\n'\n",
      " '[IMAGE]\\n'\n",
      " 'Логистическая регрессия\\n'\n",
      " '(logistic regression) - это частный случай\\n'\n",
      " 'линейной классификации\\n'\n",
      " ', когда для оценки весов используется\\n'\n",
      " 'логистическая функция потерь\\n'\n",
      " 'Достоинством метода является то, что он может выдавать не только метки '\n",
      " 'классов, но и\\n'\n",
      " 'их вероятности\\n'\n",
      " 'Для удобства обозначений включим дополнительный признак, равный '\n",
      " 'тождественной единице, в число признаков:\\n'\n",
      " '$\\\\begin{align*}\\n'\n",
      " '\\\\mathbf{x}&=[1,x^1,x^2,...x^D] \\\\\\\\\\n'\n",
      " '\\\\end{align*}$\\n'\n",
      " 'x\\n'\n",
      " 'w\\n'\n",
      " '=\\n'\n",
      " '[\\n'\n",
      " '1\\n'\n",
      " 'x\\n'\n",
      " '1\\n'\n",
      " 'x\\n'\n",
      " '2\\n'\n",
      " 'x\\n'\n",
      " 'D\\n'\n",
      " ']\\n'\n",
      " '=\\n'\n",
      " '[\\n'\n",
      " 'w\\n'\n",
      " '0\\n'\n",
      " 'w\\n'\n",
      " '1\\n'\n",
      " 'w\\n'\n",
      " '2\\n'\n",
      " 'w\\n'\n",
      " 'D\\n'\n",
      " ']\\n'\n",
      " 'Тогда линейный бинарный классификатор можно переписать в более компактном '\n",
      " 'виде:\\n'\n",
      " '$\\\\hat{y}=\\\\text{sign}(\\\\mathbf{w}^T \\\\mathbf{x})$\\n'\n",
      " 'y\\n'\n",
      " '^\\n'\n",
      " '=\\n'\n",
      " 'sign\\n'\n",
      " '(\\n'\n",
      " 'w\\n'\n",
      " 'T\\n'\n",
      " 'x\\n'\n",
      " ')\\n'\n",
      " 'Эквивалентно логистическая регрессия может быть переформулирована в виде\\n'\n",
      " 'вероятностной модели\\n'\n",
      " ', выдающей вероятность положительного класса по правилу:\\n'\n",
      " '$p(y=+1|\\\\mathbf{x})=\\\\sigma(\\\\mathbf{w}^{T}\\\\mathbf{x}),$\\n'\n",
      " 'p\\n'\n",
      " '(\\n'\n",
      " 'y\\n'\n",
      " '=\\n'\n",
      " '+\\n'\n",
      " '1∣\\n'\n",
      " 'x\\n'\n",
      " ')\\n'\n",
      " '=\\n'\n",
      " 'σ\\n'\n",
      " '(\\n'\n",
      " 'w\\n'\n",
      " 'T\\n'\n",
      " 'x\\n'\n",
      " ')\\n'\n",
      " 'где график сигмоидной функции\\n'\n",
      " '$\\\\sigma(z)$\\n'\n",
      " 'σ\\n'\n",
      " '(\\n'\n",
      " 'z\\n'\n",
      " ')\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '    Your answer:\\n'\n",
      " '    ')\n"
     ]
    }
   ],
   "source": [
    "promt= make_prompt(question, convert_passage_to_str(passages))\n",
    "pprint(promt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae23b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model= genai.GenerativeModel('models/gemini-2.0-flash-001')\n",
    "\n",
    "answer = model.generate_content(promt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0dc928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Вероятность отрицательного класса в бинарной классификации рассчитывается как 1 минус вероятность положительного класса.  Если вероятность положительного класса обозначается как  `p(y=+1|x)`, тогда вероятность отрицательного класса `p(y=-1|x)` вычисляется следующим образом:\n",
       "\n",
       "`p(y=-1|x) = 1 - p(y=+1|x)`\n",
       "\n",
       "В контексте логистической регрессии, где вероятность положительного класса моделируется сигмоидной функцией:\n",
       "\n",
       "`p(y=+1|x) = σ(w^T x)`\n",
       "\n",
       "Тогда вероятность отрицательного класса будет:\n",
       "\n",
       "`p(y=-1|x) = 1 - σ(w^T x)`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(answer.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c7748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liali\\AppData\\Local\\Temp\\ipykernel_21864\\1825996937.py:22: DeprecationWarning: The class GeminiEmbeddingFunction does not implement __init__. This will be required in a future version.\n",
      "  return chroma_client.get_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Гребневая регрессия (Ridge Regression), также известная как регуляризация Тихонова (Tikhonov regularization), является аналитическим решением для линейной регрессии, которое используется для предотвращения переобучения модели, особенно когда в данных есть мультиколлинеарность (высокая корреляция между предикторами).\n",
       "\n",
       "**Суть гребневой регрессии:**\n",
       "\n",
       "В обычной линейной регрессии мы стремимся минимизировать сумму квадратов ошибок (RSS):\n",
       "\n",
       "RSS = Σ (yᵢ - ŷᵢ)²\n",
       "\n",
       "где yᵢ - фактическое значение целевой переменной, а ŷᵢ - предсказанное значение.\n",
       "\n",
       "Гребневая регрессия добавляет к этой функции штраф за величину коэффициентов регрессии.  Функция, которую мы минимизируем, становится:\n",
       "\n",
       "Cost = RSS + α * Σ βᵢ²\n",
       "\n",
       "где:\n",
       "*   α (альфа) - это параметр регуляризации, который контролирует силу штрафа.\n",
       "*   βᵢ - коэффициенты регрессии.\n",
       "\n",
       "**Влияние параметра регуляризации (α):**\n",
       "\n",
       "*   **α = 0:**  Гребневая регрессия эквивалентна обычной линейной регрессии.\n",
       "*   **α > 0:**  Добавляется штраф за большие коэффициенты. Чем больше α, тем сильнее штраф, и тем меньше будут коэффициенты.  Это приводит к упрощению модели и снижению риска переобучения.\n",
       "*   **Большие значения α:** Коэффициенты стремятся к нулю, что может привести к недообучению.\n",
       "\n",
       "**Аналитическое решение:**\n",
       "\n",
       "В отличие от некоторых других методов регуляризации, гребневая регрессия имеет аналитическое решение, то есть коэффициенты регрессии можно вычислить напрямую по формуле:\n",
       "\n",
       "β = (XᵀX + αI)⁻¹Xᵀy\n",
       "\n",
       "где:\n",
       "*   β - вектор коэффициентов регрессии.\n",
       "*   X - матрица предикторов.\n",
       "*   y - вектор целевой переменной.\n",
       "*   I - единичная матрица.\n",
       "*   Xᵀ - транспонированная матрица X.\n",
       "*   ( )⁻¹ - операция взятия обратной матрицы.\n",
       "\n",
       "**Преимущества аналитического решения:**\n",
       "\n",
       "*   **Вычислительная эффективность:**  Аналитическое решение позволяет быстро получить коэффициенты регрессии, особенно для небольших и средних наборов данных.\n",
       "*   **Гарантированная оптимальность:**  Аналитическое решение гарантирует нахождение глобального минимума функции потерь (с учетом регуляризации).\n",
       "\n",
       "**Недостатки аналитического решения:**\n",
       "\n",
       "*   **Обращение матрицы:**  Вычисление обратной матрицы (XᵀX + αI) может быть вычислительно затратным для очень больших наборов данных.\n",
       "*   **Требования к памяти:**  Для вычисления обратной матрицы может потребоваться большой объем памяти.\n",
       "\n",
       "**Когда использовать гребневую регрессию:**\n",
       "\n",
       "*   Когда есть мультиколлинеарность в данных (высокая корреляция между предикторами).\n",
       "*   Когда есть риск переобучения модели.\n",
       "*   Когда важна вычислительная эффективность и аналитическое решение является приемлемым.\n",
       "\n",
       "**Как выбрать параметр регуляризации (α):**\n",
       "\n",
       "Оптимальное значение α обычно выбирают с помощью методов кросс-валидации.  Идея заключается в том, чтобы оценить производительность модели на разных значениях α и выбрать то значение, которое дает наилучший результат (например, наименьшую ошибку) на отложенной выборке данных.\n",
       "\n",
       "**В заключение:**\n",
       "\n",
       "Гребневая регрессия - это мощный инструмент для построения устойчивых и обобщающих линейных моделей, особенно в условиях мультиколлинеарности.  Наличие аналитического решения делает ее привлекательной с точки зрения вычислительной эффективности для задач среднего размера.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 1\n",
    "# question = \"Donne-moi le nombre de planetes dans le systeme solaire\"\n",
    "question = \"раскажи об аналитическом решении для гребневой регрессии\"\n",
    "\n",
    "# Step 2\n",
    "db = get_chroma_db(\"second_try\")\n",
    "passages = relevant_docs(question, db, n_results=2)\n",
    "\n",
    "# Step 3\n",
    "context = convert_passage_to_str(passages)\n",
    "\n",
    "# Step 4\n",
    "prompt = make_prompt(question, context)\n",
    "\n",
    "# Step 5\n",
    "model = genai.GenerativeModel('models/gemini-2.0-flash-001')\n",
    "answer = model.generate_content(prompt)\n",
    "\n",
    "# Step 6\n",
    "Markdown(answer.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e31748e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\n",
      "x\n",
      "1\n",
      "y\n",
      "1\n",
      ")\n",
      "(\n",
      "x\n",
      "2\n",
      "y\n",
      "2\n",
      ")\n",
      "(\n",
      "x\n",
      "N\n",
      "y\n",
      "N\n",
      ")\n",
      "Такая задача называется\n",
      "задачей обучения с учителем\n",
      "(supervised learning), поскольку модель может использовать правильную \"учительскую\" разметку для набора из\n",
      "$N$\n",
      "N\n",
      "объектов для настройки своих параметров. Учительская разметка получается либо в результате ручной разметки экспертами предметной области, либо в результате логирования входных и выходных данных (которые мы хотим предсказать по входным в будущем) заранее - например, можно логировать, какие письма пользователь самостоятельно разметил как спам, чтобы в будущем научиться заранее предугадывать его предпочтения.\n",
      "В зависимости от типа отклика, задачи обучения с учителем разделяются на следующие категории:\n",
      "(regression): отклик представляет собой число\n",
      "$y\\in\\mathbb{R}$\n",
      "y\n",
      "∈\n",
      "R\n",
      ": предсказываем время пути по маршруту; фокусное расстояние в фотоаппарате для чёткости лиц или стоимость акции на следующий день.\n",
      "Векторная регрессия\n",
      ": отклик представляет собой сразу вектор вещественных ответов\n",
      "$y\\in \\mathbb{R}^M$\n",
      "y\n",
      "∈\n",
      "R\n",
      "M\n",
      ": прогнозируем будущую стоимость не одной акции, а сразу нескольких акций одновременно; при прогнозе погоды предсказываем сразу температуру, влажность, давление и скорость ветра.\n",
      "Ранжирование\n",
      "(ranking): отклик принимает вещественные значения релевантности\n",
      "$y\\in\\mathbb{R}$\n",
      "y\n",
      "∈\n",
      "R\n",
      ", однако при фактическом использовании важны\n",
      "не абсолютные значения отклика, а относительные\n",
      ", потому что итоговым результатом является упорядочивание объектов по степени релевантности.\n",
      ": в информационном поиске по поисковому запросу пользователя  отранжировать релевантные документы или товары в магазине.\n",
      "(classification): отклик принимает одно из C дискретных значений -\n",
      "$y\\in\\{1,2,...C\\}$\n",
      "y\n",
      "∈\n",
      "{\n",
      "1\n",
      "2\n",
      "C\n",
      "}\n",
      ". Частным случаем классификации является\n",
      "бинарная классификация\n",
      "(binary classification), когда классов всего два. В этом случае один из них называют положительным, а другой - отрицательным, и\n",
      "$y\\in\\{+1,-1\\}$\n",
      "y\n",
      "∈\n",
      "{\n",
      "+\n",
      "1\n",
      "−\n",
      "1\n",
      "}\n",
      "Примеры бинарной классификации\n",
      ": определить, болен ли человек или здоров по результатам анализов; определить, является ли письмо спамом или полезным сообщением; предсказать, вернёт ли клиент с определёнными характеристиками кредит банку или нет.\n",
      "Примеры многоклассовой классификации\n",
      ": определить человека по фото, поставить диагноз болезни по симптомам; классифицировать новость по тематике (спорт / политика / экономика / технологии / культура).\n",
      "Разметка\n",
      "(labeling): аналогично классификации, но объект может принадлежать сразу нескольким классам или ни одному.\n",
      ": автоматическая простановка хэштегов к изображению; отнесение текста к тематическим рубрикам, которые могут одновременно в нём присутствовать.\n",
      "Другие виды откликов.\n",
      "Выше описаны наиболее типичные виды откликов, но в общем случае откликом может выступать объект произвольного типа. В частности, модели машинного обучения можно научить генерировать:\n",
      "тексты (при переводе с одного языка на другой, при ответе на вопросы),\n",
      "графы (при подборе химических соединений, обладающих требуемыми химическими свойствами),\n",
      "$t$\n",
      "t\n",
      "в поддерево\n",
      "A\n",
      "t\n",
      "Если оно равно нулю, то разрастание полностью нецелесообразно, поскольку одиночная вершина\n",
      "$t$\n",
      "t\n",
      "и образованное из неё поддерево\n",
      "A\n",
      "t\n",
      "даёт одинаковый уровень ошибок. Но чем выше\n",
      "$\\alpha^*$\n",
      "α\n",
      "∗\n",
      ", тем построение поддерева\n",
      "A\n",
      "t\n",
      "целесообразнее, поскольку, чтобы компенсировать более высокую точность поддерева по сравнению с корнем, приходится сильнее штрафовать увеличение числа листов.\n",
      "В алгоритме обрезки по минимальной цене вычисляются целесообразности\n",
      "$\\alpha^*$\n",
      "α\n",
      "∗\n",
      "для каждого поддерева\n",
      "A\n",
      "t\n",
      "полного дерева, после чего\n",
      "удаляется поддерево с минимальной целесообразностью\n",
      ". Далее\n",
      "$\\alpha^*$\n",
      "α\n",
      "∗\n",
      "пересчитываются для всех оставшихся вершин (достаточно пересчитывать не для всех, а только для поддеревьев, затронутых удалением с предыдущего шага), и процесс повторяется до тех пор, пока не останется одна корневая вершина исходного дерева. Таким образом, алгоритм выдаст систему вложенных друг в друга поддеревьев:\n",
      "T\n",
      "1\n",
      "⊃\n",
      "T\n",
      "2\n",
      "⊃\n",
      "⊃\n",
      "T\n",
      "K\n",
      "=\n",
      "корень\n",
      "первоначального\n",
      "дерева\n",
      "среди которых выбирается поддерево, дающее максимальную точность на\n",
      "Дополнительно об алгоритмах обрезки решающих деревьях вы можете прочитать в\n",
      "[2]\n",
      "[3]\n",
      "подробно разобран пример расчёт алгоритма обрезки по минимальной цене и приведены вариации алгоритма. В\n",
      "[4]\n",
      "описано применение алгоритма в библиотеке sklearn.\n",
      "Breiman, L., Friedman, J., Olshen, R.A., & Stone, C.J. (1984). Classification and Regression Trees (1st ed.). Chapman and Hall/CRC.\n",
      "Wikipedia: decision tree pruning.\n",
      "Webb A. R., Copsey K.D. Statistical pattern recognition. – John Wiley & Sons, 2011.\n",
      "Документация sklearn: post pruning decision trees with cost complexity pruning.\n",
      "Обработка пропущенных значений | Машинное и глубокое обучение\n",
      "[IMAGE]\n",
      "[IMAGE]\n",
      "Часто некоторые признаки в данных могут отсутствовать. Например, в медицинской диагностике пациент мог не проходить определённых обследований, при анализе анкет респондент мог не указать возраст, а при обработке данных домов может отсутствовать дата постройки.\n",
      "Пропущенные значения можно заполнить одним из ранее изученных\n",
      "стандартных методов\n",
      ". Однако специфика работы решающих деревьев позволяет обрабатывать пропуски по-особенному.\n",
      "пропущенный признак присутствуют только в тестовых данных\n",
      "(но не в обучающих), то при проверке правила\n",
      "$\\text{признак} \\le \\text{порог}$\n",
      "≤\n",
      "объект можно направить в дочерний узел, содержащий больше объектов обучающей выборки, т.е. в априорно более вероятный.\n",
      "Однако возможны разные стратегии, когда\n",
      "в обучающей выборке также присутствуют пропуски\n",
      "В следующих двух способах предлагается настраивать дерево, используя только известные значения признаков.\n",
      "В классическом алгоритме CART\n",
      "[1]\n",
      "предлагалась процедура суррогатных разбиений (surrogate splits). Поскольку при\n",
      "выборе правила\n",
      "[признак\n",
      "$\\le$\n",
      "≤\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
