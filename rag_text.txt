





Онлайн-учебник по машинному обучению (machine learning). | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Машинное обучение
Машинное обучение


Виктор Владимирович Китов


Навигация по темам учебника доступна слева вверху
(три палочки на мобильных устройствах).


Почта для обратной связи:

deepmachinelearning@yandex.ru
.


Условные обозначения
 учебника.


Лицензия
 на использование материалов.


Вы можете помочь:
Напишите, если учебник помог вам разобраться в какой-то теме, живой отклик всегда ценен!
Расскажите об учебнике своим друзьям и коллегам по работе.
Напишите обратную связь по материалам учебника.
Напишите, если заметите опечатки и ошибки (даже незначительные)
в тексте или работе сайта.
Следующая страница
Введение
© 2023-25 
Виктор Китов.
 
Новости проекта.









Введение в машинное обучение (machine learning). | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Введение
Содержание этой страницы
Посвящается моим родителям Владимиру и Ольге.


Введение в машинное обучение


Неформальное определение
​


В повседневной жизни все мы ежедневно сталкиваемся с принятием решений:






при текущей дорожной ситуации надо ли ехать на метро или на машине?






удалить ли письмо в электронной почте как спам или сохранить?






ожидается ли дождь, и стоит ли брать с собой зонтик?






стоит ли звонить человеку с определённым предложением или он от него, скорее всего, откажется?






стоит ли докупить хлеба и молока или их хватит до конца недели?






какое фокусное расстояние на фотоаппарате установить, чтобы лицо фотографируемого человека получилось чётким?






Аналогичные проблемы принятия решений решаются организациями в массовом порядке:






сколько хлеба и молока закупить магазину, чтобы удовлетворить спрос до конца недели?






как почтовому сервису автоматически разделять письма на полезные и спам?






какими способами и по каким маршрутам отправлять грузы?






какую погоду предсказать сервису прогноза погоды на оставшийся конец дня?






как автоматически устанавливать фокусное расстояние на производимых фотоаппаратах?






При массовом и повторяющемся принятии решений целесообразно процесс принятия этих решений автоматизировать. Можно разработать явную систему правил этого процесса. Например, при определении важности письма мы можем смотреть на то, переписывались ли мы ранее с отправителем, принадлежит ли отправитель надежной и известной компании, включает ли текст письма определённые ключевые слова, которые нам заранее не интересны? В этом случае мы как бы явно программируем алгоритм принятия решений. Но проблема заключается в том, что






Сложно разработать универсальный алгоритм, который бы подходил всем пользователям. Одних может не интересовать получение кредита или психологическая консультация, а для других это может оказаться актуальным.






Сложно учесть всё многообразие ситуаций. Например, "бесплатная психологическая консультация" может быть сформулирована как "консультация психолога без оплаты", и изначальное правило уже перестанет действовать.






В подобных случаях полезно использовать 
машинное обучение
 (machine learning).




Машинное обучение - это процесс, в результате которого компьютер по наблюдаемым данным обучается лучше решать заданную задачу. Метод решения задачи при этом ищется в широком классе функций, параметризованном вектором параметров, который и подбирается по наблюдаемым данным.




Вместо явного прописывания четкой системы правил принятия решений в идеологии машинного обучения эти правила подбираются автоматически по данным. Под компьютером при этом может пониматься любое вычислительное устройство, например смартфон или процессор робота. Рассмотрим более детальное определение:




Машина учится на заданном 
опыте
 решать некоторую

задачу
, относительно некоторого

показателя качества
, если показатель качества растет на
задаче после получения опыта.




В нашем примере задача - это классификация писем на спам/не спам, показатель качества - доля верно классифицированных писем, а опыт - коллекция прошлых писем, которые до этого были вручную размечены по классам.


В другом примере задачей выступает предсказание времени в пути, отталкиваясь от текущего времени суток, дня недели, погоды и загрузки дорог, показатель качества - модуль отклонения предсказанного времени от фактического, а опытом - история предыдущих передвижений в известных условиях и с известным временем в пути.


Примеры задач
​


Приведём примеры популярных задач, решаемых с помощью машинного обучения:






Предсказать, уйдёт ли клиент к конкурентам? (churn prediction)






Является ли последовательность финансовых транзакций мошеннической? (fraud detection)






Предсказание пробок и времени в пути при планировании маршрута (traffic prediction).






Стоит ли показывать заданный товар покупателю в качестве рекомендации? (recommender systems)






Рекомендовать ли человека в качестве друга в социальной сети?






Является ли аккаунт в социальной сети ботом?






Голосовой ассистент: распознавание речи, автоматический ответ на вопросы, генерация речевого ответа.






Идентификация человека по лицу. Распознавание номера машины на камерах.






Подсчёт и отслеживание людей по камерам видеонаблюдения (object tracking). Обнаружение неправомерных действий (activity recognition).






Автоматическое управление машинами (self-driving cars): распознавание ситуации, планирование маршрута.






Автоматическая торговля на бирже (algorithmic trading).






Перевод с одного языка на другой (machine translation).






Постановка медицинских диагнозов по жалобам пациента и результатам обследований.






Рекомендация веб-страниц по поисковому запросу (information retrieval).






Автоматическая оценка ожидаемой зарплаты кандидата по резюме.






Игра компьютера в шахматы, управление игровыми персонажами.






Автоматическая оценка квартиры по её характеристикам.






Хвалит или ругает пользователь товар в своём отзыве? (sentiment analysis)






Генерация иллюстраций к тексту. Текстовое описание, что показано на изображении.






Прогноз погоды. Рекомендации фермерам, когда сажать/поливать/удобрять посевы.






Автоматическое написание программного кода (no code AI).






Автоматический выбор, каким пользователям какую онлайн-рекламу показать (targeted ads).






Генерация химических соединений, обладающих требуемыми свойствами:






крепкий, но легкий и термостойкий материал с повышенной проводимостью (material design)






препарат, обеспечивающий лечение и обладающий минимальными побочными эффектами (drug discovery)










Типы обучения
​


Машинное обучение
 (machine learning) описывает в целом подходы про подготовку данных, настройку и оценку прогнозирующих алгоритмов. Этому посвящена первая книга сайта, которую вы сейчас читаете.


Глубокое обучение
 (deep learning) - подраздел машинного обучения про сложные многоуровневые модели (нейросети), способные решать более сложные задачи прогнозирования. С ростом вычислительных мощностей и объёма данных существует устойчивый тренд на замену классических алгоритмов машинного обучения на нейросетевые, обеспечивающие большую точность и возможность генерировать не только численные ответы, но и ответы в виде сложно структурированных данных, таких как текст, речь, изображение и видео. Глубокому обучению посвящена 
вторая часть книги
.


Обучение с подкреплением
 (reinforcement learning) - также подраздел машинного обучения, в котором строится не однократный прогноз независимо для каждого объекта, а вырабатывается интерактивная стратегия поведения в изменяемой среде.


Примером обучения с подкреплением может служить автоматическая игра в шахматы, в которой необходимо последовательно генерировать каждый следующий ход. Успех генерации определяется не только текущим ходом, но и всей последовательностью решений в течение партии. Обучение с подкреплением также применяется в управлении игровыми персонажами в играх, машинами-роботами на дорогах, дронами, продвинутыми чат-ботами и роботизированными ассистентами.


Структура книги
​


Учебник посвящён классическому машинному обучению. В 
первой части
 изучаются основные постановки задач машинного обучения и фундаментальные понятия, необходимые для настройки моделей. Во 
второй части
 рассказывается про подготовку данных перед их использованием прогнозирующими моделями. В 
третьей части
 представлен общий вид классификаторов, необходимый для понимания их работы. 
Четвёртая часть
 посвящена метрическим методам регрессии и классификации, которые строят прогнозы, отталкиваясь от расстояний между изучаемыми объектами. 
Пятая часть
 знакомит читателя с линейной регрессией вместе с её всевозможными обобщениями и усложнениями. Оценивание качества прогнозов в задаче регрессии представлено в 
шестой части
. В 
седьмой части
 даётся определение линейных классификаторов в общем виде, а также рассказывается про популярные методы этого класса - метод опорных векторов и логистическую регрессию. Построению многоклассовых классификаторов из набора бинарных посвящена 
восьмая часть
. В 
девятой части
 описываются основные методы градиентной оптимизации, применяемые в классическом машинном обучении. В 
десятой части
 описаны методы оценки точности работы классификаторов. 
Одиннадцатая часть
 посвящена решающим деревьям. В 
двенадцатой части
 читатель познакомится с понятием переобученных и недообученных моделей на примере разложения на смещение и разброс. В 
тринадцатой части
 описывается принцип построения прогнозов, используя не одну модель, а сразу несколько, и приводятся описания популярных методов построения композиций моделей, включая усреднение, голосование, бэггинг, стэкинг и другие. 
Четырнадцатая часть
 описывает алгоритм бустинга - самого популярного и успешного метода построения композиций моделей. 
Пятнадцатая
 и 
шестнадцатая
 части посвящены различным подходам к интерпретации простых и более сложных моделей машинного обучения.


Учебник не затрагивает тему использования многослойных нейросетей (глубокого обучения). Этой теме посвящён 
второй учебник
 сайта.


Примеры кода для запуска методов
​


Многие методы, описанные в учебнике, сопровождаются примерами их запуска на языке python с использованием библиотек 
sklearn
, 
numpy
 и 
matplotlib
. Для этих библиотек использовались версии 1.3.0, 1.26.0 и 3.8.4 соответственно. Для анализа данных и тестирования различных методов машинного обучения удобно использовать бесплатную среду разработки 
jupyterlab
. Для удобства установки рекомендуется использовать менеджер пакетов 
anaconda
. В приводимых примерах для генерации данных используются следующие функции:


import
 numpy 
as
 np
from
 sklearn
.
datasets 
import
 make_moons
def
 
get_demo_classification_data
(
)
:
    X
,
Y 
=
 make_moons
(
n_samples
=
3000
,
 noise
=
0.3
 
,
random_state
=
0
)
   
# генерируем данные для классификации
    X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 train_test_split
(
X
,
 Y
,
 test_size
=
0.4
,
 stratify
=
Y
,
 random_state
=
0
)
   
# разбиваем выборку на обучающую (60%) и тестовую (40%) 
    
return
 X_train
,
 X_test
,
 Y_train
,
 Y_test    
def
 
get_demo_regression_data
(
)
:
    np
.
random
.
seed
(
0
)
    X 
=
 np
.
random
.
normal
(
size
=
[
3000
,
5
]
)
    NOISE 
=
 
0.3
*
np
.
random
.
normal
(
size
=
[
3000
]
)
    Y 
=
 X
.
mean
(
axis
=
1
)
+
(
X
**
2
)
.
mean
(
axis
=
1
)
+
NOISE    
# генерируем данные для регрессии
    X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 train_test_split
(
X
,
 Y
,
 test_size
=
0.4
,
 random_state
=
0
)
   
# разбиваем выборку на обучающую (60%) и тестовую (40%) 
    
return
 X_train
,
 X_test
,
 Y_train
,
 Y_test


Примеры запуска методов будут идти после описания самих методов, но вы также можете посмотреть код сразу всех примеров 
по ссылке
 с результатами его работы.
Предыдущая страница
Машинное обучение
Следующая страница
Основы машинного обучения
Неформальное определение
Примеры задач
Типы обучения
Структура книги
Примеры кода для запуска методов
© 2023-25 
Виктор Китов.
 
Новости проекта.









Обучение с учителем | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Обучение с учителем
Настройка параметров модели
Выпуклость потерь
Регуляризация модели
Взвешенный учёт наблюдений
Связь с принципом максимального правдоподобия
Обобщающая способность
Оценка качества прогнозов
Этапы решения задачи машинного обучения
Обучение без учителя
Частичное обучение
Вопросы
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Основы машинного обучения
Обучение с учителем
Содержание этой страницы
Обучение с учителем


Признаки, отклики и обучающая выборка
​


Машинное обучение работает с так называемыми 
объектами
 (objects). В задаче классификации спама объектами являются письма, а в задаче предсказания времени пути - начальная и конечная точка маршрута и информация об окружающей среде, которая влияет на длительность маршрута.


Каждый объект описывается парой 

, где







 - входная информация, которую мы знаем об объекте;







 - выходная информация, которую мы хотим предсказать для объекта по 

.






При этом для удобства обработки входную информацию в большинстве случаев кодируют некоторым вектором фиксированной длины 

, где каждый элемент этого вектора называют 
признаком
 (feature), а весь вектор 

 - 
вектором признаков
 (feature vector). Номер признака далее будем обозначать верхним индексом: 

.


Выходную информацию 

 называют 
откликом
 или 
целевой переменной
 (target).


В наиболее типичной ситуации нам известна размеченная выборка из N объектов:





Такая задача называется 
задачей обучения с учителем
 (supervised learning), поскольку модель может использовать правильную "учительскую" разметку для набора из 

 объектов для настройки своих параметров. Учительская разметка получается либо в результате ручной разметки экспертами предметной области, либо в результате логирования входных и выходных данных (которые мы хотим предсказать по входным в будущем) заранее - например, можно логировать, какие письма пользователь самостоятельно разметил как спам, чтобы в будущем научиться заранее предугадывать его предпочтения.


Типы задач обучения с учителем
​


В зависимости от типа отклика, задачи обучения с учителем разделяются на следующие категории:






Регрессия
 (regression): отклик представляет собой число 

.




Примеры
: предсказываем время пути по маршруту; фокусное расстояние в фотоаппарате для чёткости лиц или стоимость акции на следующий день.








Векторная регрессия
: отклик представляет собой сразу вектор вещественных ответов 

.




Примеры
: прогнозируем будущую стоимость не одной акции, а сразу нескольких акций одновременно; при прогнозе погоды предсказываем сразу температуру, влажность, давление и скорость ветра.








Ранжирование
 (ranking): отклик принимает вещественные значения релевантности 

, однако при фактическом использовании важны 
не абсолютные значения отклика, а относительные
, потому что итоговым результатом является упорядочивание объектов по степени релевантности.




Примеры
: в информационном поиске по поисковому запросу пользователя  отранжировать релевантные документы или товары в магазине.








Классификация
 (classification): отклик принимает одно из C дискретных значений - 

. Частным случаем классификации является 
бинарная классификация
 (binary classification), когда классов всего два. В этом случае один из них называют положительным, а другой - отрицательным, и 

.






Примеры бинарной классификации
: определить, болен ли человек или здоров по результатам анализов; определить, является ли письмо спамом или полезным сообщением; предсказать, вернёт ли клиент с определёнными характеристиками кредит банку или нет.






Примеры многоклассовой классификации
: определить человека по фото, поставить диагноз болезни по симптомам; классифицировать новость по тематике (спорт / политика / экономика / технологии / культура).










Разметка
 (labeling): аналогично классификации, но объект может принадлежать сразу нескольким классам или ни одному.




Примеры
: автоматическая простановка хэштегов к изображению; отнесение текста к тематическим рубрикам, которые могут одновременно в нём присутствовать.








Другие виды откликов.
Выше описаны наиболее типичные виды откликов, но в общем случае откликом может выступать объект произвольного типа. В частности, модели машинного обучения можно научить генерировать:




тексты (при переводе с одного языка на другой, при ответе на вопросы),






графы (при подборе химических соединений, обладающих требуемыми химическими свойствами),






звук (при озвучивании текста),






изображения (в задачах перерисовки фотографий пользователей в стиле известных художников или по текстовому запросу).




Сложно-структурированные отклики реализуются нейронными сетями, что мы изучим во второй части книги про 
глубокое обучение
.


Пример задачи регрессии
​


Ниже приведён пример задачи регрессии, в которой по одномерному признаку по оси X необходимо предсказать вещественный отклик по оси Y. Обучающая выборка обозначена оранжевыми точками, по которым требуется восстановить зависимость 

, чтобы уметь прогнозировать целевую величину 

 для любых новых объектов 

. Как видим, это можно делать различными способами с разными ошибками прогнозов.


[IMAGE]


Пример задачи классификации
​


Далее приведен пример задачи классификации, в которой каждый объект описывается двумя признаками 

 и 

, обозначенными по осям X и Y. Каждый объект обучающей выборки изображён точкой на графике. Целевая величина для прогнозирования представляет собой один из трех классов, каждый из которых показан своим цветом. По этим точкам требуется восстановить общую закономерность соотнесения любой точки 

 одному из классов.


[IMAGE]


Детальнее задачи обучения с учителем описаны в 
[1]
 и 
[2]
.


Специальные постановки задачи обучения с учителем
​


Если, помимо обучающих объектов, заранее известны признаковые описания 

 для тестовых объектов, для которых требуется построить прогноз в будущем, то такая задача называется 
трансдуктивным обучением
 (transductive learning). Дополнительное знание о тестовых объектах позволяет более точно настроить модель именно для этих объектов.


Существуют ситуации, когда для объектов обучающей выборки известны не только целевые переменные 

, но и пояснения 

 (
привилегированная информация
, priveledged information), почему отклик именно такой. Рассмотрим в качестве примера задачу медицинской классификации, в которой для пациентов с заданными признаками (такими как пол, возраст, история визитов к врачу, общее состояние, текущие жалобы) требуется поставить диагноз болезни. В этой задаче разметка (итоговый диагноз врача), может содержать дополнительные пояснения 

, характеризующие комментарии врача, почему он поставил тот или иной диагноз. В этом случае обучающая выборка состоит уже из троек (входные признаки, отклик, пояснения):





Требуется построить модель, которая как и раньше, по входным признакам будет предсказывать отклик 

 уже для новых объектов, но для более точной настройки модель может использовать ещё и пояснения 

, доступные в обучающей выборке. Настройка модели в таком случае называется 
learning using priviledged information
 (LUPI, 
[3]
).


Литература
​






Webb A. R., Copsey K.D. Statistical pattern recognition. 3rd Edition. – John Wiley & Sons, 2011.






Aggarwal C. C. et al. Data mining: the textbook. – New York : springer, 2015.






Vapnik V., Vashist A. A new learning paradigm: Learning using privileged information //Neural networks. – 2009. – Т. 22. – №. 5-6. – С. 544-557.




Предыдущая страница
Основы машинного обучения
Следующая страница
Настройка параметров модели
Признаки, отклики и обучающая выборка
Типы задач обучения с учителем
Пример задачи регрессии
Пример задачи классификации
Специальные постановки задачи обучения с учителем
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Настройка параметров модели | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Обучение с учителем
Настройка параметров модели
Выпуклость потерь
Регуляризация модели
Взвешенный учёт наблюдений
Связь с принципом максимального правдоподобия
Обобщающая способность
Оценка качества прогнозов
Этапы решения задачи машинного обучения
Обучение без учителя
Частичное обучение
Вопросы
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Основы машинного обучения
Настройка параметров модели
Содержание этой страницы
Настройка параметров модели


Можно вручную задать функцию соответствия 

 (которую называют 
прогностической
 или 
прогнозной
 функцией), которая бы выдавала прогнозы отклика 

 по известным признакам, однако зачастую это сложно сделать из-за многообразия объектов и сложных зависимостей между признаками и откликом. Поэтому в машинном обучении с учителем соответствие между признаками и откликом ищется в некотором классе функций 

, параметризованном 
вектором параметров
 

, которые подбираются по обучающей выборке, состоящей из 

 объектов:







Параметры модели также будем называть 
весами модели
 (model weights).




Например, класс функций может быть множеством всех константных прогнозов:





или состоять из всех линейных функций от признаков:





Существуют и более сложные семейства функций, о которых будет рассказано в следующих главах.


Чтобы из семейства функций выбрать наилучшую (что эквивалентно выбору определённого вектора параметров 

) необходимо численно формализовать, какие прогнозы мы будем считать хорошими, а какие - плохими. Для этого задаётся 
функция потерь
 (loss function) 

, зависящая от истинного значения отклика 

 и предсказанного 

. Чем выше значение функции потерь, тем хуже считается прогноз.


Основные функции потерь в задаче регрессии
​


Рассмотрим основные функции потерь в задаче регрессии:


название
формула
квадрат ошибки (squared error, L2 loss)

модуль ошибки (absolute error, L1 loss)



Также широко используется гладкая комбинация обоих функций потерь, называемая 
функцией Хубера
 (smooth L1 loss):





В последнем случае 

 - гиперпараметр, задающий область квадратичной зависимости, которая продлевается линейно за пределами этой области, сохраняя непрерывность самой функции и непрерывность её производной.




Будучи гладкой, эта функция удобна для оптимизации, но в то же время так же устойчива к нетипичным наблюдениям, как и модуль ошибки.




Пример потерь для классификации
​


Для задачи классификации простейшей функцией потерь является индикатор ошибки, вычисляемый по формуле 

, где функция индикатора 

 возвращает 1, если условие выполнено, и 0 иначе. Забегая вперёд, скажем, что на практике для настройки моделей эту функцию применить нельзя, поскольку она не является дифференцируемой. Поэтому в классификации используются другие функции потерь, о которых будет рассказано 
далее
.


Функция выигрыша
Функцию потерь не нужно путать с 
функцией выигрыша
 (score function) 

, которая также часто встречается в машинном обучении. Для более плохих прогнозов функция потерь должна принимать 
более высокие
 значения, а функция выигрыша - наоборот, 
более низкие
.
Например, для классификации функцией выигрыша является индикатор верного угадывания класса 

.


Теоретический и эмпирический риск
​


Для настройки параметров модели 

 традиционно желают минимизировать ожидаемые потери на новых объектах, поступающих из некоторого вероятностного распределения, называемые теоретическим риском:





Практически эта величина невычислима из-за того, что мы не обладаем информацией о теоретическом распределении объектов 

, а знаем лишь ограниченную обучающую выборку 

. Поэтому на практике параметры 

 находятся минимизацией 
эмпирического риска
 

, представляющего собой выборочную оценку теоретического риска по обучающей выборке:





Оценка параметров 

 определяется как минимизатор эмпирического риска:





где 

 - 
матрица "объекты-признаки"
, также называемая 
матрицей признаков
 (feature matrix). Строки этой матрицы соответствуют 

-мерным векторам признаков для каждого из 

 объектов обучающей выборки, а 

 - вектор откликов, которые мы хотим научиться предсказывать по признакам.


[IMAGE]


Модель с настроенными параметрами также называют 
алгоритмом прогнозирования
.




Параметры модели не стоит путать с 
гиперпараметрами
 (hyperparameters), которые не настраиваются по обучающей выборке, а задаются пользователем либо подбираются по отдельной выборке, называемой валидационной.




Вы также можете прочитать о принципе минимизации эмпирического риска в 
[1]
.


Литература
​




Мерков А. Б. Распознавание образов: введение в методы статистического обучения. //Москва: Едиториал УРСС. – 2019.


Предыдущая страница
Обучение с учителем
Следующая страница
Выпуклость потерь
Основные функции потерь в задаче регрессии
Пример потерь для классификации
Теоретический и эмпирический риск
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Выпуклость потерь | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Обучение с учителем
Настройка параметров модели
Выпуклость потерь
Регуляризация модели
Взвешенный учёт наблюдений
Связь с принципом максимального правдоподобия
Обобщающая способность
Оценка качества прогнозов
Этапы решения задачи машинного обучения
Обучение без учителя
Частичное обучение
Вопросы
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Основы машинного обучения
Выпуклость потерь
Содержание этой страницы
Выпуклость потерь


В машинном обучении приветствуется выбор 
выпуклых
 функций потерь (convex loss functions) от параметров (или весов) модели, т.е. таких функций, что







Такие функции также называют 
выпуклыми вверх
, чтобы не путать с  
вогнутыми
 функциями (
выпуклыми вниз
), для которых выполнено неравенство в обратную сторону.




Неравенство выполнено для любых аргументов 

 из области определения функции, которое также должно быть выпуклым (т.е. если две точки принадлежат области определения, то и любая промежуточная точка на отрезке, их соединяющем, тоже принадлежит области определения функции). Геометрически определение выпуклой функции означает, что отрезок, соединяющий любые две точки на функции, нигде не может лежать ниже значений функции.


Пример выпуклой функции от одной переменной показан ниже:


[IMAGE]


Стоит отметить, что если потери на отдельном объекте 

 выпуклы по 

, то и потери по всей обучающей выборке (эмпирический риск) будут выпуклыми, т.к. усреднение выпуклых функций всегда будет тоже выпуклой функцией (докажите!).


Выпуклые функции удобны тем, что:




любой локальный минимум является 
глобальным
;


равенство нулю производной является не только необходимым, но и 
достаточным
 условием минимума.




Таким образом, найдя значение 

, в котором 

, мы точно знаем, что это глобальный минимум.


Основные функции потерь машинного обучения для задач 
регрессии
 и 
классификации
 выпуклы.


Задача
Попробуйте доказать эти свойства. Для доказательства второго свойства пригодится использование другого критерия выпуклой функции, что она всегда лежит не ниже касательной, проведённой в любой точке.


Может ли у выпуклой функции не быть минимума?
Да, рассмотрите функцию 

.


Может ли у выпуклой функции быть несколько минимумов?
Да, рассмотрите функцию 

.


Более полную информацию о выпуклых функциях вы можете прочитать в 
[1]
 и 
[2]
.


Литература
​






Wikipedia: convex function.






Bertsekas D. Convex optimization theory. – Athena Scientific, 2009. 




Предыдущая страница
Настройка параметров модели
Следующая страница
Регуляризация модели
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Регуляризация модели | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Обучение с учителем
Настройка параметров модели
Выпуклость потерь
Регуляризация модели
Взвешенный учёт наблюдений
Связь с принципом максимального правдоподобия
Обобщающая способность
Оценка качества прогнозов
Этапы решения задачи машинного обучения
Обучение без учителя
Частичное обучение
Вопросы
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Основы машинного обучения
Регуляризация модели
Содержание этой страницы
Регуляризация модели


Регуляризация моделей
 (model regularization) - распространённый приём в машинном обучении, позволяющий контролировать 
сложность
 получаемой модели (model complexity) за счёт внесения ограничений в её настройку. Под сложностью модели в этой книге будет подразумеваться её гибкость, т.е. способность подстаиваться под наблюдения обучающей выборки. Например, полином - более сложная функция, чем линейная, поскольку за счёт большего числа настраиваемых коэффициентов способен гибче настраиваться на регрессионную зависимость.


Существуют разные способы регуляризации, но самый популярный - добавление регуляризующего слагаемого в минимизируемую функцию потерь:





Функция 

 называется 
регуляризатором
 и штрафует параметры модели за излишнюю сложность. Гиперпараметр 

 выбирается пользователем и определяет, насколько важна точность по сравнению с простотой получаемой модели.


Почему 

 является именно гиперпараметром, т.е. почему её нельзя настраивать по обучающей выборке вместе с параметрами модели 

?
При настройке 

 по критерию выше можно сразу сказать, чему равно его оптимальное значение: 

! Поскольку это соответствует удалению регуляризующего слагаемого из штрафа и настройке самой сложной (гибкой) модели, обеспечивающей наиболее точную подстройку под обучающие объекты. 
Но не обязательно под тестовые.
 То есть 
обобщающая способность
 модели на новых данных (generalization ability) может оказаться неоптимальной.


Популярные функции регуляризации
​


Популярными способами выбора 

 являются:






L2-регуляризация









L1-регуляризация













ElasticNet-регуляризация









Все эти виды регуляризации поощряют выбор более малых по абсолютной величине весов в векторе 

. Это ограничивает гибкость настройки весов и препятствует  переобучению модели под обучающую выборку.


ElasticNet требует спецификации дополнительного гиперпараметра 

.


Преимущество L1-регуляризации
Особенностью L1-регуляризации является то, что она приводит к решению, в котором часть найденных весов может получаться 
в точности равной нулю
. Это достигается за счет слагаемого 

 - см. 
обоснование
. Если в прогностической модели веса входят как мультипликативные множители при признаках (как, например, в линейных моделях или на первом слое нейросетей), то это приводит к 
отбору признаков
 (feature selection) - модель полностью перестаёт учитывать признаки, при которых получились нулевые веса! Это позволяет получать более эффективные и интерпретируемые модели и не собирать значения тех признаков, которые в конечном счёте не будут использоваться.


Преимущество L2-регуляризации
В L2-регуляризации штраф квадратично возрастает при увеличении веса. Если вес - коэффициент при признаке (как, например, в линейных моделях 
регрессии
 и 
классификации
 или на первом слое 
нейросетей
), то это приводит к более равномерному распределению весов по признакам, что способствует более полному учёту их значений. В частности, если два признака принимают в точности одинаковые значения, то вес при этих признаках L2-регуляризация распределит поровну, в то время как L1-регуляризация может их распределить произвольным образом.


Так как L1- и L2-регуляризации обладают разными достоинствами, для их совмещения и используется регуляризация ElasticNet.


Можно специфицировать и собственный вид регуляризатора 

, исходя из логики решаемой задачи и представлений о том, модель с какими именно весами можно считать простой. Например, можно поощрять модели с более близкими весами друг к другу.


Другие виды регуляризации
​


Помимо дополнительного штрафа за величину весов, можно препятствовать переобучению моделей за счёт дополнительных ограничений на веса. Например, можно накладывать ограничения, что часть весов должны получаться неотрицательными. Или одни веса в точности совпадать по величине с другими.


Также можно ограничивать максимальное число итераций оптимизации при настройке функции потерь (early stopping). Это также препятствует переобучению модели под обучающую выборку.


Существуют и другие подходы к регуляризации. Особенно остро проблема переобучения стоит для нейросетей. Со всевозможными видами их регуляризации вы впоследствии 
познакомитесь
 в 
учебнике по глубокому обучению
.


Больше информации о регуляризации вы можете прочитать в 
[1]
 и 
[2]
.


Литература
​






Wikipedia: regularization (mathematics)
.






Мерков А. Б. Распознавание образов: введение в методы статистического обучения. // Москва: Едиториал УРСС. – 2010.




Предыдущая страница
Выпуклость потерь
Следующая страница
Взвешенный учёт наблюдений
Популярные функции регуляризации
Другие виды регуляризации
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Взвешенный учёт наблюдений | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Обучение с учителем
Настройка параметров модели
Выпуклость потерь
Регуляризация модели
Взвешенный учёт наблюдений
Связь с принципом максимального правдоподобия
Обобщающая способность
Оценка качества прогнозов
Этапы решения задачи машинного обучения
Обучение без учителя
Частичное обучение
Вопросы
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Основы машинного обучения
Взвешенный учёт наблюдений
Взвешенный учёт наблюдений


Классическая функция потерь минимизирует средние потери с 
равномерным
 учётом всех объектов:





Но различные объекты можно учитывать по-разному, задав 
свой вес
 для учёта каждого объекта:





Взвешенный учёт наблюдений позволяет занижать вес подозрительных объектов (информация о которых получена из ненадёжных источников) или объектов-выбросов (выбивающихся из общего распределения или на которых модель сильно ошибается).


Также взвешенный учёт наблюдений позволяет сбалансировать выборку по некоторой характеристике. Пусть, например, мы предсказываем зарплату для мужчин и женщин по их характеристикам, и наблюдений в обучающей выборке по женщинам гораздо больше, чем по мужчинам. Чтобы сделать модель с глобальной применимостью как для мужчин, так и для женщин без смещения в сторону того или иного пола, мы можем учитывать наблюдения для женщин с меньшим весом, а для мужчин - с большим.


Другой вариант применения
В первой реализации алгоритма бустинга 
AdaBoost
 прогноз строился взвешенной суммой одинаковых моделей, каждая из которых настраивалась по одной и той же обучающей выборке, а изменялись только веса объектов. Тем объектам, на которых ранее настроенная модель сильнее ошибалась, задавались повышенные веса при настройке новой уточняющей модели, чтобы она провела на них более тщательную "работу над ошибками".
Предыдущая страница
Регуляризация модели
Следующая страница
Связь с принципом максимального правдоподобия
© 2023-25 
Виктор Китов.
 
Новости проекта.









Связь с принципом максимального правдоподобия | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Обучение с учителем
Настройка параметров модели
Выпуклость потерь
Регуляризация модели
Взвешенный учёт наблюдений
Связь с принципом максимального правдоподобия
Обобщающая способность
Оценка качества прогнозов
Этапы решения задачи машинного обучения
Обучение без учителя
Частичное обучение
Вопросы
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Основы машинного обучения
Связь с принципом максимального правдоподобия
Содержание этой страницы
Связь с принципом максимального правдоподобия


Многие модели машинного обучения 

 могут сопоставлять целевой величине 
вероятностное распределение
 (probability distribution).


В случае задачи классификации - это вероятности каждого из классов при условии объекта 

:





В случае задачи регрессии предсказывается условная 
плотность вероятностного распределения
 

, позволяющая рассчитать, с какой вероятностью вещественная величина принадлежит каждому интервалу.


В этих случаях модель машинного обучения представляет собой 
вероятностную модель
. При предположении, что объекты выборки распределены 
независимо
,  вероятность пронаблюдать ответы на всей выборке 

 факторизуется в произведение вероятностей пронаблюдать ответ на каждом объекте выборки:





Задача регрессии
В случае задачи регрессии получается аналогичная факторизация, но состоящая не из вероятностей отдельных классов, а из значений условной 
плотности
.


Принцип максимума правдоподобия
 (maximum likelihood estimation) назначает такие параметры модели 

, которые бы максимизировали вероятность пронаблюдать верные отклики на всех объектах обучающей выборки. Таким образом, параметры вероятностной модели находятся из условия





Вычислительно неудобно максимизировать произведение большого количества малых чисел (получим машинный ноль), поэтому на практике максимизируют средний логарифм правдоподобия, дающий тот же самый результат:





Это очень похоже на принцип минимизации эмпирического риска, согласно которому параметры модели должны находиться из условия:





Отсюда видна взаимосвязь принципа минимизации эмпирического риска и принципа максимального правдоподобия. При выборке такой функции потерь и прогнозирующей функции, что





модель машинного обучения настраивается точно так же, как соответствующая вероятностная модель. Верно и в обратную сторону. Если вероятностную модель выбрать таким образом, что равенство выше выполняется, то модель машинного обучения можно эквивалентно описать вероятностной моделью. Знак минус взят, поскольку в одном случае целевой функционал нужно 
максимизировать
, а в другом - 
минимизировать
.


Вы также можете прочитать о связи принципов минимизации эмпирического риска и принципа максимума правдоподобия при использовании разных типов регуляризации в 
[1]
.


Литература
​




Воронцов К. В. Математические методы обучения по прецедентам (теория обучения машин) // Москва. – 2011.


Предыдущая страница
Взвешенный учёт наблюдений
Следующая страница
Обобщающая способность
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Обобщающая способность модели | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Обучение с учителем
Настройка параметров модели
Выпуклость потерь
Регуляризация модели
Взвешенный учёт наблюдений
Связь с принципом максимального правдоподобия
Обобщающая способность
Оценка качества прогнозов
Этапы решения задачи машинного обучения
Обучение без учителя
Частичное обучение
Вопросы
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Основы машинного обучения
Обобщающая способность
Содержание этой страницы
Обобщающая способность модели


После 
настройки параметров модели
 на 
обучающей выборке
 (training set) 

, нам бы хотелось оценить, насколько хорошо она будет работать на новых данных - 
тестовой выборке
 (test set) 

, т.е. оценить так называемую 
обобщающую способность
 (generalization ability) - способность модели успешно экстраполировать выученные зависимости при обучении. Ведь именно для этого мы и настраивали модель!


Тут важно помнить, что эмпирический риск на обучающей выборке не будет репрезентативно отражать эмпирический риск на новых данных, и в общем случае мы будем наблюдать, что 

, поскольку 

  выбиралась так, чтобы минимизировать ошибки именно на обучающих данных 

, но не новых. Мы лишь надеемся, что новые данные будут распределены примерно так же, как в обучающей выборке.


Чем более сложная (гибкая, с б
о
льшим числом параметров) у нас модель, тем легче ей  подстроиться под обучающую выборку и тем меньше будет 

, однако это далеко не всегда будет приводить к снижению 

! Например, мы решаем задачу линейной регрессии по одномерному признаку 

 и отклику 

. Управлять сложностью получаемой модели можно за счет поиска линейной зависимости не только от 

, но и от квадрата признака 

, куба признака 

 и так далее до определённой степени 

. Тогда наша модель будет иметь вид:





и будет моделировать множество всевозможных полиномиальных зависимостей 

 от 

. Выбирая различные 

, мы будем управлять сложностью получаемой модели. На рисунке ниже обучающая выборка в осях 

 показана точками, а прогнозы модели при различных 

 показаны пунктирной линией. Видно, что малое 

  (слева) будет приводить к линейной зависимости, которая слишком проста для реальной зависимости в данных, что соответствует 
недообученной модели
 (underfitted model), в то время как при высоком 

 (справа) зависимость получается сложнее реальной зависимости и приводит к 
переобученной модели
 (overfitted model). Промежуточное 

 приводит к модели, сложность которой примерно соответствует сложности реальных данных.


[IMAGE]


Более формально понятия недообученных и переобученных моделей будут рассмотрены в 
отдельном разделе
 учебника.


Гиперпараметры моделей
​


Такой параметр, как 

 в примере, который не настраивается на обучающей выборке (как вектор весов 

), а выбирается пользователем, называется 
гиперпараметром
 (hyperparameter).


Подумайте, почему K нельзя настраивать на обучающей выборке?
Такой способ настройки будет всегда поощрять более гибкую модель с б
о
льшим значением K.
В частности, при K>=N-1 модель будет иметь как минимум столько же настраиваемых параметров, сколько объектов в выборке, и сможет обеспечить безошибочные прогнозы на всех объектах обучающей выборки, но не на новых тестовых объектах!


У большинства моделей машинного обучения есть гиперпараметр, отвечающий за сложность модели. Важно тщательно настроить этот гиперпараметр, чтобы 
сложность модели соответствовала сложности реальной зависимости в данных
.


Если модель будет слишком простой, то она будет показывать недостаточную точность из-за того, что у неё не хватает выразительной способности описать реальную зависимость.


Если же модель будет слишком сложной, то она начнёт 
перенастраиваться на особенности реализации обучающей выборки
 (которая случайна в силу случайного отбора объектов в неё) вместо подгонки под реальную зависимость, что также негативно повлияет на её обобщающую способность на тестовых данных. Детальнее  недообученные и переобученные модели будут описаны в 
отдельном разделе книги
.


Вы также можете прочитать недообученных и переобученных моделях в 
[1]
.


Литература
​




Geeksforgeeks: underfitting and overfitting.


Предыдущая страница
Связь с принципом максимального правдоподобия
Следующая страница
Оценка качества прогнозов
Гиперпараметры моделей
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Оценка качества прогнозов | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Обучение с учителем
Настройка параметров модели
Выпуклость потерь
Регуляризация модели
Взвешенный учёт наблюдений
Связь с принципом максимального правдоподобия
Обобщающая способность
Оценка качества прогнозов
Этапы решения задачи машинного обучения
Обучение без учителя
Частичное обучение
Вопросы
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Основы машинного обучения
Оценка качества прогнозов
Содержание этой страницы
Оценка качества прогнозов


Мы можем использовать для прогнозирования разные модели или одну и ту же модель, но при разных значениях гиперпараметров. Также для обработки варьируют весь 
конвейер обработки данных
 (пайплайн, pipeline), включающий как предобработку данных (заполнение пропущенных значений, отсев аномальных наблюдений, отбор и кодирование признаков), так и итоговое построение прогнозов. Важно уметь оценивать качество модели, чтобы подобрать самую точную модель и её наилучшую конфигурацию, а также знать, на какое качество работы мы можем рассчитывать на новых данных.


Как можно было бы оценить качество прогнозов модели? Как мы выяснили раньше, средние потери на обучающих объектах представляют собой необъективную и слишком оптимистическую оценку потерь модели на новых объектах, занижая потери, поскольку её параметры подбираются так, чтобы 
именно на обучающих объектах
 модель работала хорошо. Для более объективной оценки модели есть два подхода - использование отложенной 
валидационной выборки
 и 
кросс-валидация
.


Валидационная выборка
​


В этом подходе предлагается разбить размеченную выборку случайно на две подвыборки:






обучающую
 (training set, ~80% объектов), на которой настраивать параметры модели 

.






валидационную
 (validation set, ~20% объектов), на которой оценивать её качество.






[IMAGE]


Таким образом, множество индексов всех объектов 

 случайным образом разбивается на два подмножества:







 - индексы объектов обучающей выборки;







 - индексы объектов валидационной выборки.






Настройка параметров производится по обучающим объектам (

 - число элементов в множестве 

):





При желании можно также производить 
настройку с регуляризацией
.


Оценка качества прогнозов производится по объектам валидационной выборки:





В этом случае регуляризация не используется, т.к. нас интересует 
только точность
 итоговых прогнозов.


Данный подход также называется 
валидацией на отложенных данных
 (hold-out validation).


Итоговая модель
После того, как мы оценили качество модели на валидационной выборке, итоговая модель обучается 
на всех
 размеченных данных (и на обучающей, и на валидационной выборке). Так мы повысим качество итоговой модели, настраивая её, используя всю доступную информацию.


Кросс-валидация
​


Недостатком отложенной валидационной выборки является то, что приходится обучать модель на подмножестве данных, а не на всех, поскольку часть данных резервируется на оценку качества (валидационную выборку). Валидационная выборка должна занимать существенную пропорцию от всех данных, чтобы репрезентативно представлять разнообразие новых наблюдений в будущем. Из-за этого тестируемая модель будет в общем получаться хуже, чем итоговая модель, которая обучается на всех данных.


Кросс-валидация
 (перекрёстный контроль, кросс-проверка, cross-validation) - другой подход, который позволяет задействовать больше размеченных объектов для обучения, и все размеченные объекты для тестирования качества прогнозов, что обеспечивает более точное оценивание качества прогнозов.


Для этого размеченная выборка делится на 

 примерно равных групп объектов, называемых блоками (folds), а подход целиком называется 

-блоковой кросс-валидацией (K-fold cross-validation).





 обычно берется равным от 3 до 8. Дальнейшее наращивание 

 слишком усложняет настройку, но не приводит к существенному улучшению качества оценок.




Далее каждый из этих блоков поочерёдно исключается, а модель настраивается по оставшимся блокам, как показано на рисунке, где строки - это этапы работы алгоритма, а столбцы - блоки объектов, на которые мы разбили обучающую выборку:


[IMAGE]


После прохода по всем блокам мы получим несмещённые вневыборочные прогнозы для всех объектов, усреднением потерь на которых мы получим итоговую оценку качества.


Преимущества
​






Полученная таким образом оценка будет точнее, чем предыдущий подход, поскольку качество прогнозов будет оценено 
на всех располагаемых объектах
, а не только на валидационной выборке.






Также, поскольку каждый раз исключается лишь один из небольших блоков, тестируемая модель обучается на большем объеме данных и получается 
ближе к итоговой
, которую мы обучаем на всей выборке.






Поскольку модель в кросс-валидации перенастраивается 

 раз, можно исследовать стабильность потерь и стабильность настроенных параметров по отдельным блокам, анализируя их стандартные отклонения по блокам. Также можно следить за тем, насколько рассогласованными получаются прогнозы между 

 моделями, обученными на каждой подвыборке, что позволит оценивать уверенность в прогнозах.






Недостатки
​


Недостатком кросс-валидации является то, что приходится 

 раз перенастраивать модель, в отличие от подхода с отложенной валидационной выборкой, где оцениваемая модель настраивалась лишь один раз.


В частном случае кросс-валидации при 

 модель будет применена к каждому объекту в отдельности. Такой метод называется 
скользящим
контролем
 (leave-one-out), но применяется только для моделей с очень быстрой настройкой, поскольку требует перенастройки модели 

 раз.


Mетоды оценки качества прогнозов моделей и их программные реализации в вы также можете прочитать в 
[1]
.


Особенности применения методов
​


Альтернативная итоговая модель
​


Вместо обучения итоговой модели на всех данных можно в качестве итоговой брать усреднение прогнозов по 

 моделям, обученным на каждом этапе кросс-валидации.


Такая конфигурация может показывать более высокую точность. Сложность обучения у неё ниже (не нужно настраивать модель сразу на всех данных), но сложность прогнозирования выше (поскольку придётся для каждого прогноза усреднять по прогнозам 

 моделей).


Случайное перемешивание
​


Как перед применением подхода с отложенной выборкой, так и перед кросс-валидацией важно объекты перемешать 
в случайном порядке
, поскольку исходный порядок объектов мог быть неслучайным. Например, при диагностике заболеваний пациентов поликлиники сначала могли идти здоровые пациенты, а потом больные (во время эпидемии). Для сбалансированного разбиения на подвыборки наблюдения по пациентам необходимо предварительно перемешать.


Стратифицированное разбиение
​


Важно помнить, что случайное разбиение на подвыборки меняет распределение признаков и отклика. Например, в случае задачи классификации распределение классов на полной выборке и подвыборках будет различаться в зависимости от характера разбиения. Для сохранения распределения по классам можно производить случайное разбиение 
со стратификацией
 (stratified split), позволяющее сохранить исходное распределение классов в каждой подвыборке. Такое разбиение проиллюстрировано ниже для случая 3-х классов:


[IMAGE]


Задача
Предложите алгоритм генерации разбиения со стратификацией по классам.


Несбалансированная классификация
Сохранить исходное распределение классов 
особенно важно
 в задаче 
несбалансированной классификации
 (umbalanced classification), в которой одни классы встречаются существенно реже остальных. В таком случае высока вероятность, что в подвыборку не попадёт ни одного объекта-представителя редкого класса, и подвыборка получится нерепрезентативной!
Примеры задач несбалансированной классификации: выявление редких заболеваний в медицинской диагностике, обнаружение мошеннических транзакций среди миллионов остальных.
Несбалансированная классификация требует особых подходов, реализованных, например, в библиотеке imbalanced-learn 
[2]
.


В случае, когда классы встречаются часто, стратификация не так критична, поскольку внутри больших подвыборок распределение классов и так будет получаться похожим на априорное распределение по всей выборке. Это следует из закона больших чисел 
[3]
.


Учет случайности результатов
​


Поскольку разбиение на обучающие и валидационные блоки происходит случайно, то результаты 
будут различаться при перезапусках
. Для воспроизводимости экспериментов важно зафиксировать случайный порядок. Это достигается 
инициализацией генератора случайных чисел фиксированным числом
 (random state, random seed).


Чем его инициализировать?
В обучающих ноутбуках генератор случайности часто инициализируют числом 42. Однако никакой магии именно в таком выборе нет, главное - зафиксировать случайность любым числом, например, нулём.


Если позволяют вычислительные ресурсы, можно перезапустить процедуру несколько раз с разной инициализацией, чтобы оценить влияние вида случайного разбиения на результат.


Анализ результатов
​


Полученное качество можно визуализировать в виде сравнительной таблицы качества работы разных моделей или одной и той же модели, но при разных значениях гиперпараметров.


В случае кросс-валидации полезно добавлять информацию о стандартном отклонении (standard deviation) оценки, полученной по разным блокам кросс-валидации. Эта информация позволит судить о статистической значимости различий.


Информативно строить графики зависимости качества прогнозов от отдельного гиперпараметра (validation curve) и от размера обучающей выборки (learning curve), как показано ниже 
[4]
:


[IMAGE]


Подбор гиперпараметров
​


С помощью валидационной выборки или кросс-валидации подбираются наилучшие гиперпараметры модели. Чаще всего гиперпараметры модели настраивают 
полным перебором по сетке значений
 (grid search), выбирая конфигурацию, обеспечивающую максимальную точность прогнозов.


Вместо перебора по фиксированной сетке значений варианты гиперпараметров можно 
сэмплировать случайно из заданного диапазона
 (random search).


Когда случайный поиск лучше поиска по сетке?
​


Случайный перебор лучше поиска по сетке за счёт более полного перебора вариантов, если настраивается набор гиперпараметров, среди которых 
некоторые гиперпараметры слабо влияют на результат
.


Простой пример
Рассмотрим два гиперпараметра 

, среди которых первый влияет, а второй - не влияет на функцию потерь. Если вычислительный бюджет позволяет сделать только 16 оценок, то при поиске по сетке будет использоваться сетка значений 

. Заметим, что мы переберём лишь 4 уникальных значения гиперпараметра 

, а перебор по всевозможным соответствующим значениям незначимого гиперпараметра 

 будет производиться вхолостую! В случайном же поиске будут оцениваться все 16 различных значений гиперпараметра 

, что повысит полноту содержательного перебора.


Существуют и более продвинутые способы перебора гиперпараметров, обеспечивающие за минимальное число проверок более быструю сходимость к наилучшей конфигурации (см. hyperparameter optimization, 
[5]
).


Оценка качества при одновременном подборе гиперпараметров
Если по валидационной выборке или кросс-валидации производилась настройка гиперпараметров, то использовать 
те же данные для итоговой оценки качества работы модели нельзя
, так как при многократном переподборе значений гиперпараметров модель могла переобучиться, выбрав ту конфигурацию, которая хорошо работает именно на заданной валидационной выборке. Для несмещённой оценки качества подобранных гиперпараметров необходимо разбивать не на две, а на три выборки:




обучающую (на которой настраиваем параметры модели),






валидационную (на которой настраиваем гиперпараметры модели),






тестовую (на которой уже тестируем качество итогового решения).




Только оценку качества прогнозов на отдельной тестовой выборке можно считать несмещенной в результате подбора гиперпараметров, поскольку только объекты этой выборки модель увидит в первый раз. Существует и кросс-валидационный подход многократного разбиения не на две, а сразу на три подвыборки (nested cross-validation 
[6]
) для одновременного подбора гиперапаметров и оценки качества модели с наилучшими из них. Он обеспечивает более точную оценку качества при более высоких вычислительных ресурсах.


Оценка качества прогнозов для временных рядов
​


Для оценки качества прогнозирования временных рядов (последовательности наблюдений, которые поступают динамически по времени) 
нельзя использовать обычные подходы
, поскольку они приведут к случайному перемешиванию объектов во времени, и мы начнём тестировать качество прогнозов более ранних наблюдений по более поздним данным!


Поэтому для временных рядов используется оценка качества прогнозов с контролем по времени (out-of-time control), при котором усредняется качество прогнозов на один или несколько шагов вперед при всевозможных временных разбиениях на известные прошлые и неизвестные будущие наблюдения, подлежащие прогнозированию, как показано на рисунке:


[IMAGE]


Литература
​




Документация scikit-learn: модели отбора признаков и оценки.


Imbalanced-learn documentation.


Wiki: закон больших чисел.


Документация sklearn: validation curves.


Geeksforgeeks: hyperparameter optimization.


Inria: nested cross-validation.


Предыдущая страница
Обобщающая способность
Следующая страница
Этапы решения задачи машинного обучения
Валидационная выборка
Кросс-валидация
Преимущества
Недостатки
Особенности применения методов
Альтернативная итоговая модель
Случайное перемешивание
Стратифицированное разбиение
Учет случайности результатов
Анализ результатов
Подбор гиперпараметров
Когда случайный поиск лучше поиска по сетке?
Оценка качества прогнозов для временных рядов
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Этапы решения задачи машинного обучения | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Обучение с учителем
Настройка параметров модели
Выпуклость потерь
Регуляризация модели
Взвешенный учёт наблюдений
Связь с принципом максимального правдоподобия
Обобщающая способность
Оценка качества прогнозов
Этапы решения задачи машинного обучения
Обучение без учителя
Частичное обучение
Вопросы
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Основы машинного обучения
Этапы решения задачи машинного обучения
Содержание этой страницы
Этапы решения задачи машинного обучения


Процесс решения практических задач с использованием машинного обучения состоит из следующих этапов:






Понимание бизнес-проблемы.


На этом этапе мы отвечаем на следующие вопросы:






Какую задачу в конечном счете нам нужно решить?






Что дано и что необходимо найти? Для чего?










Формализация задачи.


Решаются вопросы:






Какими входными признаками мы располагаем для решения?






Какая функция потерь будет реалистично оценивать фактические потери (например, в деньгах) от тех или иных ошибок прогнозирования?










Сбор данных.


Осуществляется сбор разнородных данных из разных источников в единую базу данных.


Выбор признаков
Полезно спросить экспертов предметной области, какие данные в принципе нужны для построения прогнозов? Это даст ключ к пониманию, какие данные вам необходимо дополнительно собрать.






Предобработка данных.


На этом этапе решаются следующие проблемы:






Как заполнять пропущенные значения?






Какие объекты считать аномальными и исключать из анализа?






Как кодировать сложные неструктурированные данные (тексты, графы, изображения, видеозаписи, аудиофайлы) в виде векторов вещественных чисел? Как представить категориальные переменные в вещественном виде? Этот этап описывается в 
следующей части учебника
.










Генерация признаков.


Модель может неэффективно работать на исходных признаках. Например, линейная модель будет строить только линейные зависимости, а фактическая зависимость может быть нелинейной. Поэтому целесообразно модели помочь на этом этапе, сгенерировав нелинейные трансформации исходных признаков. Очень важно на данном этапе сгенерировать именно те признаки, которые бы действительно информативно помогали выбранной модели предсказывать ожидаемый отклик.






Отбор информативных признаков.


На этапе сбора, предобработки и генерации признаков мы, скорее всего, получим избыточный набор информации. Лишние признаки повышают вычислительные расходы и ухудшают обобщающую способность модели, приводя к переобучению: если рассеивать внимание модели на неинформативные признаки, то она может ошибочно выучить ложную закономерность.






Настройка модели.


Здесь мы выбираем несколько моделей машинного обучения, по которым настраиваем их параметры, как описано в главе о 
настройке параметров модели
.






Оценка качества модели.


Этот этап описан в разделе, посвященном 
оценке качества прогнозов моделей
.






Внедрение модели.


Включает интеграцию модели в существующую инфраструктуру, перенаправление на неё потоков данных и учёт прогнозов модели в последующих бизнес-процессах.






Поддержка модели.


Данные со временем изменяются, а закономерности в них устаревают. Поэтому важно в динамическом режиме работы отслеживать качество работы модели, чтобы периодически донастраивать её параметры и учитывать новые источники данных.






На каждом этапе возможен откат к одному из предыдущих этапов. Часто при оценке качества модели мы можем получить неудовлетворительное качество и прийти к выводу, что для лучшей точности необходимы дополнительные признаки из существующих (генерация признаков) или из новых источников (сбор данных). Даже после внедрения модели может выясниться, что модель решает немного не ту задачу, которая нужна конечным пользователям, после чего может потребоваться переосмысление бизнес-проблемы. Поэтому указанную последовательность действий правильнее рассматривать не как список, а как циклическую последовательность непрерывных улучшений, как визуализируется в методологии CRISP-DM 
[1]
:


[IMAGE]


Литература
​




Wikipedia: CRISP-DM.


Предыдущая страница
Оценка качества прогнозов
Следующая страница
Обучение без учителя
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Обучение без учителя | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Обучение с учителем
Настройка параметров модели
Выпуклость потерь
Регуляризация модели
Взвешенный учёт наблюдений
Связь с принципом максимального правдоподобия
Обобщающая способность
Оценка качества прогнозов
Этапы решения задачи машинного обучения
Обучение без учителя
Частичное обучение
Вопросы
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Основы машинного обучения
Обучение без учителя
Содержание этой страницы
Обучение без учителя


Обучение без учителя
 (unsupervised learning) в машинном обучении представляет собой задачу, в которой по вектору признаков 

 требуется предсказать некоторые отклики 

, однако обучающая выборка состоит 
только из признаковых описаний
 для набора объектов:





Поскольку разметка для объектов отсутствует, то в качестве функции потерь выступает не эмпирический риск, а некоторая вручную подобранная эвристика, характеризующая желаемый результат. При этом выбор целевой эвристики формализует свойства прогнозов, которые мы хотим получить и диктуется целевой задачей. Выбор той или иной эвристикой 
существенно влияет на результат
, иногда кардинально.


Обычно в задачах обучения без учителя прогнозы строятся только для исходной выборки, однако могут возникать задачи, где требуется применение полученной модели и для новых объектов.


Рассмотрим примеры задач обучения без учителя.


Кластеризация
​


В 
кластеризации
 (clustering) необходимо разбить объекты на группы (называемые кластерами) так, чтобы объекты, попавшие в одну группу были метрически похожими (расстояние между ними было небольшим), а объекты, попавшие в разные группы - метрически непохожими (удалёнными друг от друга). Ниже приведён пример кластеризации в двумерном признаковом пространстве 

, где первый признак отложен вдоль оси X, а второй - вдоль оси Y. Объекты обучающей выборки показаны на графике слева. Поскольку выборка не размечена, то все точки обозначены чёрным цветом. В результате применения алгоритма кластеризации (график справа) объекты разбиваются на три кластера (красный, зеленый, синий) так, что объекты из одинакового кластера похожи, а из разных - нет.


[IMAGE]


Число кластеров может быть как известно заранее, так и определяться автоматически в зависимости от алгоритма. С основными алгоритмами кластеризации и их реализациями в бибилотеке sklearn вы можете ознакомиться в 
[1]
.


Алгоритмы кластеризации используются, например, когда необходимо разбить клиентов компании на отдельные группы с похожими характеристиками. Или  распределить книги электронной библиотеки по категориям на основе сходства их содержания. Также кластеризация применяется для генерации новых признаков объектов для повышения качества решения задач обучения с учителем, например:






номер кластера, которому принадлежит объект;






расстояние от объекта до центра его кластера, измеряющее степень типичности объекта;






вектор направления изменения объекта в сторону центра его кластера (что нужно изменить в объекте, чтобы сделать его более типичным);






расстояние до ближайшего чужого кластера, отношение расстояния до своего и до ближайшего чужого кластера (насколько объект лежит на границе двух кластеров).






Обнаружение аномалий
​


Поступающие на обработку объекты имеют некоторое распределение. Большинство объектов типичны (имеют высокую вероятность, согласно распределению объектов), но некоторые объекты могут оказаться нетипичными (и иметь малую вероятность). Такие объекты лежат далеко от других объектов выборки. Выявление подобных нетипичных объектов называется 
обнаружением аномалий
 (anomaly detection) или 
детекцией выбросов
 (outlier detection).


Ниже приведён пример работы алгоритма по детекции выбросов в выборке, регулярные объекты которой помечены белым, а выбросы - красным.


[IMAGE]


Выбросы обычно получаются в результате 
ошибок измерения
. Например, операционист при вводе информации о клиенте мог вбить лишнюю цифру, либо измеряющий сенсор мог испортиться и записать неверную информацию. В таких случаях детекция выбросов представляет собой важный этап предобработки данных - перед настройкой модели важно обнаружить все выбросы и исключить их из обучающей выборки, чтобы они не привели к смещению прогнозов модели.


Однако также бывает, что 
выбросы соответствуют реально существующим объектам
 в природе, которые требуют специальной обработки. Например, если каждый объект - вектор параметров работы станка (температура, потребление электричества, число оборотов двигателя и т.д.), снимаемых каждую минуту, то наблюдение-выброс может соответствовать ситуации, когда станок выходит на нештатный и опасный режим работы (например, из-за короткого замыкания в сети, пожара, перегрузки), что чреватого поломкой. Своевременное обнаружение подобных аномалий позволит остановить работу станка досрочно, уменьшив размер ущерба, и представляет собой отдельную важную задачу.


Обучение без учителя!
Поскольку невозможно заранее описать многообразие всех ошибок измерения и типов нестандартных объектов, то получаем задачу без учителя. Если бы мы размечали объекты на типичные и нетипичные вручную и настраивали бы по этим данным классификатор, то он был бы способен детектировать 
только ту нетипичность, которая уже наблюдалась в обучающей выборке
!


Со всевозможными алгоритмами обнаружения аномалий и их реализациями в sklearn вы можете ознакомиться в 
[2]
.


Снижение размерности
​


Задача 
снижения размерности
 данных (dimensionality reduction, 
[3]
) заключается в том, чтобы представить исходные многомерные объекты 

, лежащие в многомерном пространстве 

 , в маломерные векторы 

 из пространства 

, где 

. Это отображение должно сохранять геометрические свойства исходных объектов:






если исходные объекты 

 были близки, то и их образы 

 также должны быть близки






если 

 были далеки, то и их образы 

 тоже должны быть далеки друг от друга.






По сути, снижение размерности переводит исходные, возможно, избыточные признаковые представления объектов в новые компактные признаковые представления без дублирования информации. Пример снижения размерности из трёхмерного в двумерное пространство приведён ниже, где цвет обозначает множества похожих объектов (изначально не задан):


[IMAGE]


Поиск ассоциативных правил
​


Часто входные данные представляют собой наборы элементов. Например, в магазине покупатели чаще всего покупают не один товар, а  целый набор товаров, пробитых в одном чеке. Примеры совместно купленных товаров показаны в таблице:


номер чека
набор купленных товаров
1
хлеб, сыр, масло
2
ветчина, масло, хлеб
3
кофе, печенье, сливки
4
хлеб, бекон, джем
5
чай, кофе, сливки, сахар
6
масло, яйца, хлеб
7
кофе, конфеты, сливки


Анализируя чеки, можно автоматически искать множества совместно покупаемых товаров и извлекать правила вида:






если покупатель купил хлеб, то, скорее всего, он купит и молоко;






если покупатель купил кофе, то, скорее всего, он купит сливки.






Условие срабатывания правила, а также предсказываемый правилом результат могут состоять и из нескольких товаров.


Автоматическое извлечение подобных правил из наблюдаемых наборов элементов называется 
поиском ассоциативных правил
 (association rule mining, 
[4]
). Наборы элементов могут быть как неупорядоченными множествами (при анализе чеков в магазине), так и упорядоченными - например, при анализе последовательности посещённых веб-страниц на веб-сайте.


В целом о задачах обучения без учителя можно дополнительно прочитать в 
[5]
.


Литература
​




Sklearn: clustering
.


Sklearn: outlier detection.


Wikipedia: dimensionality reduction.


Wikipedia: association rule learning.


Geeksforgeeks: unsupervised learning.


Предыдущая страница
Этапы решения задачи машинного обучения
Следующая страница
Частичное обучение
Кластеризация
Обнаружение аномалий
Снижение размерности
Поиск ассоциативных правил
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Частичное обучение | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Обучение с учителем
Настройка параметров модели
Выпуклость потерь
Регуляризация модели
Взвешенный учёт наблюдений
Связь с принципом максимального правдоподобия
Обобщающая способность
Оценка качества прогнозов
Этапы решения задачи машинного обучения
Обучение без учителя
Частичное обучение
Вопросы
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Основы машинного обучения
Частичное обучение
Содержание этой страницы
Частичное обучение


Частичное обучение
 (semi-supervised learning) представляет собой промежуточный случай между 
обучением с учителем
 (в котором все объекты обучающей выборки размечены) и 
обучением без учителя
 (в которой ни один объект не размечен). В частичном обучении 
часть объектов имеют разметку, а часть - нет
, поэтому обучающая выборка имеет следующий вид:





Такая постановка задачи весьма типична, поскольку часто не составляет труда собрать большие наборы неразмеченных данных (изображений, текстов, видео в интернете), однако их корректная разметка требует человеческого труда, поэтому разметить мы можем далеко не все собранные объекты.


Упрощенный пример частичного обучения приведён ниже на графике слева для задачи бинарной классификации двумерных объектов, обозначенных квадратами. Изначально в выборке размечено всего два квадрата (в синий и красный класс). Лучшее, что мы можем сделать, 
используя только размеченные данные
 - это разделить пространство признаков прямой, равноудалённой от этих двух точек. Однако если мы будем использовать знание о распределении неразмеченных объектов (две концентрических окружности) и предположение о том, что близкие объекты принадлежат одинаковому классу, то мы сможем существенно расширить множество размеченных объектов (график справа), из которого уже естественнее провести границу между классами в форме окружности.


[IMAGE]


Методы частичного обучения используют предположение о том, что похожие (метрически близкие) объекты должны принадлежать одинаковому классу. Это всего лишь предположение, которое 
может быть и не выполнено
. Тут многое зависит от признаков, которыми мы описываем объекты, а также от функции расстояния, по которой считаем близость. Для верификации предположения необходима проверка на отдельной валидационной выборке!


:::


При правильно подобранном признаковом описании объектов и функции вычисления расстояния методы частичного обучения дают эффект, когда число размеченных объектов мало, а неразмеченных - велико. Если же размеченных объектов и так много, то потенциальный эффект от их использования будет минимальным и лучше использовать классическое обучение с учителем.


Трансдуктивное обучение
Задача 
трансдуктивного обучения
 (transductive learning), в которой заранее известны признаковые описания объектов тестовой выборки (на которой мы хотим применить нашу модель), представляет собой частный случай частичного обучения и к ней могут быть применены такие же подходы.


Дополнительно о методах обучения без учителя можно прочитать в 
[1]
.


Литература
​




Geeksforgeeks: semi-supervised learning in ML.


Предыдущая страница
Обучение без учителя
Следующая страница
Вопросы
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Вопросы для самопроверки | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Обучение с учителем
Настройка параметров модели
Выпуклость потерь
Регуляризация модели
Взвешенный учёт наблюдений
Связь с принципом максимального правдоподобия
Обобщающая способность
Оценка качества прогнозов
Этапы решения задачи машинного обучения
Обучение без учителя
Частичное обучение
Вопросы
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Основы машинного обучения
Вопросы
Вопросы для самопроверки




Чем задача регрессии отличается от задачи классификации?


Какое число уникальных значений целевой переменной может быть в задаче разметки (labeling) на 

 классов?


Объясните, почему в среднем эмпирический риск на обучающей выборке будет меньше, чем на тестовой?


Чем обучение с учителем отличается от обучения без учителя?


Чем отличаются параметры модели от гиперпараметров?


Объясните, зачем нужна L2 регуляризация? Её целесообразнее применять для недообученных или переобученных моделей?


Рассмотрим задачу классификации, в которой наблюдений первого класса существенно больше, чем второго. При взвешенном учёте каждого объекта вес учёта объектов второго класса при расчёте функции потерь должен быть больше или меньше, чем вес объектов первого класса? Почему?


Для чего используется кросс-валидация? Какие у неё преимущества и недостатки по сравнению с использованием отдельной валидационной выборки?


В чём заключается основное предположение методов частичного обучения? Всегда ли оно выполняется на практике?


Предыдущая страница
Частичное обучение
Следующая страница
Подготовка данных
© 2023-25 
Виктор Китов.
 
Новости проекта.









Фильтрация выбросов | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Фильтрация выбросов
Заполнение пропусков
Обработка временного признака
Обработка категориальных признаков
Нормализация признаков
Генерация признаков
Сокращение числа признаков
Преобразование целевой переменной
Вопросы
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Подготовка данных
Фильтрация выбросов
Содержание этой страницы
Фильтрация выбросов


Обучающая выборка может содержать как типичные, так и нетипичные объекты, называемые 
выбросами
 (outliers) и 
аномалиями
 (anomaly). Выбросы, как правило, лежат далеко от основного распределения объектов и способны существенно ухудшить настройку модели. Выбросами могут выступать:






Измерения, произведённые с ошибкой. Например, операционист неверно занес данные в компьютер.






Верно измеренные объекты, но нетипичные по своей сути и требующие отдельной обработки. Например, в мониторинге логов на сайте выбросам могут соответствовать активность не реальных пользователей, а ботов.






Чтобы настроить модель устойчивее обрабатывать именно типичные случаи, необходимо провести предварительную 
фильтрацию выбросов
 (outlier detection). Существуют отдельный класс методов, позволяющий идентифицировать объекты-выбросы сразу по всему вектору признаков, см. 
[1]
. Однако для первичной обработки может использоваться и простой анализ распределений каждого признака в отдельности с идентификацией аномально больших и аномально малых значений.


Детальнее о задаче фильтрации выбросов можно прочитать в 
[2]
. Простые программные способы обрезки аномальных значений в отдельных признаках описаны в документации библиотеки 
feature-engine
 
[3]
.


Литература
​






Документация scikit-learn: outlier_detection.






Geeksforgeeks: what is anomaly detection?






Документация feature-engine: outliers.




Предыдущая страница
Подготовка данных
Следующая страница
Заполнение пропусков
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Заполнение пропусков в данных | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Фильтрация выбросов
Заполнение пропусков
Обработка временного признака
Обработка категориальных признаков
Нормализация признаков
Генерация признаков
Сокращение числа признаков
Преобразование целевой переменной
Вопросы
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Подготовка данных
Заполнение пропусков
Содержание этой страницы
Заполнение пропусков в данных


Когда мы измеряем признаки объектов, некоторые из признаков могут отсутствовать. В этом случае вектор признаков будет содержать пропуски (missing values). Например, если объект описывает человека по данным заполняемой анкеты, то человек мог не заполнять отдельные поля или сделать это неразборчиво. При этом большинство моделей машинного обучения требуют для обработки 
полный вектор признаков без пропусков
.


Простейшим выходом при работе с пропусками могло бы быть исключение всех объектов, у которых хотя бы один из признаков не указан. Этот приём подходит, если число объектов с пропущенными значениями невелико относительно общего объема выборки. Если же таких объектов много, то нужно выработать 
метод заполнения пропущенных значений
 (missing data imputation). Рассмотрим популярные методы для различных типов данных.


Пропуски в категориальных и бинарных признаках
​


Для категориальных признаков, принмающих одно из 

 дискретных значений, таких как марка машины, профессия и город проживания человека пропуски можно заполнять:






максимально частой категорией (в статистике это называется 
модой распределения
, mode imputation)






новой категорией [пропуск]






Второй способ, очевидно, лучше, когда число категорий велико, и нет оснований во всех неопределённых случаях предпочитать самую частую категорию.


Более продвинутая техника заключается в предсказании пропущенной категории отдельным классификатором, обученным предсказывать значение признака с пропусками по оставшимся известным признакам. Это позволит заполнять значения не константой, а переменной величиной в зависимости от других характеристик объекта. Например, если человек не указал город проживания, но указал место  работы, то его местоположение можно восстановить с некоторой точностью.


Пропуски в вещественных признаках
​


Для вещественных признаков пропуски можно заполнять






выборочным средним 
[1]
,






выборочной медианой 
[2]
.






Выборочные статистики считаются по присутствующим значениям признака в других объектах. Медиана более предпочтительна, поскольку является мерой оценки центра распределения, устойчивой к наличию выбросов (robust to outliers), в отличие от среднего.


Задача
Оцените, насколько сильно может сместиться среднее и медиана при внесении одного очень большого или очень малого наблюдения в выборку.


Часто, однако, признаки неправильно заполнять значением "в среднем", поскольку сам факт того, что значение пропущено, может говорить о 
нестандартности реального значения признака
. Например, человек мог не указать величину своей зарплаты, если ему кажется, что она слишком маленькая или, наоборот, слишком большая. Для таких ситуаций нужно предсказывать значение пропущенного признака по другим признакам, решая задачу регрессии. Либо просто подставлять условное среднее или медиану при условии другого известного признака, связанного с рассматриваемым.


Индикатор пропуска
Можно создать дополнительный бинарный признак, характеризующий, было ли значение первоначального признака известно заранее или было пропущено с последующим заполнением. Это позволит модели машинного обучения различать эти две ситуации и относиться к автоматически заполненному значению признака 
с большим недоверием
.
При заполнении условной модой/средним/медианой можно также генерировать признак условного стандартного отклонения, чтобы подсказать модели, с каким уровнем неопределённости признак был предсказан.


Программные способы заполнения пропущенных значений в данных представлены в библиотеках 
pandas
 
[3]
, 
sklearn
 
[4]
 и 
feature-engine
 
[5]


Литература
​






Wikipedia: arithmetic mean.






Wikipedia: median.






Документация pandas: missing data.






Документация scikit-learn: восстановление пропущенных значений.






Документация feature-engine: imputation.




Предыдущая страница
Фильтрация выбросов
Следующая страница
Обработка временного признака
Пропуски в категориальных и бинарных признаках
Пропуски в вещественных признаках
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Обработка временного признака | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Фильтрация выбросов
Заполнение пропусков
Обработка временного признака
Обработка категориальных признаков
Нормализация признаков
Генерация признаков
Сокращение числа признаков
Преобразование целевой переменной
Вопросы
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Подготовка данных
Обработка временного признака
Содержание этой страницы
Обработка временного признака


Временной признак
​


Часто одним из признаков является 
время наблюдения
 для заданного объекта. Например, в задаче прогноза числа арендованных велосипедов для разных дней, вектор признаков будет включать не только погоду, температуру и другие характеристики, но и 
дату наблюдения
.


Для эффективного использования временного признака рекомендуется его заменить на новый признак, равный 
числу дней с начала наблюдений
, т.е. с минимального значения этого признака среди всех объектов. Если известна не только дата, но и время, этот признак можно закодировать как 
число секунд с начала измерений
.


Тренд
​


Предложенный признак позволит учесть 
временной тренд
. В случае задачи предсказания числа арендованных велосипедов он может состоять в том, что спрос рос со временем за счёт роста популярности недорогих и экологичных видов транспорта.


Сезонность
​


Сезонность - это периодическая зависимость целевой величины от времени.


В нашем примере отклик имеет выраженную сезонность, поскольку ожидаемое число арендованных велосипедов зависит от дня недели, а также различается в оразные времена года. Для учёта сезонности полезно извлечь дополнительные категориальные признаки, характеризующие 
месяц и день недели
. Также полезно извлечь признаки характеризующие 
праздничные дни
. Если известна не только дата, но и время, то можно учитывать и внутридневную сезонность, извлекая такой категориальный признак, как номер часа.


Ниже приведены модели, не учитывающие и учитывающие информацию, извлечённую из временного признака:


[IMAGE]


Вы можете дополнительно ознакомиться с примером прогнозирования временных рядов с учётом тренда и сезонности в 
[1]
.


Дополнительные признаки
При прогнозировании временных рядов очень информативно использовать ранее наблюдавшиеся (лагированные) значения целевой величины с задержкой во времени. При этом можно использовать несколько значений для задержки, привязанной к сезонности. Например, при прогнозировании спроса на велосипеды можно использовать наблюдавшийся спрос неделю/год назад. Помимо использования лагированных значений непосредственной величины, которую прогнозируем (например, спрос в Зеленограде), полезно также использовать лагированные агрегаты этой величины (спрос по московской области/России в целом).


Детальнее о прогнозировании и аналитике временных рядов вы можете прочитать в учебнике ШАД от Яндекса 
[2]
 и 
[3]
.


Литература
​




Medium: time series analysis.


Учебник ШАД: временные ряды.


Учебник ШАД: аналитика временных рядов.


Предыдущая страница
Заполнение пропусков
Следующая страница
Обработка категориальных признаков
Временной признак
Тренд
Сезонность
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Обработка категориальных признаков | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Фильтрация выбросов
Заполнение пропусков
Обработка временного признака
Обработка категориальных признаков
Нормализация признаков
Генерация признаков
Сокращение числа признаков
Преобразование целевой переменной
Вопросы
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Подготовка данных
Обработка категориальных признаков
Содержание этой страницы
Обработка категориальных признаков


Категориальные признаки
 (categorical features) - это признаки, принимающие одно из 

 дискретных значений, такие как профессия человека или город, в котором он родился. Такие признаки очень часто встречаются на практике. Частным случаем категориальных признаков являются 
бинарные признаки
 (binary features), принимающие всего два значения, такие как семейное положение человека или индикатор, были ли у человека просрочки по кредитам.


Модель машинного обучения ожидает на входе вектор, состоящий только из вещественных признаков. Если бинарный признак мы можем представить в вещественном виде, закодировав категории цифрами 0 и 1, то в случае признака, описывающего несколько категорий, возможны различные варианты кодировок, которые мы рассмотрим далее.


Порядковое кодирование
​


В 
порядковом кодировании
 (ordinal encoding) категория заменяется её номером. Рассмотрим кодировку признака [профессия]. Пусть для простоты она принимает всего 4 возможных значения: программист, художник, дизайнер и системный администратор. В порядковом кодировании мы заменяем профессии их номерами:


значение
номер
программист
0
художник
1
дизайнер
2
системный администратор
3


Этот вид кодирования 
не рекомендуется применять на практике
, поскольку метод машинного обучения впоследствии будет считать, что движение в направлении 0,1,2,3 будет соответствовать возрастанию какой-то реально существующей характеристики, которой в действительности нет, поскольку 
нумерация была произвольной
. Также в нашем примере метод на основе близости численных значений будет считать, что программист ближе по смыслу к художнику, чем к системному администратору, что в действительности не так.


Кодирование частотами
​


При 
частотном кодировании
 (frequency encoding) значение каждой категории заменяется на частоту встречаемости этой категории. Пусть, например, у нас 7 человек, среди которых два программиста, три системных администратора, один дизайнер и художник. Для этого случая частотное кодирование будет выглядеть так:


значение
кодировка
программист
2/7
системный администратор
3/7
системный администратор
3/7
дизайнер
1/7
художник
1/7
системный администратор
3/7
программист
2/7


Обратим внимание, что кодирование неоднозначно для дизайнера и художника, которые встретились одинаковое число раз.




Полезность кодировки определяется тем, насколько частота встречаемости категорий связана с целевой переменной.




One-hot кодирование
​


При 
one-hot кодировании
 (one-hot encoding, dummy encoding). Вначале все категории нумеруются произвольным образом. Каждый категориальный признак, принимающий значение i-й категории среди 

 возможных, кодируется 

-мерным вектором из нулей, где на одной только i-й позиции стоит единица.


Пример соответствия категорий кодировкам:


направление
кодировка
север
[0,0,0,1]
юг
[0,0,1,0]
восток
[0,1,0,0]
запад
[1,0,0,0]


Пример применения кодировки к данным:


направление
кодировка
север
[0,0,0,1]
север
[0,0,0,1]
запад
[1,0,0,0]
восток
[0,1,0,0]
север
[0,0,0,1]


Метод однозначно кодирует категорию и, в отличие от предыдущих методов, производит сопоставление одному категориальному признаку сразу набор бинарных признаков (по числу категорий). Все категории, независимо от порядка кодирования,  получаются равнозначными: попарное расстояние между кодировками любой пары категорий получается одним и тем же.


One-hot кодирование - самый популярный способ представления категориальных признаков, однако у него есть недостаток, что при слишком большом числе категорий он приводит к сильному разрастанию числа признаков. Например, если категория - это город, то, поскольку городов очень много, число признаков значительно увеличивается, что приводит к сильному увеличению параметров модели машинного обучения, ухудшая её настройку. Одним из способов борьбы с этим является объединение различных родственных категорий в одну. Например, вместо указания города можно указывать область, в которой этот город находится. Если же не хочется  терять детализации, то можно использовать усиленную 
регуляризацию
 модели.


Эмбеддинги
Представление определённой дискретной сущности (например, категории в категориальном признаке) вектором вещественных чисел называется 
эмбеддингом
 (embedding). One-hot кодирование приводит к слишком длинному вектору, если число категорий велико. Вместе с этим понятно, что если использовать не только значения 0/1, а весь спектр вещественных чисел, то можно даже большое число категорий однозначно закодировать компактным вектором эмбеддинга. Эмбеддинги можно сэмплировать случайно, при этом желательно обеспечивать одинаковое попарное расстояние между эмбеддингами разных категорий. Или генерировать эмбеддинги так, чтобы расстояние между эмбеддингами оказывалось более близким для более близких категорий по смыслу (например, работа программиста более близка к работе системного администратора, а работа художника - к работе дизайнера, поэтому и соответствующие эмбеддинги должны быть ближе). Существуют продвинутые методы автоматической генерации эмбеддингов, о которых можно прочитать, например, в статье 
[1]
.


Кодирование средним
​


Кодирование средним
 (mean encoding, target encoding) - компактный и максимально информативный способ кодирования категориального признака путём замены каждой категории на среднее прогнозируемого отклика 
при условии этой категории
.


Приведём пример для регрессии, когда по профессии необходимо предсказать зарплату:


признак (профессия)
отклик
кодирование признака
программист
300
350
системный администратор
250
200
системный администратор
200
200
дизайнер
220
200
художник
150
150
дизайнер
180
200
программист
400
350
системный администратор
150
200


А ниже показан пример кодирования средним для классификации, когда по профессии предсказываем, вернёт человек кредит или нет:


признак (профессия)
отклик
кодирование признака
программист
1
1
системный администратор
1
2/3
системный администратор
0
2/3
дизайнер
1
1/2
художник
0
0
дизайнер
0
1/2
программист
1
1
системный администратор
1
2/3


Как видим, для регрессии и бинарной классификации один столбец исходного признака заменяется на один столбец условных средних. В случае многоклассовой классификации каждая категория будет заменяться на 
вектор условных частот каждого из классов
 при условии категории.


Представленный способ кодирования максимально информативен для решения итоговой задачи предсказания отклика по кодировке, поскольку кодировка в явном виде агрегирует информацию об отклике.


Переобучение
Кодирование признака агрегацией по отклику 
приводит к переобучению
, поскольку мы через признак явно передаём информацию об ожидаемом ответе, пусть и в усреднённом виде. Для категорий, которые встретились единожды ("художник" в  примере) мы перенесли отклик в признак в явном виде! Получается, мы решаем нечестную задачу, поскольку сообщаем модели информацию об ожидаемом отклике, которую она не должна знать.
Чтобы избежать переобучения и сделать прогнозы честными, можно выделить отдельную обучающую выборку на кодирование средним только по ней, а потом перенести вычисленное соответствие категорий средним откликам в основную обучающую выборку, по которой уже будем настраивать модель.
Более эффективный способ с точки зрения переиспользования данных - для каждого объекта подставлять вместо категории условное среднее отклика по всем объектам 
кроме рассматриваемого
 (
leave one out encoding
).


Варианты метода
Вместо каждой категории можно подставлять условное среднее по другому вещественному или бинарному признаку. Такое кодирование не приводит к подглядыванию в неизвестный отклик, поэтому для него не нужна отдельная выборка для кодировки.
Также вместо среднего значения при условии каждой категории можно подставлять условную медиану, максимум, минимум или стандартное отклонение - в зависимости от задачи.


Кодирование циклических переменных
​


Циклическое кодирование
 (cyclic encoding) применяется для кодирования категориальных переменных, принимающих циклические значения, такие как час в сутках и день месяца. В этих случаях существует естественный порядок на значениях.


Например, час в сутках принимает значения 0,1,2,3,...22,23. За счёт вещественного представления часа в сутках удаётся передать модели, что соседние часы близки, а дальние - далеки, что сделает зависимость от часа дня более плавной. При этом необходимо учесть, что, в силу цикличности, час 23 близок к нулевому часу.


Моделировать такие виды близости можно с помощью 
циклического кодирования
, при котором признак 

 кодируется парой вещественных значений:





Поскольку 

 - непрерывные функции, то такое представление для близких значений 

 и 

 будет выдавать близкие кодировки, а дополнительно удастся сообщить модели, что 23 часа близко к часу ночи, а 31 число близко к первому! Эффект достигается за счёт свойств периодичности синуса и косинуса:


[IMAGE]


Какую кодировку использовать?
Конечный вид кодировки подбирается методом проб и ошибок и в конечном счете определяется тем, какой из них будет приводить к более точным прогнозам. Можно кодировать категориальный признак и сразу несколькими способами!


Обзор различных видов кодирования категориальных признаков можно прочитать в 
[2]
, а в 
[3]
 приводятся сравнительные эксперименты по эффективности кодирования признаков разными способами.


Программные реализации кодирования признаков библиотек sklearn и feature_engine описаны в 
[4]
 и 
[5]
.


Литература
​






А.Г. Дьяконов. Методы решения задач классификации с категориальными признаками.






Medium: categorical data encoding techniques.






Pargent F. et al. Regularized target encoding outperforms traditional methods in supervised machine learning with high cardinality features //Computational Statistics. – 2022. – Т. 37. – №. 5. – С. 2671-2692.






Документация scikit-learn: preprocessing.






Документация feature-engine: categorical encoding.




Предыдущая страница
Обработка временного признака
Следующая страница
Нормализация признаков
Порядковое кодирование
Кодирование частотами
One-hot кодирование
Кодирование средним
Кодирование циклических переменных
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Нормализация признаков | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Фильтрация выбросов
Заполнение пропусков
Обработка временного признака
Обработка категориальных признаков
Нормализация признаков
Генерация признаков
Сокращение числа признаков
Преобразование целевой переменной
Вопросы
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Подготовка данных
Нормализация признаков
Содержание этой страницы
Нормализация признаков


Входные признаки в большинстве случаев будут иметь разный масштаб (диапазон изменения значений признака): одни признаки могут изменяться в диапазоне 

, другие - в 

 и т.д. Как мы впоследствии увидим из описаний методов машинного обучения, 
для большинства из них
 масштаб признаков будет оказывать влияние на прогноз. Для таких моделей чем выше разброс значений признака, тем сильнее он будет влиять на прогноз, перекрывая влияние признаков меньшего масштаба.


Рассмотрим в качестве примера классификацию методом ближайшего соседа (nearest neighbor), который для каждого объекта 

 назначает тот класс, к которому принадлежит ближайший к нему объект 
из обучающей выборки
. Для простоты рассмотрим классификацию на 2 класса (зелёный и красный) в двумерном пространстве признаков. Обучающая выборка состоит из двух объектов и требуется построить прогноз для точки в начале координат.


Исходная обучающая выборка приведена на рисунке слева:


[IMAGE]


Как видим, обучающие объекты равноудалены от точки, для которой требуется сделать прогноз, поэтому оба класса равновероятны. Если мы умножим первый признак на два 

, то прогнозом станет красный класс, как более близкий (в центре изображения). А если умножим на два второй признак 

, то прогнозом будет уже зелёный класс (справа)!


Чем выше разброс вдоль определённого признака, тем сильнее он влияет на прогноз, поэтому, чтобы влияние всех признаков было одинаковым, их необходимо 
нормализовать
, то есть привести к одному масштабу. Наиболее распространены следующие способы:


Название
Преобразование
Выходные свойства
Стандартизация

нулевое среднее и единичная дисперсия
Диапазонное шкалирование

принадлежит интервалу [0,1]
Нормализация средним

нулевое среднее, с единичным диапазоном


Каждый вид шкалирования применяется к каждому признаку (столбцу в матрице объекты-признаки X) 
независимо
.


Самым популярным методом нормализации признака является 
стандартизация признака
 (standardization, standard scaler). Вторым по популярности является 
диапазонное шкалирование
 (min-max scaler). Оно хорошо тем, что значения признака из отрезка [0,MAX] переводятся в отрезок [0,1], причём ноль переходит в ноль, что полезно для 
разреженных данных
 (sparse data), в которых большинство значений - нули. Такие данные часто возникают на практике и эффективно кодируются разреженными матрицами (sparse matrix, 
[1]
), которые экономично их хранят и производят операции над ними, оперируя только ненулевыми элементами. Диапазонное шкалирование 
позволяет сохранить свойство разреженности
.


Влияние выбросов
​


Наличие выбросов (аномально больших или малых значений) искажает результат нормализации, так наличие даже одного выброса может существенно сместить среднее, дисперсию, минимум или максимум. Поэтому важно 
предварительно отфильтровать выбросы из выборки
. Альтернативно можно заменить неустойчивые к выбросам статистики на устойчивые по схеме ниже:


неустойчивая статистика
робастный аналог
значение


центр распределения


разброс распределения

 

1% перцентиль
минимум

99% перцентиль
максимум


Медиана
​


Медиана
 (median) - величина, альтернативная 
выборочному среднему
 (mean) для оценки центра распределения. Для выборки значений признака медиана - это такое значение, что половина наблюдений оказываются меньше, а другая половина - больше этого значения. Для вероятностного распределения медиана - это такое значение, что половина вероятностной массы лежит слева, а другая половина - справа от значения медианы.


[IMAGE]


p-процентная перцентиль
​



-процентная перцентиль (percentile) - это такое значение, что






для выборки наблюдений 

 
процентов
 наблюдений лежит слева, а 

 процентов - справа от значения.






для вероятностного распределения признак с вероятностью 

 принимает значение меньше, а с вероятностью 

 - больше значения перцентили.






Как видно, 

-квантиль соответствует 

-процентной перцентили.


Литература
​




Python-school: введение в разреженные матрицы.


Предыдущая страница
Обработка категориальных признаков
Следующая страница
Генерация признаков
Влияние выбросов
Медиана
p-процентная перцентиль
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Генерация признаков | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Фильтрация выбросов
Заполнение пропусков
Обработка временного признака
Обработка категориальных признаков
Нормализация признаков
Генерация признаков
Сокращение числа признаков
Преобразование целевой переменной
Вопросы
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Подготовка данных
Генерация признаков
Содержание этой страницы
Генерация признаков


Исходных признаков может оказаться недостаточно для построения точной модели. Например, линейные методы моделируют только линейные зависимости отклика от признаков, а реальная зависимость может быть нелинейной, поэтому модель будет работать неточно. Для повышения точности моделей 
генерируют новые признаки
 из существующих (feature engineering). Признаки желательно генерировать так, чтобы они как можно точнее соответствовали фрагментам реальной зависимости в данных, из которых модель уже соберёт итоговое решение. Например, в задаче автоматической оценки стоимости земельного участка нам может быть известна его длина и ширина. Логично сгенерировать новый признак, равный их произведению и соответствующий площади участка.


Подходы для генерации новых признаков
​






Можно генерировать признаки, соответствующие интерпретируемым характеристикам, влияющим на отклик. Зная, например, длину и ширину участка, можно взять их произведение, что будет соответствовать его площади. При  оценке квартир это может быть отношение жилой площади к числу комнат, чтобы определить средний размер каждой комнаты и т.д. Можно использовать признаки, исходящие из общей логики, например, предварительно кластеризовать все объекты и в качестве дополнительного признака подставлять номер класса, в который попал объект. При работе с людьми по их возрасту можно сгенерировать три бинарных признака





Это позволит линейной модели по-разному обрабатывать несовершеннолетних, работающих людей и пенсионеров. Чаще границы отрезков дискретизации не подбирают вручную, а разбивают на равномерные отрезки. Такие алгоритмы, как 
решающие деревья
, способны самостоятельно извлекать подобные признаки, но им сложно аппроксимировать линейные комбинации над признаками, поэтому им на вход можно подавать эти комбинации в явном виде как разности и суммы исходных признаков. 
Метрические алгоритмы
 предсказывают отклик только на основе попарных расстояний между объектами. Поэтому им может подойти расширение числа признаков как их разумной дискретизацией, так и линейными комбинациями над признаками. В свою очередь, линейным моделям и решающим деревьям можно дополнительно подавать на вход расстояния от каждого объекта до некоторого набора характерных объектов выборки (эталонов). Например, это может быть расстояние до центров кластеров при предварительной 
кластеризации
 объектов.






В качестве признаков модели могут выступать даже прогнозы других моделей. Тогда итоговая модель будет учиться агрегировать прогнозы этих моделей наилучшим образом и будет называться 
ансамблем
 или 
композицией моделей
 (model ensemble). Чтобы избежать переобучения за счёт повторного переиспользования информации об откликах, базовые и агрегирующая разных модель должны обучаться на разных выборках, что реализуется в 
блендинге и стэкинге
.






Больше не всегда означает лучше!
Увеличение числа признаков повышает вероятность настроиться на 
ложную зависимость
 (false dependency) между одним из признаков и откликом, которая будет соответствовать не реальной зависимости, а случайному совпадению в данных. Например, если зафиксировать вектор откликов и по нему сгенерировать очень много случайных признаков из равномерного распределения, то некоторые из них, в силу случайности, окажутся сильно скоррелироваными с целевой величиной! Но это будет ложная зависимость, поскольку, в силу случайности, нельзя будет рассчитывать на подобную скоррелированность на новых тестовых данных.


Обзор частых приёмов генерации новых признаков с кодом реализации можно прочитать в 
[1]
.


Литература
​




Kaggle: a reference guide to feature engineering methods.


Предыдущая страница
Нормализация признаков
Следующая страница
Сокращение числа признаков
Подходы для генерации новых признаков
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Сокращение числа признаков | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Фильтрация выбросов
Заполнение пропусков
Обработка временного признака
Обработка категориальных признаков
Нормализация признаков
Генерация признаков
Сокращение числа признаков
Преобразование целевой переменной
Вопросы
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Подготовка данных
Сокращение числа признаков
Содержание этой страницы
Сокращение числа признаков


Исходных признаков может быть слишком много в силу избыточного сбора даже слабоинформативных данных. Либо могло появиться много новых признаков после их генерации из существующих.


Почему больше не всегда лучше?
Число оцениваемых параметров модели растет с увеличением числа признаков. Например, линейные модели прогнозируют отклик, отталкиваясь от линейной комбинации признаков с оцениваемыми весами. Чем больше признаков, тем больше весов нужно оценить. При ограниченной обучающей выборке это будет приводить к неточной оценке коэффициентов и переобучению модели. Увеличение числа признаков также увеличивает накладные расходы на хранение и обработку данных.


Поэтому, если число входных признаков велико, то их количество сокращают, что может осуществляться






методами отбора признаков (feature selection);






методами снижения размерности (dimensionality reduction).






Различие подходов графически показано ниже:


[IMAGE]


При отборе признаков используется 
подмножество из исходных признаков
, а остальные просто отбрасываются. При снижении размерности каждый выходной признак получается некоторым преобразованием 
над всеми исходными признаками
.


Существует много методов отбора признаков. Многие из них описаны в 
[1]
. Например, можно выбрать подмножество признаков, которые сильнее всего скоррелированы с откликом. А в качестве снижения размерности часто используется 
метод главных компонент
 (principal component analysis, PCA), который линейной трансформацией переводит объекты из многомерного признакового пространства в маломерное таким образом, чтобы сумма квадратов расстояний от исходных объектов до их проекций оказывалась наименьшей, как показано ниже (при переводе объектов из трёхмерного признакового пространства в двумерное):


[IMAGE]


Теоретические основы метода и способ реализации можно прочитать в 
[2]
.


Литература
​






Документация sklearn: feature selection.






Вики-конспекты ИТМО: метод главных компонент.




Предыдущая страница
Генерация признаков
Следующая страница
Преобразование целевой переменной
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Преобразование целевой переменной | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Фильтрация выбросов
Заполнение пропусков
Обработка временного признака
Обработка категориальных признаков
Нормализация признаков
Генерация признаков
Сокращение числа признаков
Преобразование целевой переменной
Вопросы
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Подготовка данных
Преобразование целевой переменной
Содержание этой страницы
Преобразование целевой переменной


Помимо предобработки признаков можно анализировать и обрабатывать и 
саму целевую переменную
 

. Например, удалять объекты, у которых отклик получился аномально большим или малым. Аномальные отклики могут быть вызваны ошибками в измерениях или нетипичными случаями, удаление которых повысит стабильность настройки модели.


Также часто проще что проще прогнозировать не исходный отклик 

, а 
некоторую его преобразованную версию
 

. Например, при построении линейной регрессии может выясниться, что признаки и отклик связаны не линейно, а по экспоненциальному закону.


Тогда нужно нелинейно преобразовывать целевую переменную:





после чего 
обучать модель
 на выборке





После применения модели
 её прогнозы нужно возвращать в исходную шкалу изменения отклика:





где 

 - обратная функция к 

.


Для откликов, принимающих только положительные значения, популярным преобразованием является логарифмирование и последующее экспоненцирование:





Более общий способ
: подобрать такое преобразование целевой переменной, при котором отклик становится распределённым по 
нормальному закону распределения
.


Если 

 - 
функция распределения
 

, а 

 - функция распределения стандартного нормального распределения, то преобразование 

 будет монотонным, а преобразованный таким образом отклик - нормально распределённым со средним 0 и дисперсией 1. Такое преобразование реализовано в библиотеке sklearn 
[1]
.


Литература
​




Sklearn: TransformedTargetRegressor.


Предыдущая страница
Сокращение числа признаков
Следующая страница
Вопросы
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Вопросы для самопроверки | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Фильтрация выбросов
Заполнение пропусков
Обработка временного признака
Обработка категориальных признаков
Нормализация признаков
Генерация признаков
Сокращение числа признаков
Преобразование целевой переменной
Вопросы
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Подготовка данных
Вопросы
Вопросы для самопроверки




Расскажите про методы заполнения пропусков в данных. Когда стоит использовать заполнение глобальным средним, а когда - условным (при условии другого известного признака)?


Какие есть сравнительные преимущества и недостатки у кодирования средним и one-hot кодирования при кодировании категориальных признаков?


Как вы думаете, зачем в циклическом кодировании используется пара из синуса и косинуса? Почему не ограничиваются одной из этих периодических функций?


Какими выходными свойствами будет обладать нормализованный признак после его нормализации посредством стандартизации, диапазонного шкалирования и нормализации средним?


Квантилю и персентилю с каким уровнем будет соответствовать медиана распределения?


Почему медиана, как оценка центра вероятностного распределения, будет обладать устойчивостью к выбросам?


Пусть перед вами стоит задача снижения размерности признакового пространства. В каких случаях снижение размерности следует предпочесть отбору признаков?


Предыдущая страница
Преобразование целевой переменной
Следующая страница
Классификаторы в общем виде
© 2023-25 
Виктор Китов.
 
Новости проекта.









Общий вид прогнозирующих функций | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Общий вид прогнозирующих функций
Отступ классификации
Предсказание вероятностей и преобразование SoftMax
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Классификаторы в общем виде
Общий вид прогнозирующих функций
Содержание этой страницы
Общий вид прогнозирующих функций


Регрессия в общем виде
​


Регрессионная зависимость (в которой откликом является вещественное число) в общем виде записывается в виде некоторой функции, параметризованной вектором параметров 

:





Многоклассовый классификатор в общем виде
​


В многоклассовой классификации отклик принимает одно из 

 дискретных значений:





Соответственно, каждый многоклассовый классификатор определяет внутри себя 

 
дискриминантных функций
 (discriminant functions) или 
функций рейтинга класса
 

, 

 - свою для каждого класса. По смыслу дискриминантная функция 

 определяет, насколько хорошо объект 

 подходит под  соответствующий класс 

.


В качестве прогноза классификатор выдаёт класс, обладающий максимальным рейтингом:







Часто дискриминатные функции определяют как линейные функции от признаков либо как условные вероятности классов при условии вектора признаков 

, однако в общем случае это могут быть произвольные функции!




Пусть прогнозы классификатора определены в каждой точке 

. Однозначно ли по классификатору определяются его дискриминантные функции?
Нет, не однозначно. Например, мы можем прибавить или вычесть любую константу одновременно из всех дискриминантных функций, и на прогноз это не окажет никакого влияния: максимум будет достигаться на том же самом классе.
На самом деле дискриминантные функции определены даже с точностью до монотонно возрастающего преобразования. Например, мы можем одновременно возвести в куб или экспоненцировать все дискриминантные функции, и это не окажет влияния на прогноз класса!


Каким уравнением задаётся граница между i-м и j-м классом?
Граница между i-м и j-м классом - это множество всех таких объектов, для которых рейтинг для i-го класса совпадает с рейтингом для j-го класса, т.е. это множество точек:



Подробнее о дискриминантных функциях можно прочитать в [1].


Бинарный классификатор в общем виде
​


В бинарной классификации возможных классов всего два, один из которых называется положительным, а другой - отрицательным:







В качестве положительного обычно выбирают 
целевой класс
, который встречается реже. Например, больной пациент при классификации людей на больных и здоровых или мошенническая транзакция при классификации на регулярные и мошеннические.




Прогноз строится по формуле





где 

 - 
относительная дискриминантная функция
, по смыслу определяющая, насколько положительный класс лучше подходит для объекта 

, чем отрицательный, а функция знака возвращает знак аргумента:





При 

 функция знака не определена, и её можно доопределить возвращать либо +1, либо -1.


Литература
​




Webb A. R., Copsey K.D. Statistical pattern recognition. – John Wiley & Sons, 2011: Discriminant functions.


Предыдущая страница
Классификаторы в общем виде
Следующая страница
Отступ классификации
Регрессия в общем виде
Многоклассовый классификатор в общем виде
Бинарный классификатор в общем виде
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Отступ классификации | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Общий вид прогнозирующих функций
Отступ классификации
Предсказание вероятностей и преобразование SoftMax
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Классификаторы в общем виде
Отступ классификации
Содержание этой страницы
Отступ классификации


Введение
​


В регрессии (когда прогнозируем вещественное число) есть понятие 
величины ошибки
, характеризующей степень того, насколько мы ошиблись в прогнозе:





Соответственно, мы определяем функцию потерь от этой ошибки, характеризующую штраф за то или иное отклонение:


задача
название
формула
регрессия
квадрат ошибки (squared error)

регрессия
модуль ошибки (absolute error)

регрессия

-нечувствительная, 




Проинтерпретируйте 

-нечувствительные потери.

-нечувствительные потери штрафуют отклонение пропорционально величине отклонения за вычетом 

 и вообще не штрафуют, если отклонение оказалось по абсолютной величине меньше 

. Это полезно в приложениях, где существует некоторый допустимый уровень ошибки, таких как прогноз погоды для бытовых нужд, когда разница в 

 градус несущественна.


Но как измерять степень рассогласованности классификационного прогноза с истинным значением? Можно смотреть на индикатор ошибки 

, однако эта величина принимает всего два дискретных значения: 0 для верного и 1 - для неверного прогноза! Индикатор не позволяет понять, 
насколько уверенно
 модель пыталась предсказать правильный отклик! Для этого используется понятие 
отступа
 (margin).


Отступ для многоклассовой классификации
​


Определение отступа
Отступ
 (margin) - непрерывная величина, измеряющая качество классификации по формуле:

где 

 - рейтинг верного класса, а 

 - максимальный рейтинг среди всех неверных.


Отступ по смыслу измеряет, насколько модель 
уверенно назначала верный класс по сравнению со всеми неверными
. Чем отступ выше, тем модель была более уверена в правильном прогнозе. Если 

, то модель делает верный прогноз, а если 

, то неверный.


Если применить модель ко всем объектам обучающей выборки, посчитать на них отступ и отсортировать по нему, то получим примерно такой график:


[IMAGE]


По величине отступа объекты делятся на следующие категории:






Надежно классифицированные объекты
 (обозначены светло-зелёным): отступ положительный и заметно больше нуля. При хорошей настройке модели большинство объектов будут принадлежать этой категории.






Объекты-эталоны
 (обозначены насыщенным зелёным): отступ положительный и большой. Объекты, лежащие в глубине своего класса и описывающие характерных представителей своего класса.






Пограничные объекты
 (обозначены оранжевым): отступ несильно отличается от нуля, объекты лежат на границе классов, и на таких объектах обычно достигается максимальное число ошибок.






Объекты-выбросы
 (обозначены красным): отступ отрицательный и большой по абсолютной величине. Объекты лежат в глубине чужого класса. На них модель уверена, что класс один, хотя на самом деле он совсем другой.






Для повышения точности настройки модели полезно отфильтровать объекты-выбросы, чтобы они не мешали её настройке.


При этом, если нужно сократить размер обучающей выборки для повышения эффективности обучения, то делать это можно взяв эталонные объекты (определяющие расположения классов) и пограничные (несущие более детальную информацию о границах между ними), добавляя в первую очередь те пограничные объекты, на которых отступ меньше, но которые всё ещё не являются выбросами. Уменьшение размера выборки известно в литературе как отбор прототипов (prototype selection). О более продвинутых подходах можно прочитать в 
[1]
.


Информацию об отступах объектов можно использовать и для более эффективного порядка обхода объектов в численных методах оптимизации модели методом 
стохастического градиентного спуска
 вместо выбора случайных групп объектов.


Отступ для бинарной классификации
​


В случае бинарной классификации формула для отступа упрощается:





где, как и раньше, 

 определяет 
относительную дискриминантную функцию
.


Литература
​




Bien J., Tibshirani R. Prototype selection for interpretable classification. – 2011.


Предыдущая страница
Общий вид прогнозирующих функций
Следующая страница
Предсказание вероятностей и преобразование SoftMax
Введение
Отступ для многоклассовой классификации
Отступ для бинарной классификации
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Предсказание вероятностей и преобразование SoftMax | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Общий вид прогнозирующих функций
Отступ классификации
Предсказание вероятностей и преобразование SoftMax
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Классификаторы в общем виде
Предсказание вероятностей и преобразование SoftMax
Содержание этой страницы
Предсказание вероятностей и преобразование SoftMax


Часто в прикладных задачах требуется хорошо предсказывать не только 
метку класса
 

, но и 
вероятность каждого класса
 

 Например, в задачах прогноза погоды важно не только предсказать, будет ли ясная погода или дождь, но и вероятность дождя. Ведь даже если она меньше 50%, но близка к ней, то имеет смысл брать зонтик.


Для предсказания вероятностей классов нужно использовать их 
дискриминантные функции
 

 характеризующие степень уверенности классификатора в том или ином классе. Поскольку дискриминантные функции могут принимать произвольные значения - как положительные, так и отрицательные - а сумма дискриминантных функций не обязательно равна единице, то к ним необходимо применить некоторое монотонно-возрастающее преобразование 

, обеспечивающее два свойства:






выходы должны быть неотрицательными;






выходы должны суммироваться в единицу.






В качестве такого преобразования используют операцию SoftMax, используемую для перевода ненормированных рейтингов классов в их вероятности:





Как вы думаете, на что влияет параметр 

?
Параметр 

, называемый 
температурой
 (temperature), определяет контрастность получаемых вероятностей. Чем 

 выше, тем метод становится менее чувствительным к индивидуальным различиям дискриминантных функций, результирующее распределение вероятностей становится более близким к равномерному.
И наоборот, чем 

 ниже, тем сильнее SoftMax реагирует на изменения рейтингов, а выходные вероятности становятся более контрастными.
Эти случаи показаны на рисунке:
[IMAGE]


Обобщение SoftMax-преобразования
SoftMax-преобразование можно обобщить, применяя любую монотонно возрастающую функцию 

, принимающую неотрицательные значения:

В частном случае 

 получим операцию SoftMax.


Детальнее о SoftMax-преобразовании можно прочитать в 
[1]
.


Литература
​




Wikipedia: softmax function.


Предыдущая страница
Отступ классификации
Следующая страница
Метрические методы прогнозирования
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Метрические методы | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Метрические методы
Метод ближайших центроидов
Метод K ближайших соседей
Анализ метода K ближайших соседей
Обобщение метода K ближайших соседей с весами
Веса в метрических методах
Локально-постоянная регрессия
Функции расстояния
Вопросы
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Метрические методы прогнозирования
Метрические методы
Содержание этой страницы
Метрические методы


Метрические методы прогнозирования
 - это методы, прогнозы которых определяются только расстояниями между целевым объектом, для которого строится прогноз, и некоторыми другими объектами 

, полученными из обучающей выборки. Таким образом, прогноз строится по общей формуле:





где 

 - функция, вычисляющая расстояние (измеряющее степень непохожести) между объектами 

 и 

, а 

 - значения откликов на объектах 

.




По смыслу прогнозная функция 

 предсказывает отклик агрегацией откликов среди некоторых обучающих объектов, максимально похожих на целевой объект.




Базовое предположение метода
Ключевое предположение метрического метода - близким объектам соответствуют близкие отклики. Если отклик действительно определяется выбранными признаками и зависит от них непрерывным образом, то это предположение весьма естественно.


Недостатком метода является 
сложный способ вычисления прогноза
, если используется большой набор референсных объектов 

.


Достоинством метода является его 
обобщаемость на любую функцию расстояния
. Варьируя способ вычисления расстояния между объектами 

, мы будем получать различные версии одного и того же метода!


Рассмотрим для примера две задачи с одинаковыми входными данными:






по фото человека определить, кто именно на нём изображён (независимо от позы);






по фото человека определить его позу (независимо от того, кого фотографировали).






Эти две противоположные во многом задачи можно решать одним и тем же методом, лишь варьируя функцию расстояния!


Более того, функцию расстояния можно параметризовать некоторым вектором параметров 

:





а дальше настраивать вид расстояния, который больше всего подходит под нашу задачу, что известно как 
обучение расстояния
 (metric learning). Существуют различные подходы обучения расстояний и даже специализированная python-бибилотека, которая их реализует 
[1]
.


Применимость методов
Обычные методы машинного обучения используют признаковое описание объектов в виде вектора признаков 
фиксированного размера
. Если сами объекты при этом могут иметь произвольный размер (например, тексты могут иметь произвольную длину, графы - произвольное число вершин и рёбер), то кодирование подобных объектов векторами фиксированного размера будет приводить к потере информации, что будет снижать точность прогнозов.
Если же мы определим функцию расстояния над 
исходным представлением объектов
 (а не сокращенным в виде вектора признаков), то сможем избежать потери информации, поскольку прогноз будет зависеть только от попарных расстояний между объектами. Например, мы можем определить расстояние между строками произвольной длины как минимальное число вставок/удалений и замен одного символа другим, необходимых для перевода одной строки в другую - так называемое 
редакторское расстояние
 или 
расстояние Левенштейна
 (edit distance, Levenstein distance - 
[2]
, 
[3]
). Его можно определить и для графов произвольного размера, а также для других типов данных.


Литература
​






Документация metric-learn.






Wikipedia: Levenshtein distance.






Левенштейн В. И. Двоичные коды с исправлением выпадений, вставок и замещений символов //Доклады Академии наук. – Российская академия наук, 1965. – Т. 163. – №. 4. – С. 845-848.




Предыдущая страница
Метрические методы прогнозирования
Следующая страница
Метод ближайших центроидов
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Метод ближайших центроидов | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Метрические методы
Метод ближайших центроидов
Метод K ближайших соседей
Анализ метода K ближайших соседей
Обобщение метода K ближайших соседей с весами
Веса в метрических методах
Локально-постоянная регрессия
Функции расстояния
Вопросы
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Метрические методы прогнозирования
Метод ближайших центроидов
Содержание этой страницы
Метод ближайших центроидов


Идея метода
​


Метод ближайших центроидов
 (nearest centroids, 
[1]
) представляет собой простейший 
метрический метод
 и решает задачу классификации. Рассмотрим демонстрационную обучающую выборку из двумерных объектов, разбитых на три класса. Класс объектов будем обозначать цветом.


[IMAGE]


Обучение метода заключается в вычислении 
центроидов
 для каждого класса.





Ниже они обозначены крестиками соответствующего цвета.


[IMAGE]


На этапе предсказания класса для объекта 

 вычисляются расстояния до каждого из центроидов. Объекту назначается тот класс, расстояние до которого меньше всего:





Чему равны дискриминантные функции для этого метода?
Дискриминантная функция
 каждого из классов вычисляет рейтинг соответствующего класса: чем он выше, тем класс более вероятен. Поэтому дискриминантная функция каждого класса будет равна расстоянию от 

 до центроида соответствующего класса 
со знаком минус
 (либо любой другой убывающей функции от расстояния).


Разделение признакового пространства методом ближайших центроидов для демонстрационного примера приведено ниже:


[IMAGE]


Как видим, границы между классами представляют собой прямые линии.


Всегда ли границы между классами будут линейными гиперплоскостями?
Границы между классами 

 и 

 задаются условием 

, что в случае метода ближайших центроидов будет 

. Если использовать 
евклидову функцию расстояния
, то это всегда будет линейной гиперплоскостью (докажите! подсказка: распишите уравнение границы в аналитическом виде).


Варианты усложнения метода
​


Метод использует не объекты обучающей выборки, а их внутриклассовые усреднения (центроиды). Если хотим использовать только обучающие объекты, то в качестве центроидов нужно выбирать центральные объекты класса из обучающей выборки (т.е. такие объекты выборки, что расстояние от них до всех других объектов того же класса будет наименьшим).


За счет того, что сравнение 

 происходит лишь с центроидами, а не со всеми объектами выборки, 
прогноз будет строиться быстро
. Однако метод способен выделять лишь выпуклые формы кластеров, поэтому в общем случае будет работать неточно. Его можно использовать как 
бейзлайн
 (простой метод, задающий нижнюю границу на точность), а также усложнить, характеризуя каждый класс не одним центроидом, а сразу несколькими в разных позициях.


Также метод можно обобщить, используя различные функции вычисления расстояния.


Описание метода и особенностей его реализации можно прочитать в документации sklearn 
[2]
.


Пример запуска в Python
​


Метод ближайших центроидов:


from
 sklearn
.
neighbors 
import
 NearestCentroid
from
 sklearn
.
metrics 
import
 accuracy_score
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_classification_data
(
)
  
model 
=
 NearestCentroid
(
)
      
# инициализация модели
model
.
fit
(
X_train
,
Y_train
)
;
    
# обучение модели
Y_hat 
=
 model
.
predict
(
X_test
)
  
# построение прогнозов
print
(
f'Точность прогнозов: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)




Больше информации
. 
Полный код
.


Литература
​






Wikipedia: nearest_centroid_classifier.






Документация sklearn: nearest centroid classifier.




Предыдущая страница
Метрические методы
Следующая страница
Метод K ближайших соседей
Идея метода
Варианты усложнения метода
Пример запуска в Python
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Метод K ближайших соседей | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Метрические методы
Метод ближайших центроидов
Метод K ближайших соседей
Анализ метода K ближайших соседей
Обобщение метода K ближайших соседей с весами
Веса в метрических методах
Локально-постоянная регрессия
Функции расстояния
Вопросы
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Метрические методы прогнозирования
Метод K ближайших соседей
Содержание этой страницы
Метод K ближайших соседей


Идея метода
​


Метод K ближайших соседей (K nearest neighbors, 
[1]
) умеет решать как задачу классификации, так и задачу регрессии. Обучение метода заключается лишь в сохранении обучающих объектов в памяти. На этапе построения прогноза для объекта 

 ищутся 

 ближайших к нему объектов обучающей выборки ("ближайшие соседи"), после чего






для классификации: назначается самый частый класс среди 

 ближайших объектов;






для регрессии: назначается средний отклик по откликам среди 

 ближайших объектов.






Иллюстрация для двумерного пространства признаков и задачи регрессии приведена ниже:


[IMAGE]


Каждый объект обучающей выборки обозначен красным шаром, а радиус шара - величина отклика. Требуется построить прогноз для тестового объекта, обозначенного зелёным шаром. Его отклик (радиус) определяется средним значением откликов (радиусов) среди K ближайших объектов.


Выбор 

 влияет на результат. Например, увеличение 

 с 3 до 5 приводит к увеличению прогноза.


На следующем рисунке показана иллюстрация для задачи классификации. Класс обозначен цветом и формой. Требуется построить прогноз для объекта, обозначенного зелёным шаром.


[IMAGE]


Здесь также видно, что выбор 

 влияет на результат. При 

 целевому объекту будет назначен красный класс, а при 

 - уже синий.


Прогноз вероятностей классов
Метод K ближайших соседей может выдавать и 
вероятности классов
. Для этого достаточно усреднить частоты попадания классов в число ближайших соседей.


Анализ метода
​


Рассмотрим работу метода для задачи классификации двумерных объектов с различным выбором гиперпараметра 

.


[IMAGE]


[IMAGE]


[IMAGE]


[IMAGE]


[IMAGE]


Как видим, при увеличении 

 модель становится более простой (менее гибкой), поскольку усреднение производится по более широкой окрестности объектов.


Как будет работать метод при K=N?
При K=N в качестве прогноза будет производиться агрегация сразу по всем объектам выборки, и метод выродится в константный прогноз, назначающий всем объектам самый распростаранённый класс в обучающей выборке.


В качестве другого примера рассмотрим задачу регрессии по одному признаку, где истинный отклик генерируется по формуле 

, а 

 - случайный нормально распределённый шум. Обучающие объекты обозначены черными точками, а целевая зависимость - пунктирной линией. Сплошной линией обозначен прогноз метода 

 ближайших соседей при различных значениях гиперпараметра 

.


[IMAGE]


Здесь также видно, что при малом 

 метод чересчур гибкий и переобучается под шум в данных. А при больших 

 - недостаточно гибкий и недообучается.


Почему гиперпараметр K нельзя подбирать по обучающей выборке?
Гиперараметр K определяет гибкость модели. Чем он ниже, тем модель получается более гибкой и тем точнее настраивается на данные. Соответственно, при выборке 

 на основе обучающей выборки всегда будет оказываться, что наилучшим значением параметра будет 

, при котором достигается 100% точность. Поэтому 

 и является гиперпараметром (а не параметром, подбираемым на обучающей выборке), и выбирать его следует только на основе 
прогнозов на внешней валидационной выборке
.


При 

 метод называется 
методом ближайшего соседа
 (nearest neighbor method).


Родственный метод
В качестве альтернативы можно усреднять не по фиксированному числу ближайших объектов, а по всем объектам, попавшим в 

-окрестность целевого объекта 

, сколько бы их ни оказалось (radius nearest neighbor). В чем-то этот метод логичнее, поскольку позволяет контролировать похожесть объектов, по которым будет строиться прогноз.
Однако он используется реже в связи со сложностью выбора радиуса окрестности 

. Если она слишком велика, то будет производиться усреднение по избыточному количеству объектов. А если слишком мала, то в окрестность может не попасть ни один объект!


Указанный метод также допускает обобщение на произвольную функцию расстояния.


Более детально о теории метода ближайших соседей можно прочитать в [2], а также в документации библиотеке sklearn 
[3]
 вместе с описанием реализации. Также идея метода и 
основные методы повышения скорости его работы
 описаны в учебнике ШАД 
[4]
.


Пример запуска в Python
​


Метод K ближайших соседей для классификации:


from
 sklearn
.
neighbors 
import
 KNeighborsClassifier
from
 sklearn
.
metrics 
import
 accuracy_score
from
 sklearn
.
metrics 
import
 brier_score_loss
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_classification_data
(
)
  
model 
=
 KNeighborsClassifier
(
n_neighbors
=
3
)
  
# инициализация модели
model
.
fit
(
X_train
,
Y_train
)
                   
# обучение модели                
Y_hat 
=
 model
.
predict
(
X_test
)
                
# построение прогнозов
print
(
f'Точность прогнозов: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
  
P_hat 
=
 model
.
predict_proba
(
X_test
)
  
# можно предсказывать вероятности классов
loss 
=
 brier_score_loss
(
Y_test
,
 P_hat
[
:
,
1
]
)
  
# мера Бриера на вер-ти положительного класса
print
(
f'Мера Бриера ошибки прогноза вероятностей: 
{
loss
:
.2f
}
'
)




Больше информации
. 
Полный код
.


Метод K ближайших соседей для регрессии:


from
 sklearn
.
neighbors 
import
 KNeighborsRegressor
from
 sklearn
.
metrics 
import
 mean_absolute_error
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_regression_data
(
)
  
model 
=
 KNeighborsRegressor
(
n_neighbors
=
3
)
  
# инициализация модели
model
.
fit
(
X_train
,
Y_train
)
                  
# обучение модели                
Y_hat 
=
 model
.
predict
(
X_test
)
               
# построение прогнозов
print
(
f'Средний модуль ошибки 
(
MAE
)
:
 \
            
{
mean_absolute_error
(
Y_test
,
 Y_hat
)
:
.
2f
}
'
)
   




Больше информации
. 
Полный код
.


Далее мы проанализируем 
достоинства и недостатки метода K ближайших соседей
, рассмотрим его 
обобщение
, при котором ближайшие объекты по-разному будут влиять на прогноз, а также рассмотрим 
основные функции расстояния
 в машинном обучении.


Литература
​




Wikipedia: k-nearest neighbors algorithm.


Webb A. R., Copsey K.D. Statistical pattern recognition. – John Wiley & Sons, 2011: k-nearest-neighbour method.


Документация sklearn: nearest neighbors.


Учебник ШАД: метрические методы.


Предыдущая страница
Метод ближайших центроидов
Следующая страница
Анализ метода K ближайших соседей
Идея метода
Анализ метода
Пример запуска в Python
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Анализ метода K ближайших соседей | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Метрические методы
Метод ближайших центроидов
Метод K ближайших соседей
Анализ метода K ближайших соседей
Обобщение метода K ближайших соседей с весами
Веса в метрических методах
Локально-постоянная регрессия
Функции расстояния
Вопросы
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Метрические методы прогнозирования
Анализ метода K ближайших соседей
Содержание этой страницы
Анализ метода K ближайших соседей


Достоинства метода
​


Метод K ближайших соседей легко реализовать, и он является интерпретируемым методом: всегда можно обосновать его прогноз, сославшись на похожие объекты в обучающей выборке, отклик для которых известен.




Свойство интерпретируемости важно в приложениях, в которых цена ошибочного прогноза велика, например, в медицине, где ценой ошибки может быть жизнь пациента.




Метод не требует обучения - нужно лишь сохранить обучающие объекты в памяти, поэтому качество его работы можно оценивать 
кросс-валидацией
 с большим числом блоков и даже скользящим контролем (когда число блоков совпадает с числом объектов выборки).


Метод может применяться в 
онлайн-обучении
 (online machine learning 
[1]
), когда данные поступают динамическим потоком и быстро устаревают, например, при автоматической торговле на бирже. Для этого в качестве обучающей выборки нужно учитывать только те объекты, которые мы недавно пронаблюдали.


Метод легко подхватывает основные паттерны в данных, запоминая примеры каждого случая. Поэтому метод легко может оказаться лучшим, например, в классификации на 
очень большое число классов
, когда число представителей каждого класса мало.


Недостатки метода
​


Для работы метода необходимо хранить все объекты обучающей выборки, поскольку эти объекты по сути и составляют 
параметры метода
.


Параметрические и непараметрические методы
Методы, в которых число параметров растёт с ростом объема выборки, называются 
непараметрическими
 в противоположность 
параметрическим
  методам, в которых число параметров 
заранее фиксировано
.
Например, распределение случайной величины мы можем моделировать Гауссовым распределением - тогда, с ростом выборки наблюдений, число параметров (среднее и матрица ковариации) будет оставаться прежним. Если же мы оцениваем распределение гистограммой, то с ростом числа наблюдений, если параллельно делать гистограмму более точной, 
увеличивая число её столбцов
, этот метод становится уже непараметрическим.
Непараметрические методы не делают таких существенных предположений о распределении данных, как параметрические, поэтому обычно работают точнее, когда накоплено большое количество наблюдений.


При построении прогноза даже для одного объекта требуется вычисление расстояний от этого объекта 
до всех объектов обучающей выборки
, чтобы найти K ближайших соседей. Поэтому в простейшей реализации метод применим лишь для малых выборок или в ситуациях, когда скорость построения прогнозов не важна.


Ускорение поиска ближайших соседей
Существуют подходы ускорения прогнозов метода K ближайших соседей, усложняющие его обучение и снижающие его применимость в онлайн-обучении:




Можно ускорить вычисление расстояний между объектами, снизив число признаков.






Можно уменьшить размер выборки, отобрав только эталонные объекты для каждого класса и существенные объекты на границах между классами, отбросив малоинформативные.






Можно упорядочить объекты по определённой структуре признакового пространства. Поиск похожих объектов вместо полного перебора тогда сведётся к направленному поиску по этой структуре (KD-trees, ball-trees 
[2]
 либо направленный поиск по 
графу близости между объектами
 (proximity graph)).






Можно использовать 
локально-чувствительное хэширование
 (locality sensitive hashing), при котором строится хэш-функция, отображающая метрически близкие объекты в одинаковые значения. Тогда, отобразив целевой объект в какое-то значение хэш-функции, можно сразу найти похожие объекты. Это будут объекты обучающей выборки, для которых хэш-функция приняла такое же значение.




Хороший обзор методов ускоренного поиска ближайших соседей представлен в учебнике ШАД 
[3]
.


Проклятие размерности
​


Также метод подвержен так называемому 
проклятию размерности
 (curse of dimensionality). Суть проклятия размерности заключается в том, что с ростом размерности признакового пространства 

 для обеспечения определённого уровня точности методу необходим экспоненциальный рост числа наблюдений (относительно 

). Если же рост числа наблюдений не происходит, то точность работы метода снижается.


Примеры проклятия размерности из разных областей можно прочитать в 
[4]
, а здесь мы сосредоточимся на её интуиции для метода K ближайших соседей.


Пусть нам нужно построить прогноз для объекта 

. Поместим этот объект в центр двух вложенных друг в друга  

-мерных кубов со сторонами 

 и 

, где 

 - какая-то малая фиксированная константа, например 0.001. Тогда объем внутреннего куба будет 

, а объём внешнего - 

. Отношение двух объёмов будет экспоненциально быстро стремиться к нулю с ростом 

, и уже при  небольшом значении 

 будет пренебрежимо малым:





Это означает, что доля объема, покрываемого внутренним кубом, от объема внешнего куба будет становиться пренебрежимо малой, а почти весь объем внешнего куба будет концентрироваться на его границе. Аналогичные рассуждения можно провести и для двух сфер вокруг целевого объекта - с ростом 

 почти весь объем внешней сферы будет концентрироваться на её границе.


При равномерном распределении объектов в признаковом пространстве вероятность пронаблюдать объект в определённой области будет пропорциональна объёму области. Значит, при поиске ближайших объектов к заданному эти объекты, скорее всего, 
будут располагаться не рядом, а на удалении
 от него.




Ближайшие соседи перестанут оказываться метрически близкими и перестанут репрезентативно описывать отклик целевого объекта!




Это можно понять и проще - чем большим числом признаков описывается каждый  объект, тем в среднем более удалёнными объекты будут оказываться друг от друга при вычислении расстояний между ними. Таким образом, 
ближайшие соседи перестают быть на самом деле близкими
, и предсказательная сила их откликов для целевого объекта снижается.


Не всё так плохо
Проклятие размерности - скорее теоретическая проблема. На практике, несмотря на то, что мы можем рассматривать все больше и больше признаков, они скорее всего будут скоррелированы друг с другом. Поэтому даже при увеличении размерности признакового пространства объекты будут заполнять его не равномерно, а на некотором многообразии меньшей размерности, вследствие чего метод будет работать лучше ожиданий.


Однако об этой особенности следует помнить, чтобы не добавлять лишних признаков, слабо влияющих на отклик, иначе они могут снизить качество прогнозов.




Литература
​






Wikipedia: Online machine learning.






Документация sklearn: nearest neighbor algorithms.






Учебник ШАД: метрические методы.






Wikipedia: Curse of dimensionality.




Предыдущая страница
Метод K ближайших соседей
Следующая страница
Обобщение метода K ближайших соседей с весами
Достоинства метода
Недостатки метода
Проклятие размерности
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Обобщение метода K ближайших соседей с весами | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Метрические методы
Метод ближайших центроидов
Метод K ближайших соседей
Анализ метода K ближайших соседей
Обобщение метода K ближайших соседей с весами
Веса в метрических методах
Локально-постоянная регрессия
Функции расстояния
Вопросы
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Метрические методы прогнозирования
Обобщение метода K ближайших соседей с весами
Обобщение метода K ближайших соседей с весами


В методе 
K ближайших соседей
 отклики ближайших объектов учитываются равномерно, с одинаковыми весами. Можно дополнительно повысить качество прогнозов, если позволить более близким ближайшим соседям влиять сильнее на прогноз, чем более далёким. Для этого равномерное усреднение по ближайшим соседям 
заменяется на взвешенное усреднение
, где больший вес будет соответствовать более близким соседям.


Обозначим 

 - ближайшие соседи в обучающей выборке для целевого объекта 

, для которого мы строим прогноз. Причем эти соседи упорядочены по возрастанию расстояния от них до целевого объекта 

:





Регрессионный прогноз базового метода строится простым усреднением по откликам ближайших соседей:





Взвешенное обобщение строится уже взвешенным усреднением откликов:





Аналогично в задаче классификации базовым методом вероятности классов строятся по формуле:





Взвешенное обобщение учитывает каждого ближайшего соседа со своим весом:





О популярных методах расчета весов можно прочитать в 
следующей главе
.
Предыдущая страница
Анализ метода K ближайших соседей
Следующая страница
Веса в метрических методах
© 2023-25 
Виктор Китов.
 
Новости проекта.









Веса в метрических методах | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Метрические методы
Метод ближайших центроидов
Метод K ближайших соседей
Анализ метода K ближайших соседей
Обобщение метода K ближайших соседей с весами
Веса в метрических методах
Локально-постоянная регрессия
Функции расстояния
Вопросы
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Метрические методы прогнозирования
Веса в метрических методах
Содержание этой страницы
Веса в метрических методах


Веса 

, с которыми учитываются ближайшие соседи, должны быть неотрицательными и убывать с ростом расстояния до ближайшего соседа.


Их можно сделать зависимыми от порядкового номера 

 ближайшего соседа:





Тогда они будут убывать по экспоненциальному закону от порядкового номера соседа.


Также их можно сделать убывающими по линейному закону:





Однако более естественно и правильно сделать веса зависящими от расстояний между ближайшим соседом и целевым объектом 

, а не от его порядкового номера. Пусть 

 - ближайшие соседи в обучающей выборке для целевого объекта 

, для которого мы строим прогноз.


Веса можно сделать убывающими по гиперболическому закону:





В чём недостаток такого выбора весов и как его исправить?
При приближении к соседу его вес будет неограниченно возрастать, в результате чего отклик на этом объекте начнёт перевешивать отклики на других соседях. Чтобы воспрепятствовать неограниченному возрастанию весов, нужно его ограничить сверху некоторой константой 

:



Также можно сделать веса убывающими по линейному закону:





В более общем виде веса определяются по формуле:





для некоторой убывающей функции 

, называемой 
ядром
 (kernel) и зависящей от расстояния между объектами 

, нормированной на 
параметр ширины
 окна 

 (bandwidth), который в общем случае может представлять собой не константу, а тоже функцию от 

.


Графики популярных ядер 

 приведены ниже вместе с формулами для их расчёта 
[1]
:


[IMAGE]






Ядро
Формула
top-hat

линейное

Епанечникова

экспоненциальное

Гауссово

квартическое



Гиперпараметр ширины окна 

 определяет, насколько сильно меняются веса при изменении расстояний до объектов. Чем 

 выше, тем слабее веса зависят от расстояний, а при 

 веса стремятся к равномерным, и взвешенный метод ближайших соседей стремится к обычному (без весов).


Ширину окна можно варьировать в зависимости от целевого объекта, поэтому в общем случае она записывается как 

.


Литература
​




Документация sklearn: simple 1D kernel density estimation.


Предыдущая страница
Обобщение метода K ближайших соседей с весами
Следующая страница
Локально-постоянная регрессия
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Локально-постоянная регрессия | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Метрические методы
Метод ближайших центроидов
Метод K ближайших соседей
Анализ метода K ближайших соседей
Обобщение метода K ближайших соседей с весами
Веса в метрических методах
Локально-постоянная регрессия
Функции расстояния
Вопросы
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Метрические методы прогнозирования
Локально-постоянная регрессия
Содержание этой страницы
Локально-постоянная регрессия


Локально-постоянная регрессия
 (local constant regression), известная также как 
ядерная регрессия
 (kernel regression 
[1]
) и 
регрессия Надарая-Ватсона
 (Nadaraya–Watson regression), представляет собой непараметрический метод для моделирования сложных регрессионных зависимостей. Она была впервые предложена в работах [2] и [3].


Допустим, нам нужно моделировать некоторую нелинейную зависимость 

, показанную ниже:


[IMAGE]


Можно было бы искать наилучший в среднеквадратичном смысле константный прогноз:





Задание
Докажите, что оптимальный константный прогноз, минимизирующий средний квадрат ошибки, это действительно выборочное среднее.
Подсказка: поскольку оптимизационный критерий по 

 является 
выпуклым
, то не только необходимым, но и 
достаточным
 условием оптимальности будет равенство нулю его производной.


Однако константный прогноз слишком прост и нам не подходит, поскольку целевая зависимость нелинейная. Поэтому для построения прогноза в точке 

 будем использовать 
локально-постоянный прогноз
, получаемый в результате минимизации квадратов ошибок 
в локальной окрестности от целевой точки
:


[IMAGE]




Усредняя лишь по близлежащим точкам к целевой получим нелинейную аппроксимацию общего вида, показанную на рисунке выше красной линией.




В общем случае локально-постоянная регрессия ищет наилучший константный прогноз, усредняя 
по всем объектам
 обучающей выборки, 
но с весами
 - чем объект более удалён от целевой точки, тем вес его меньше, и тем слабее он влияет на прогноз:





Задание
Докажите, что оптимальный константный прогноз, минимизирующий квадраты ошибок с весами, это действительно взвешенное среднее.


Веса 

 определяются так же, как и в случае взвешенного учета ближайших соседей, через убывающую функцию ядра (kernel) 

 от расстояния, нормированного на ширину окна 

 (bandwidth):





Разница лишь в том, что теперь это веса для всех объектов обучающей выборки, а не только для ближайших соседей. Типовые ядра 

 такие же, как раньше:


Ядро
Формула
top-hat

линейное

Епанечникова

экспоненциальное

Гауссово

квартическое



а гиперпараметр ширины окна 

 задаёт ширину усреднения. Для ядер top-hat, линейного, Епанечникова и квартического прогноз будет получаться усреднением только по точкам, лежащим на расстоянии не более чем 

 от целевой. Для Гауссова и экспоненциального ядер усреднение всегда будет производиться по всем объектам, но основной вклад также будут давать объекты, лежащие в той же окрестности.


Вид ядра характеризует гладкость получаемой зависимости (рекомендуется Гауссово ядро и квартическое), однако на точность приближения больше всего влияет ширина окна 

 - чем она выше, тем более плавной будет получаться моделируемая зависимость, которая при 

 будет стремиться к константе (обоснуйте!).


Целесообразно варьировать гиперпараметр 

 для разных частей признакового пространства: чем гуще лежат обучающие объекты, тем меньше мы можем взять 

, производя полноценное усреднение по всё еще большому числу объектов. Поэтому в общем виде этот гиперпараметр также можно сделать зависящим от 

:





Задание
При каком выборе 

 и 

 локально-постоянная регрессия превратится в 
метод K ближайших соседей
?


Обобщение
Поскольку прогноз локально-постоянной регрессии зависит от объектов только через расстояния до них, то это метрический метод, который мы можем обобщать, выбирая различные функции расстояния!


Этот метод, будучи метрическим, наследует преимущества и недостатки метода ближайших соседей.


Литература
​






Wikipedia: kernel regression.






Nadaraya E. A. On estimating regression //Theory of Probability & Its Applications. – 1964. – Т. 9. – №. 1. – С. 141-142.






Watson G. S. Smooth regression analysis //Sankhyā: The Indian Journal of Statistics, Series A. – 1964. – С. 359-372.




Предыдущая страница
Веса в метрических методах
Следующая страница
Функции расстояния
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Функции расстояния | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Метрические методы
Метод ближайших центроидов
Метод K ближайших соседей
Анализ метода K ближайших соседей
Обобщение метода K ближайших соседей с весами
Веса в метрических методах
Локально-постоянная регрессия
Функции расстояния
Вопросы
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Метрические методы прогнозирования
Функции расстояния
Содержание этой страницы
Функции расстояния


Преимуществом метрических методов является то, что их можно применять с любой 
функцией расстояния
 (distance function) между объектами 

. По смыслу расстояние измеряет непохожесть объектов между собой, и его не надо путать с 
функцией похожести
 (similarity function) 

, принимающей более высокие значения между более похожими объектами.


Взаимосвязь расстояния и похожести
Мы всегда можем преобразовать расстояние в похожесть и наоборот, применяя некоторую убывающую функцию 

:

Например, 

 или 

.


Сравнение векторов вещественных чисел
​


Если 

, то часто используются следующие функции расстояния:


Название

Евклидово


 (Манхэттенская)





Канберра

Ланса-Уильямса



Косинусная мера близости
​


Очень популярна 
косинусная мера близости
 
[1]
:





измеряющая косинус угла между векторами 

 и 

, поэтому принимающая значения на отрезке 

.


Согласно этой мере объекты близки, если угол между ними мал, а, соответственно, косинус этого угла близок к единице. Косинусная мера близости не зависит от длин сравниваемых векторов (докажите!).




Это полезно в некоторых приложениях, таких как анализ текстов, кодируемых счётчиками встречаемости в них слов. Если продублировать документ, то счётчики всех слов увеличатся вдвое, как и длина вектора признаков, кодирующего документ. Поскольку дублирование текста не оказывает влияние на смысл документа, то оно не должно изменять попарные расстояния между документами, что и наблюдается для косинусной меры близости.




Расстояние Махаланобиса
​


Для сравнения векторов, элементы которых сильно скоррелированы между собой, используется Евклидово расстояние, но не между исходными объектами 

, а между их декоррелированными версиями:





Задача
Докажите, что 

 и 

 будут иметь нулевое среднее и единичную матрицу ковариаций, т.е. отдельные элементы векторов будут не скоррелированы между собой.


Графически процесс перевода из скоррелированного пространства (A) в декоррелированное (B) показан ниже:


[IMAGE]


В терминах исходных векторов это расстояние выражается как





и называется 
расстоянием Махаланобиса
 
[2]
.


Задача
Докажите, что Евклидово расстояние между декореллированными версиями объектов 

 и 

 будет считаться по формуле выше.


В более общем случае расстояние можно определить через произвольную неотрицательно-определённую матрицу 

, которую можно настраивать по данным (metric learning 
[3]
):





Сравнение бинарных векторов
​


Для бинарных векторов, состоящих только из нулей и единиц, часто используют 
расстояние Хэмминга
 
[4]
:





Сравнение множеств
​


Для сравнения двух множеств X и Z (например наборов товаров, купленных в магазине по двум чекам) используется 
мера близости Жаккара
 (Jaccard index 
[5]
), равная числу элементов в пересечении множеств, нормированному на число элементов в их объединении:





Мера принимает значения в отрезке 

.


Сравнение строк
​


Для сравнения строк часто используется 
редакторское расстояние
 (edit distance), называемое также 
расстоянием Левенштейна
 (Levenstein distance 
[6]
, предложена в 
[7]
). Для двух строк 

  и 

 оно вычисляется как минимальное число операций вставки символа, удаления символа и замены одного символа другим, необходимое для перевода одной строки в другую. Например, расстояние между строками "вагон" и "авто" будет 4, поскольку минимально требуется 4 операции для преобразования одной строки в другую:


операция
результат
ВАГОН
1
удаление В
АГОН
2
замена Г на В
АВОН
3
вставка Т
АВТОН
4
удаление Н
АВТО




Строки могут быть произвольной длины, содержать пробелы и описывать целые тексты!




Существует эффективный алгоритм, позволяющий найти минимальное количество редакторских операций за полиномиальное время от длин строк 
[8]
, предложенный в 
[9]
.


Сравнение временных рядов
​


Временные ряды можно сравнивать как вектора их последовательных значений, но только в случае, когда они состоят из одинакового количества элементов. Перед сравнением может применяться приведение их значений к одному масштабу (например, нулевое среднее и единичная дисперсия).


Также динамику рядов можно раскладывать по базису некоторых функций, а ряды представлять в виде коэффициентов разложения по базису и сравнивать обычными функциями расстояния между векторами признаков.


Если временные ряды разные по длительности, то можно более короткий временной ряд растянуть до длины более длинного временного ряда.


Альтернативно можно использовать 
алгоритм динамической трансформации временной шкалы
 (dynamic time warping 
[10]
), в котором перед сравнением ищется оптимальное локальное растяжение участков каждого из рядов, чтобы они лучше подходили друг к другу, как показано ниже на рисунке справа (
источник
):


[IMAGE]


Этот алгоритм позволяет сравнивать временные ряды разной длины по наличию в них схожей динамики, даже если она происходила с разной скоростью. Расчёт расстояния также может быть эффективно произведён за полиномиальное время от длин сравниваемых рядов.


Литература
​






Wikipedia: cosine similarity.






Wikipedia: Mahalanobis distance.






Kulis B. et al. Metric learning: A survey //Foundations and Trends® in Machine Learning. – 2013. – Т. 5. – №. 4. – С. 287-364.






Wikipedia: Hamming distance.






Wikipedia: Jaccard index.






Wikipedia: Levenshtein distance.






Левенштейн В. И. Двоичные коды с исправлением выпадений, вставок и замещений символов //Доклады Академии наук. – Российская академия наук, 1965. – Т. 163. – №. 4. – С. 845-848.






Wikipedia: edit distance.






Kukich K. Techniques for automatically correcting words in text //ACM computing surveys (CSUR). – 1992. – Т. 24. – №. 4. – С. 377-439.






Wikipedia: dynamic time warping.




Предыдущая страница
Локально-постоянная регрессия
Следующая страница
Вопросы
Сравнение векторов вещественных чисел
Косинусная мера близости
Расстояние Махаланобиса
Сравнение бинарных векторов
Сравнение множеств
Сравнение строк
Сравнение временных рядов
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Вопросы для самопроверки | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Метрические методы
Метод ближайших центроидов
Метод K ближайших соседей
Анализ метода K ближайших соседей
Обобщение метода K ближайших соседей с весами
Веса в метрических методах
Локально-постоянная регрессия
Функции расстояния
Вопросы
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Метрические методы прогнозирования
Вопросы
Вопросы для самопроверки




Рассмотрим метод ближайших центроидов, метод ближайших соседей и метод Надарая-Ватсона. Какой из этих методов может решать только задачу регрессии, только задачу классификации и обе эти задачи?


Перечислите сравнительные достоинства и недостатки метода ближайших центроидов, метода ближайших соседей и метода Надарая-Ватсона.


Использование каких функций ядра в локально-линейной регрессии приведёт к использованию не всех, а лишь части объектов обучающей выборки при построении прогноза? Какие это будут объекты?


Почему гиперпараметр 

 в локально-постоянной регрессии нельзя настраивать по обучающей выборке?


Как гиперпараметр 

 влияет на гибкость настройки локально-постоянной регрессии под объекты обучающей выборки?


Почему косинусная мера близости не будет зависеть от длин сравниваемых векторов?


Какие функции расстояния между временными рядами не будут зависеть от длин временных рядов?


К чему сведётся расстояние Махаланобиса при нулевой попарной корреляции между признаками? При каких дополнительных условиях получим евклидово расстояние?


Предыдущая страница
Функции расстояния
Следующая страница
Линейная регрессия и её обобщения
© 2023-25 
Виктор Китов.
 
Новости проекта.









Линейная регрессия | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Линейная регрессия
Аналитическое решение для линейной регрессии
Регуляризация в линейной регрессии
Аналитическое решение для гребневой регрессии
Линейный ансамбль моделей
Регрессия опорных векторов
Orthogonal matching pursuit
Локально-линейная регрессия
Дополнительная литература
Вопросы
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Линейная регрессия и её обобщения
Линейная регрессия
Содержание этой страницы
Линейная регрессия


Идея метода
​


В 
линейной регрессии
 (linear regression) прогноз строится как линейная комбинация признаков:





Если ввести в признаки константную единицу и использовать векторное обозначение





то прогноз линейной регрессии можно записать в компактном виде:





Модель основана на следующих предположениях:






каждый признак 

 линейно влияет на отклик с коэффициентом 

;






характер влияния каждого признака постоянен и не зависит от значений других признаков.






Достоинства линейной регрессии
​


Модель линейной регрессии простая и интерпретируемая, быстро работает и содержит мало параметров, поэтому наименее склонна к переобучению.




Если число признаков 

 велико, а число объектов в обучающей выборке 

 мало, то при тщательно подобранной 
регуляризации
 модель может оказаться наилучшей среди всех возможных!




Другим достоинством линейной регрессии является наличие 
аналитического решения
 (при минимизации суммы квадратов прогнозов), которое является глобальным минимумом функции потерь, т.е. наилучшим значением из всех возможных.


Недостатки линейной регрессии
​


Предположения линейной регрессии довольно просты и на практике, скорее всего, выполняться не будут: признаки влияют скорее всего нелинейно и характер этого влияния зависит от значений других признаков.




Например, при оценке стоимости квартиры по её характеристикам, стоимость нелинейным образом зависит от увеличения расстояния до метро, причем характер этого влияния разный в зависимости от того, есть ли рядом остановка общественного транспорта или нет.




Нарушение модельных предположений будет приводить к меньшей точности прогнозов.


Моделирование более сложных зависимостей
Ограничения линейной регрессии можно исправить вручную, если в качестве признаков добавлять 
нелинейные трансформации
 исходных признаков. Тогда модель в терминах исходных признаков будет получаться нелинейной! Если трансформации будут зависеть не от каждого признака по отдельности, а сразу от нескольких признаков, то характер влияния признаков также будет варьироваться в зависимости от значений других признаков.


Ранее мы обсуждали, что для многих методов машинного обучения масштаб признаков (диапазон принимаемых значений) влияет на прогнозы. Например, признак [вес] мы можем измерять в килограммах, граммах или тоннах, и это будет оказывать влияние на прогноз.


Будет ли изменение масштаба признаков (после перенастройки модели с новым масштабом) влиять на прогнозы линейной регрессии?
Нет, не будет. Например, если признак уменьшить в 100 раз, то соответствующий коэффициент при признаке увеличится в 100 раз, а итоговый прогноз не изменится.


Связь с вероятностной моделью
Минимизация суммы квадратов отклонений соответствует применению метода максимального правдоподобия к вероятностной модели

где 

 - шум, распределённый согласно 
нормальному распределению
 (докажите).


А если бы мы взяли 

 из 
распределения Лапласа
, то чему бы соответствовал метод максимального правдоподобия?
Минимизации суммы модулей ошибок прогнозов (докажите).


Пример запуска в Python
​


Пример использования линейной регрессии в библиотеке sklearn:


from
 sklearn
.
linear_model 
import
 LinearRegression
from
 sklearn
.
metrics 
import
 mean_absolute_error
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_regression_data
(
)
  
model 
=
 LinearRegression
(
)
     
# инициализация модели
model
.
fit
(
X_train
,
Y_train
)
     
# обучение модели                
Y_hat 
=
 model
.
predict
(
X_test
)
  
# построение прогнозов
print
(
f'Средний модуль ошибки 
(
MAE
)
:
 \
        
{
mean_absolute_error
(
Y_test
,
 Y_hat
)
:
.
2f
}
'
)
    




Больше информации
. 
Полный код
.


В следующих главах мы рассмотрим аналитический вывод весов для линейной регрессии, введение регуляризации в модель и всевозможные усложнения и варианты применения модели.


Дополнительно о линейной регрессии можно прочитать в википедии 
[1]
, а также в документации sklearn 
[2]
.


Литература
​






Wikipedia: linear regression.






Документация sklearn: linear models.




Предыдущая страница
Линейная регрессия и её обобщения
Следующая страница
Аналитическое решение для линейной регрессии
Идея метода
Достоинства линейной регрессии
Недостатки линейной регрессии
Пример запуска в Python
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Аналитическое решение для линейной регрессии | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Линейная регрессия
Аналитическое решение для линейной регрессии
Регуляризация в линейной регрессии
Аналитическое решение для гребневой регрессии
Линейный ансамбль моделей
Регрессия опорных векторов
Orthogonal matching pursuit
Локально-линейная регрессия
Дополнительная литература
Вопросы
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Линейная регрессия и её обобщения
Аналитическое решение для линейной регрессии
Аналитическое решение для линейной регрессии


Веса линейной регрессии находятся 
из принципа минимизации наименьших квадратов
 (МНК, ordinary least squares, OLS):





Этот критерий по 

 является выпуклым как суперпозиция линейной и выпуклой функции.


Тип векторов
Все вектора в этом разделе, как и глобально в книге, будем считать векторами-столбцами (а не строками). Это важно для понимания аналитических выкладок.


Будет ли суперпозиция двух выпуклых функций выпуклой?
Суперпозиция двух выпуклых функций может и не быть выпуклой, например, 

 для

Однако суперпозиция 
линейной
 и выпуклой функции всегда выпукла - докажите самостоятельно.


Поэтому не только необходимым, но и достаточным условием минимума потерь будет покомпонентное равенство нулю 
градиента
 функции потерь. Причем, также в силу выпуклости функции, будет гарантия, что найденный минимум будет 
глобальным минимумом
 функционала, т.е. обеспечивать наименьшее значение функции потерь среди всех возможных.


Мы говорим про градиент, а не про производную, поскольку при дифференцировании скалярной функции 

 по вектору 

 получим вектор частных производных по каждой компоненте вектора 

:





Найдем оптимальные веса аналитически. Поскольку функция потерь является выпуклой по весам, то не только необходимым, но и 
достаточным
 условием оптимальности будет покомпонентное равенство нулю градиента функции потерь:








Перепишем условие, используя обозначения для матрицы объекты-признаки 

 и вектора откликов 

:





Откуда получаем аналитическое итоговое решение для линейной регрессии:





Обратим внимание, что решение не будет существовать, если матрица 

 вырождена, что эквивалентно тому, что 
ранг матрицы
 

.


Задача
Докажите, что 

 для любой матрицы 

.


Последнее, в свою очередь, означает линейную зависимость между признаками, т.е. что найдётся такой набор весов 

, что





В этом случае один из признаков лишний, поскольку может быть получен как линейная комбинация других признаков, а само решение неоднозначно, поскольку если 

 - решение, то и 

 - тоже решение для любого 

, поскольку





Следовательно, если матрица 

 необратима и аналитическая оценка весов не определена, то нужно уменьшить число признаков через 
отбор признаков/снижение размерности
.
Предыдущая страница
Линейная регрессия
Следующая страница
Регуляризация в линейной регрессии
© 2023-25 
Виктор Китов.
 
Новости проекта.









Регуляризация в линейной регрессии | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Линейная регрессия
Аналитическое решение для линейной регрессии
Регуляризация в линейной регрессии
Аналитическое решение для гребневой регрессии
Линейный ансамбль моделей
Регрессия опорных векторов
Orthogonal matching pursuit
Локально-линейная регрессия
Дополнительная литература
Вопросы
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Линейная регрессия и её обобщения
Регуляризация в линейной регрессии
Содержание этой страницы
Регуляризация в линейной регрессии


Идея регуляризации
​


Как известно, слишком простые (то есть недостаточно гибкие по выразительной способности) модели строят неточные прогнозы из-за недообучения, а слишком сложные (избыточно гибкие) - к неточным прогнозам из-за переобучения, что можно проиллюстрировать характерным графиком:


[IMAGE]


Поэтому важно подобрать сложность модели таким образом, чтобы её сложность соответствовала сложности реальных данных (точка A на графике выше).


Сложность линейной регрессии можно контролировать, варьируя количество признаков, которые мы добавляем в модель, но этот подход обладает следующими недостатками:






Остаётся неясным, какие признаки удалять в первую очередь?






Характер влияния будет получаться дискретный, а не непрерывный, что препятствует более тонкой настройке сложности.






Если все признаки оказывают влияние, то удаление даже части из них будет ухудшать прогноз.






В связи с этими недостатками принято контролировать сложность модели, добавляя в её настройку дополнительное слагаемое (регуляризатор) 

, как говорилось во 
введении в регуляризацию
:





Популярными способами выбора 

 являются:






L2-регуляризация









L1-регуляризация











ElasticNet-регуляризация







Контроль сложности
Гиперпараметр 

 определяет силу регуляризации, то есть степень упрощения модели. Чем 

 выше, тем сильнее оптимизатор при настройке весов будет ориентироваться на регуляризатор, прижимающий веса к нулю, а не на точность модели на обучающей выборке. При 

 веса будут стремиться к нулю, а результирующий регрессионный прогноз будет вырождаться в максимально простую модель - константу.


Обратим внимание, что по формулам выше не рекомендуется подвергать регуляризации смещение 

, чтобы даже при слишком сильной регуляризации прогнозы оставались в среднем несмещёнными.


Особенности решения с регуляризацией
Для всех представленных видов регуляризации оптимизируемый критерий будет выпуклым, поэтому, найдя какой-либо минимум, мы можем быть уверены, что это глобальный минимум (докажите).


Линейная регрессия с L2-регуляризацией называется 
гребневой регрессией
 (ridge regression), а с L1-регуляризацией - 
лассо-регрессией
 (LASSO, Least Absolute Shrinkage and Selection Operator).


Сравнительные достоинства L1- и L2-регуляризации 
уже рассматривались ранее
. Поэтому лишь напомним вкратце, что L1-регуляризация может выдавать оптимальное решение, в котором 
часть весов будет в точности равна нулю
. В контексте линейной регрессии это означает автоматический 
отбор признаков
, поскольку признаки при нулевых коэффициентах вообще не будут оказывать влияния на прогнозы модели. Чем выше гиперпараметр 

, тем больше признаков будет отброшено из модели.


Анализ данных и интерпретируемость
Коэффициент 

 полезно варьировать для обнаружения самых значимых признаков для прогнозирования в целях общего анализа данных и интерпретации зависимостей между ними.


L2-регуляризация, в свою очередь, способствует более равномерному распределению весов по признакам и более полному учёту входной информации.


ElasticNet-регуляризация обладает обоими свойствами и требует задания дополнительного гиперпараметра 

.


Гиперпараметр 

 обычно подбирают по прогнозам на валидационной выборке или используя кросс-валидацию по логарифмической сетке значений 

. Найдя наилучшее значение, его можно уточнить по более мелкой сетке в окрестности найденного значения.


Решение для линейной регрессии с 

- и ElasticNet-регуляризацией находится 
численными методами
, а для гребневой регрессии (L2-регуляризация) его 
можно найти аналитически
.


Будет ли изменение масштаба признаков (после перенастройки модели с новым масштабом) влиять на решение линейной регрессии с регуляризацией?
Да, будет. Например, если признак уменьшим в 100 раз, то соответствующий коэффициент при признаке будет стремиться к увеличению в 100 раз, однако регуляризация не даст в полной мере это реализовать!
Поэтому, чтобы обеспечить регуляризацию одинаковой силы на все признаки, их необходимо предварительно привести к одной шкале, используя 
нормализацию
. Также нормализация важна, если мы хотим выявить самые значимые признаки посредством L1-регуляризации.
Версии линейной регрессии с регуляризациями L1, L2 и ElasticNet реализованы в библиотеке sklearn 
[1]
.


Пример запуска в Python
​


Использование  гребневой регрессии:


from
 sklearn
.
linear_model 
import
 Ridge
from
 sklearn
.
metrics 
import
 mean_absolute_error
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_regression_data
(
)
  
model 
=
 Ridge
(
alpha
=
1
)
        
# инициализация модели, alpha-вес при регуляризаторе
model
.
fit
(
X_train
,
Y_train
)
    
# обучение модели                
Y_hat 
=
 model
.
predict
(
X_test
)
 
# построение прогнозов
print
(
f'Средний модуль ошибки (MAE): 
{
mean_absolute_error
(
Y_test
,
 Y_hat
)
:
.2f
}
'
)
  




Больше информации
. 
Полный код
.


Использование LASSO-регрессии:


from
 sklearn
.
linear_model 
import
 Lasso
from
 sklearn
.
metrics 
import
 mean_absolute_error
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_regression_data
(
)
  
model 
=
 Lasso
(
alpha
=
1
)
        
# инициализация модели, alpha-вес при регуляризаторе
model
.
fit
(
X_train
,
Y_train
)
    
# обучение модели                
Y_hat 
=
 model
.
predict
(
X_test
)
 
# построение прогнозов
print
(
f'Средний модуль ошибки (MAE): 
{
mean_absolute_error
(
Y_test
,
 Y_hat
)
:
.2f
}
'
)
  




Больше информации
. 
Полный код
.


Зашумление признаков
​


Альтернативным способом регуляризации является обучение на признаках, 
к которым добавлен случайный шум
 

. Это заставит модель не переобучаться под значения отдельных признаков, поскольку значения каждого признака становятся менее надёжными из-за шума. Чем дисперсия шума выше, тем сильнее регуляризующий эффект от зашумления.




Обратим внимание, что при применении модели шум 
не добавляется
. Настроенная модель работает на исходных признаках.




Шум удовлетворяет двум свойствам:






нулевое мат. ожидание: 

,






нескореллированные компоненты, каждая из которых имеет дисперсию 

:









где 

 - единичная матрица.


Интересно, что если усреднять потери 
по всевозможным реализациям шума
, то получим, что зашумление признаков эквивалентно L2-регуляризации!


Доказательство эквивалентности

где в предпоследней формуле мы использовали линейность мат. ожидания, равенство нулю мат. ожидания шума и его известную ковариационную матрицу.
Таким образом, зашумление признаков во время обучения эквивалентно в среднем добавлению L2-регуляризации. О связи зашумления признаков с регуляризацией в более общем случае нелинейных нейросетевых моделей можно прочитать в 
[1]
.


Литература
​






Документация sklearn: linear models.






Bishop C. M. Training with noise is equivalent to Tikhonov regularization //Neural computation. – 1995. – Т. 7. – №. 1. – С. 108-116.




Предыдущая страница
Аналитическое решение для линейной регрессии
Следующая страница
Аналитическое решение для гребневой регрессии
Идея регуляризации
Пример запуска в Python
Зашумление признаков
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Аналитическое решение для гребневой регрессии | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Линейная регрессия
Аналитическое решение для линейной регрессии
Регуляризация в линейной регрессии
Аналитическое решение для гребневой регрессии
Линейный ансамбль моделей
Регрессия опорных векторов
Orthogonal matching pursuit
Локально-линейная регрессия
Дополнительная литература
Вопросы
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Линейная регрессия и её обобщения
Аналитическое решение для гребневой регрессии
Аналитическое решение для гребневой регрессии


В гребневой регрессии вектор весов 

 находится из условия:





Поскольку этот критерий выпуклый (докажите!), минимум является глобальным минимумом и находится из условия покомпонентного равенства градиента функции потерь нулю, т.е. 

:





Отсюда, используя обозначение 

 для единичной матрицы, получаем:








Используя обозначения для матрицы объекты-признаки 

 и вектора откликов 

, это можно переписать в виде:





откуда получим итоговый вид аналитического решения:





Существование решения
Обратим внимание, что матрица 

 положительно определена (докажите!), поэтому всегда невырождена для любых 

. Поэтому решение всегда существует - в отличие от линейной регрессии без регуляризации. Интуитивно решение существует, поскольку даже в случае линейной зависимости признаков регуляризация привносит в него однозначность - среди всех решений необходимо найти то, которое обладает максимальной простотой (минимизирует 

).
Предыдущая страница
Регуляризация в линейной регрессии
Следующая страница
Линейный ансамбль моделей
© 2023-25 
Виктор Китов.
 
Новости проекта.









Линейный ансамбль моделей | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Линейная регрессия
Аналитическое решение для линейной регрессии
Регуляризация в линейной регрессии
Аналитическое решение для гребневой регрессии
Линейный ансамбль моделей
Регрессия опорных векторов
Orthogonal matching pursuit
Локально-линейная регрессия
Дополнительная литература
Вопросы
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Линейная регрессия и её обобщения
Линейный ансамбль моделей
Линейный ансамбль моделей


Для повышения точности прогнозов часто используют 
ансамбли моделей
 (model ensemble), называемые также 
композициями моделей
. Для этого используют прогнозы 

 базовых моделей 

, а итоговый прогноз строят через 
агрегирующую модель
 (называемую также 
мета-моделью
) 

. Таким образом, прогнозы базовых моделей выступают признаками для агрегирующей модели.


Часто используется линейная комбинация прогнозов различных моделей:





Веса 

 этой модели настраиваются через линейную регрессию, признаками которой выступают прогнозы базовых моделей. Чтобы избежать переобучения, коэффициенты  настраиваются 
на отдельной обучающей выборке
, а не выборке, по которой настраивались параметры базовых моделей.




Построение прогнозов, агрегируя ансамбли моделей и используя при этом 
произвольную агрегирующую функцию
, будет впоследствии рассматриваться в 
алгоритме стэкнига и блендинга
.




Веса можно настраивать обычным способом, а можно ввести дополнительные требования из логики задачи:





Вместо классической L2-регуляризации мы приближаем веса к равномерным 

. Тогда даже для больших 

 модель будет сдвигаться к разумной стратегии - равномерному усреднению прогнозов базовых моделей, а не к константному нулю.


Добавление смещения
Если базовые модели систематически переоценивают или недооценивают прогноз, то в агрегирующую модель можно добавить смещение 

, которое мы не будем подвергать регуляризации.
Предыдущая страница
Аналитическое решение для гребневой регрессии
Следующая страница
Регрессия опорных векторов
© 2023-25 
Виктор Китов.
 
Новости проекта.









Регрессия опорных векторов | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Линейная регрессия
Аналитическое решение для линейной регрессии
Регуляризация в линейной регрессии
Аналитическое решение для гребневой регрессии
Линейный ансамбль моделей
Регрессия опорных векторов
Orthogonal matching pursuit
Локально-линейная регрессия
Дополнительная литература
Вопросы
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Линейная регрессия и её обобщения
Регрессия опорных векторов
Содержание этой страницы
Регрессия опорных векторов


Ранее мы везде настраивали коэффициенты 
линейной регрессии
 минимизируя квадрат ошибки:





Но их можно настраивать, используя и другие функции потерь, более соответствующие смыслу задачи!


Например, когда для нас несущественны небольшие отклонения в пределах 

, а сверх этого потери возрастают линейно, то можно использовать для настройки 

-нечувствительную функцию потерь (

-insensitive loss):





Регрессия опорных векторов
 (support vector regression) - это линейная регрессия, веса которой настраиваются, используя 

-нечувствительную функцию потерь с L2-регуляризацией. На графике ниже показан пример настроенной регрессии опорных векторов по точкам (слева) и 

-нечувствительная функция потерь (справа):


[IMAGE]


После настройки метода все объекты обучающей выборки разделятся на опорные (support vectors) и неинформативные (non-informative vectors).


Опорные объекты (выше обозначены желтыми кружками):






прогнозируются с ошибкой по модулю больше или равной 

;






влияют
 на наклон прогнозирующей гиперплоскости .






В свою очередь, неинформативные объекты (обозначены зелёными кружками):






прогнозируются с ошибкой по модулю меньше 

;






не влияют
 на наклон прогнозирующей гиперплоскости, поскольку на них функция потерь равна нулю.






Именно опорные объекты определяют решение задачи. Если же исключить неинформативные объекты из выборки, то итоговое решение не поменяется, поскольку потери на них равны нулю.




Если число опорных объектов невелико (а его можно контролировать, изменяя 

), то можно интерпретировать модель, анализируя объекты, повлиявшие на решение.




Обобщение метода (kernel trick)
Оптимизационную задачу для регрессии опорных векторов и формулу для построения прогноза можно переформулировать так, что прогноз будет зависеть только от скалярных произведений между векторами 

, а не от самих векторов 

. Методы, для которых выполнено это свойство, можно обобщить через ядра (применить так называемый 
kernel trick
 
[1]
), заменив все скалярные произведения на другую функцию, удовлетворяющую ряду свойств и называемую 
ядром Мерсера
:

Регрессию опорных векторов таким образом можно обобщить и превратить из линейного метода в нелинейный!


Более детально с регрессией опорных векторов, её обобщениями и реализациями алгоритмов настройки параметров вы можете ознакомиться в 
[1]
.


Литература
​






Wikipedia: kernel method.






Smola A. J., Schölkopf B. A tutorial on support vector regression //Statistics and computing. – 2004. – Т. 14. – С. 199-222.




Предыдущая страница
Линейный ансамбль моделей
Следующая страница
Orthogonal matching pursuit
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Orthogonal matching pursuit | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Линейная регрессия
Аналитическое решение для линейной регрессии
Регуляризация в линейной регрессии
Аналитическое решение для гребневой регрессии
Линейный ансамбль моделей
Регрессия опорных векторов
Orthogonal matching pursuit
Локально-линейная регрессия
Дополнительная литература
Вопросы
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Линейная регрессия и её обобщения
Orthogonal matching pursuit
Содержание этой страницы
Orthogonal matching pursuit


Orthogonal Matching Pursuit
  регрессия (OMP regression, 
[1]
) - это комбинация отбора признаков и линейной регрессии, в которой строится максимально точная линейная модель с числом признаков, равным 

.


Алгоритм применяется, когда число признаков слишком велико и требуется построить компактную модель, зависящую лишь от небольшого их числа. Это полезно для повышения интерпретируемости модели, повышения скорости её работы и уменьшения переобучения.


Будем использовать следующие обозначения:







 - множество всех признаков,







 - разность множеств (множество элементов 

, не содержащихся в 

),







 - число элементов множества 

.






Алгоритм итеративный, в котором на каждой итерации расширяется число используемых признаков 

 на единицу, а вектор ошибок текущей итерации на всех объектах выборки обозначим через 

.


Алгоритм OMP-регрессии работает следующим образом:




Начальное множество признаков - пустое множество, а начальная модель - тождественный ноль:




Поскольку начальная модель - тождественный ноль, то ошибки в начале совпадают с верными ответами:




пока 

:






выбрать признак 

, у которого максимальная корреляция с ошибками текущей модели 

.






добавить этот признак в число отобранных: 







обучить линейную регрессию предсказывать 

, используя только отобранные признаки из 







обновить вектор 

 ошибками обновлённой модели








Таким образом, алгоритм OMP 
жадным образом
 (greedy search) добавляет максимально скоррелированные признаки с откликом по одному, пока не наберёт необходимое количество. В число признаков должна входить константа 1, чтобы модель могла выучить смещение.


Можно досрочно прерывать алгоритм, как только средние потери модели становятся ниже заданного порога. В этом случае достаточное число признаков может быть и меньше 

.


Альтернативный подход
Для построения модели с минимальным числом признаков также можно использовать 
лассо-регрессию
 с гиперпараметром 

 подбираемым таким образом, чтобы настроенная модель зависела только от 

 признаков.


Литература
​




Rubinstein R., Zibulevsky M., Elad M. Efficient implementation of the K-SVD algorithm using batch orthogonal matching pursuit //Cs Technion. – 2008. – Т. 40. – №. 8. – С. 1-15.


Предыдущая страница
Регрессия опорных векторов
Следующая страница
Локально-линейная регрессия
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Локально-линейная регрессия | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Линейная регрессия
Аналитическое решение для линейной регрессии
Регуляризация в линейной регрессии
Аналитическое решение для гребневой регрессии
Линейный ансамбль моделей
Регрессия опорных векторов
Orthogonal matching pursuit
Локально-линейная регрессия
Дополнительная литература
Вопросы
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Линейная регрессия и её обобщения
Локально-линейная регрессия
Содержание этой страницы
Локально-линейная регрессия


В традиционной линейной регрессии прогноз строится как линейная комбинация признаков:





где веса находятся 
из принципа минимизации наименьших квадратов
:





Обратим внимание, что формула (1) предполагает глобальную линейную связь между признаками и откликами. Но как быть, если реальная зависимость нелинейна? Один из вариантов - добавлять нелинейные трансформации в число признаков. Другой подход - использовать линейную зависимость, но 
со своими коэффициентами для каждого объекта
 

, что реализуется в алгоритме 
локально-линейной регрессии
 (local linear regression, locally weighted scatterplot smoothing, LOWESS 
[1]
), в которой прогноз 

 также строится по формуле (1), однако параметры 

 находятся по объектам, лежащим недалеко от 

, за счёт минимизации 
взвешенной
 суммы квадратов ошибок:





Как видим, объекты 

 учитываются с весами 

, где вес каждого объекта определяется 
близостью
 к прогнозируемому объекту 

: чем он ближе, тем его вес больше. Это позволяет вычислять коэффициенты линейной регрессии 
адаптивно к той точке, в которой нужно построить прогноз
. В другой точке 

 зависимость также будет линейной, но уже с другими коэффициентами.




Поэтому прогнозная функция для всевозможных 

 уже будет получаться 
нелинейной
.




Веса 

 вычисляются по тем же формулам, что и веса 
локально-постоянной регрессии
.


По сравнению с 
локально-постоянной регрессией
, локально-линейный вариант более вычислительно трудоёмкий, поскольку необходимо заново находить минимум (2) для каждого тестового объекта 

. Зато он более гибкий. В частности локально-линейная регрессия лучше экстраполирует зависимости в областях, где обучающих примеров мало, как показано на рисунке по краям:


[IMAGE]


Литература
​




Wikipedia: local regression.


Предыдущая страница
Orthogonal matching pursuit
Следующая страница
Дополнительная литература
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Дополнительная литература | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Линейная регрессия
Аналитическое решение для линейной регрессии
Регуляризация в линейной регрессии
Аналитическое решение для гребневой регрессии
Линейный ансамбль моделей
Регрессия опорных векторов
Orthogonal matching pursuit
Локально-линейная регрессия
Дополнительная литература
Вопросы
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Линейная регрессия и её обобщения
Дополнительная литература
Содержание этой страницы
Дополнительная литература


Мы рассмотрели линейную регрессию, её предположения, свойства, обобщения и способы внесения регуляризации в модель. Далее в отдельном разделе будут описаны методы 
численной оптимизации
 для настройки параметров линейной регрессии и других моделей.


Дополнительно по теме вы можете прочитать соответствующие главы учебника ШАД 
[1]
 и учебника А. Г. Дьяконова 
[2]
. Особенности реализации линейных моделей на python вы можете прочитать документации библиотеки sklearn 
[3]
.


Литература
​






Учебник ШАД: линейные модели.






Дьяконов А.Г. Машинное обучение и анализ данных: линейная регрессия.






Документация sklearn: linear models.




Предыдущая страница
Локально-линейная регрессия
Следующая страница
Вопросы
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Вопросы для самопроверки | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Линейная регрессия
Аналитическое решение для линейной регрессии
Регуляризация в линейной регрессии
Аналитическое решение для гребневой регрессии
Линейный ансамбль моделей
Регрессия опорных векторов
Orthogonal matching pursuit
Локально-линейная регрессия
Дополнительная литература
Вопросы
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Линейная регрессия и её обобщения
Вопросы
Вопросы для самопроверки




В каких случаях лучше использовать линейную регрессию, а в каких - метод K ближайших соседей для построения прогнозов?


Зачем используется регуляризация? В каких случаях лучше использовать L1-регуляризацию, а в каких - L2-регуляризацию?


В каких ситуациях по сути оценка весов линейной регрессии не будет определена? Почему?


Какой гиперпараметр в гребневой и LASSO-регрессии отвечает за выразительную сложность (гибкость) модели? Его увеличение увеличивает или уменьшает  сложность модели?


От объектов, удовлетворяющих какому свойству, будет зависеть решение регрессии опорных векторов? А от каких не будет? Почему?


Почему при линейной комбинации прогнозов различных базовых моделей, веса при моделях необходимо настраивать не на той же самой выборке, на которой настраивались базовые модели? Приведите иллюстративный пример.


Почему важно всегда включать константный признак в список признаков метода Orthogonal Matching Pursuit регрессии?


Приведите примеры задач, в которых оправдано использование 

-нечувствительных потерь.


Предыдущая страница
Дополнительная литература
Следующая страница
Оценка качества регрессии
© 2023-25 
Виктор Китов.
 
Новости проекта.









Меры оценки качества регрессионных прогнозов | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Меры оценки качества регрессионных прогнозов
Конечные меры эффективности
Поточечный график
Вопросы
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Оценка качества регрессии
Меры оценки качества регрессионных прогнозов
Содержание этой страницы
Меры оценки качества регрессионных прогнозов


В задаче регрессии строится прогноз 

 вещественной целевой переменной 

.


О качестве регрессионных прогнозов судят по ошибкам модели на объектах отдельной 
валидационной выборки
.





Несмещённая оценка качества
Напомним, что оценивать качество работы модели необходимо на данных, которые 
модель увидела впервые
, а не на тех данных, на которых настраивались параметры модели. Иначе мы получим слишком оптимистичные ошибки.
Причём данные для оценки не могут быть в валидационной выборке, если она  использовалась для подбора гиперпараметров, поскольку в этом случае модель уже использовала эти данные! Для несмещённой оценки качества в этом случае необходима третья 
независимая выборка
.


Ниже будут приведены популярные функции оценки качества регрессионных прогнозов. Но важно помнить, что итоговый выбор меры качества должен как можно точнее оценивать 
реальные потери заказчика от ошибок прогнозирования
 (например, в рублях), поскольку именно ради минимизации этих потерь модель машинного обучения и внедряется!


Mean squared error (MSE)
​


Среднеквадратичная ошибка
 (mean squared error, MSE) используется как для настройки параметров модели, так и для оценки её качества на новых данных, и считается по формуле:





Коэффициент детерминации
​


Коэффициент детерминации 

 по сути определяется также среднеквадратичной ошибкой и вычисляется по формуле:





Он принимает значения от 

 до 1. Чем он выше, тем прогноз в среднем лучше по сравнению с прогнозированием константой, в качестве которой берется средний отклик. Значение 1 соответствует идеально точным прогнозам, а значение 0 - прогнозам, по качеству неотличимым от прогнозирования средним значением.


Root mean squared error (RMSE)
​


Корень из среднеквадратичной ошибки
 (root mean squared error (RMSE)) вычисляется по формуле:





и её рекомендуется использовать вместо MSE, поскольку она будет измерять ошибку в той же размерности, в которой строится прогноз. Например, если предсказывается сколько клиент потратит на сервис в рублях, то RMSE будет измерять погрешность также в рублях, в то время как MSE будет измерять погрешность в рублях в квадрате (руб
2
) и будет несравнимой напрямую со значением прогноза.


Mean absolute error (MAE)
​


Средний модуль ошибки
 (mean absolute error, MAE) вычисляется по формуле:





MAE измеряется в той же размерности, что и прогнозируемая величина. По сравнению с RMSE, MAE обладает преимуществом, что её значение меньше подвержено влиянию отдельных нетипичных объектов, на которых мы получили очень большую ошибку прогноза.


MSE и RMSE будут учитывать 
не саму величину ошибки, а её квадрат
, что приведёт к завышенному влиянию на них наблюдений-выбросов.


Доля плохо предсказанных объектов
​


Чтобы 
сосредоточить внимание на плохо спрогнозированных объектах
, можно вычислять долю объектов, на которых ошибка оказалась выше определённого порога 

:





Эта мера полезна для контроля доли ситуаций, в которых модель дала совсем неудовлетворительный прогноз.


Средняя относительная ошибка
​


Часто важно не абсолютное значение ошибки, а относительное. Например, при прогнозировании спроса на редко покупаемые товары, такие как автомобили, ошибка на 1,2,3 может оказаться существенной. Но эта же величина ошибки будет несущественной, если речь идёт о часто покупаемых товарах, таких как молоко и хлеб, поскольку оцениваемая величина для магазина измеряется в тысячах. Для этого усредняют не абсолютные, а относительные значения ошибки, как показано ниже.


Макроусреднённая относительная ошибка
​


MAPE
 (mean absolute percentage error) вычисляет 
макроусреднённую
 (macro averaged) относительную ошибку по формуле:





Если в качестве откликов возможны нулевые значения 

, то, чтобы не делить на ноль, можно штрафовать прогнозы нуля большой, но фиксированной константой, либо нормировать в этих случаях на небольшую положительную константу 

:





Микроусреднённая относительная ошибка
​


Мера 
WAPE
 (weighted average percentage error) вычисляется как 
микроусреднение
 относительных ошибок (micro averaging) по формуле:





Такая мера ошибки полезна при прогнозировании спроса на товары, которые покупаются редко (т.е. часто 

).


Задача
Минимизация MSE будет эквивалентна оптимизации каких из вышеприведённых критериев? Почему?


Мы привели самые популярные способы оценки качества регрессии. Оценке качества классификации будет посвящён 
отдельный раздел учебника
. Вы также можете ознакомиться с методами оценки качества регрессии и классификации в учебнике ШАД 
[1]
 и учебнике А. Г. Дьяконова 
[2]
.


Чтобы понять, насколько высокий результат обеспечивает наша модель необходимо сравнить значение критерия для выбранной модели и 
общепринятых моделей, используемых в данной предметной области
, называемых бейзлайнами (baselines).


Оптимизация по целевым мерам качества


Оптимизация параметров модели
​


Меры MAE и WAPE также можно оптимизировать напрямую, но для этого придётся в качестве потерь задавать модули, а не квадраты ошибок, и использовать для этого уже 
численную оптимизацию
, реализованную в большинстве пакетов машинного обучения.


Для минимизации MAPE и MAPE' можно минимизировать модули ошибок, где каждый объект учитывается взвешенным образом с весом 

 и 

 соответственно.


подсказка
Регрессионные прогнозы лучше оценивать не по стандартной мере качества, а по 
целевой мере потерь
, которая максимально близко соответствует реальным потерям (например, в рублях) при тех или иных ошибках прогнозирования.


Оптимизация гиперпараметров модели
​


Гиперпараметры модели
 также рекомендуется подбирать, оптимизируя 
целевую меру потерь
. Это легко сделать, поскольку чаще всего гиперпараметры подбираются перебором по сетке или другим безградиентным методом оптимизации. Поэтому целевая мера не обязательно должна быть дифференцируемой.


Литература
​




Учебник ШАД: метрики классификации и регрессии.


Дьяконов А.Г. Машинное обучение и анализ данных: функции ошибки в задачах регрессии.


Предыдущая страница
Оценка качества регрессии
Следующая страница
Конечные меры эффективности
Mean squared error (MSE)
Коэффициент детерминации
Root mean squared error (RMSE)
Mean absolute error (MAE)
Доля плохо предсказанных объектов
Средняя относительная ошибка
Макроусреднённая относительная ошибка
Микроусреднённая относительная ошибка
Оптимизация параметров модели
Оптимизация гиперпараметров модели
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Конечные меры эффективности | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Меры оценки качества регрессионных прогнозов
Конечные меры эффективности
Поточечный график
Вопросы
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Оценка качества регрессии
Конечные меры эффективности
Конечные меры эффективности


Решая задачи, мы реализуем некоторую сложную многосоставную бизнес-цель. Например, пытаемся максимизировать лояльность пользователя при использовании нашего сервиса, которая зависит от удобства сервиса, выгодных цен, индивидуальных предложений, наличия товаров на складе, скорости обслуживания.


Для успешного решения задачи важно как-то 
квантифицировать
 (quantify) достижение цели в виде измеримого ключевого показателя эффективности (key performance indicators, KPI). Например, измерять лояльность можно по средней оценке пользователей, доле положительных отзывов на сервис и доле вернувшихся пользователей среди существующих в следующем месяце.


Отслеживание KPI
При работе бизнеса нужно динамически отслеживать KPI и его динамику во времени, подобно тому, как при лечении пациента отслеживается его температура, давление и другие ключевые показатели здоровья.


Стандартные меры качества прогнозов, предлагаемые в этом учебнике, оценивают лишь один из факторов, влияющих на общую эффективность. Например:






точность рекомендаций в списке рекомендованных товаров;






качество прогноза спроса на товары перед их доставкой на склад;






вероятность заинтересованности клиента в спец. предложении.






По историческим данным можно оценить влияние этих метрик на конечный KPI, например, линейно:





После подобной оценки можно на качественном уровне оценивать влияние отдельных мер качества на итоговую эффективность всего бизнеса и судить о том, модели с какими мерами качества нам подходят, а с какими - нет.
Предыдущая страница
Меры оценки качества регрессионных прогнозов
Следующая страница
Поточечный график
© 2023-25 
Виктор Китов.
 
Новости проекта.









Поточечный график | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Меры оценки качества регрессионных прогнозов
Конечные меры эффективности
Поточечный график
Вопросы
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Оценка качества регрессии
Поточечный график
Поточечный график


Для визуализации качества регрессионных прогнозов строят 
поточечный график
 (scatter plot), показывающий зависимость предсказанных откликов от реальных, то есть визуализируют множество точек







Прогнозы будут тем лучше, чем ближе они будут лежать к диагональной прямой 

.




Рассмотрим следующую одномерную зависимость признака от отклика в осях 

:


[IMAGE]


Тогда в осях 

 прогнозы будут выглядеть так:


[IMAGE]


По второму графику сразу видно, что модель систематически занижает прогнозы для малых 

 и для больших, а для средних наоборот завышает. Это можно использовать для более тонкой настройки регрессионной модели.


По близости точек к диагонали можно судить о точности прогнозов. Также по графику легко можно идентифицировать выбросы - это будут те точки, которые сильно отклоняются от диагонали.


Визуализация в случае большого числа объектов
Если наблюдений слишком много, то вместо поточечной визуализации можно строить эмпирическое распределение плотности точек, например, в виде двумерной гистограммы.
Предыдущая страница
Конечные меры эффективности
Следующая страница
Вопросы
© 2023-25 
Виктор Китов.
 
Новости проекта.









Вопросы для самопроверки | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Меры оценки качества регрессионных прогнозов
Конечные меры эффективности
Поточечный график
Вопросы
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Оценка качества регрессии
Вопросы
Вопросы для самопроверки




Какие меры ошибки регрессионных прогнозов выдают результат в той же шкале и имеют ту же размерность, что и прогноз? (например, если прогнозируем килограммы, то и ошибка тоже будет иметь размерность килограммов)


Что соответствует идеальному прогнозу, а что - максимально плохому? Какая ситуация соответствует нулевому значению?


Опишите пример ситуации, когда мера ошибки должна быть несимметрична, т.е. недооценка и переоценка прогноза приводят к разному ущербу. Предложите формулу, по которой вы бы оценивали модель в этой ситуации.


Как вы можете проинтерпретировать ситуацию, когда мера MAPE оказалась большой, а мера WAPE низкой?


Предыдущая страница
Поточечный график
Следующая страница
Линейная классификация
© 2023-25 
Виктор Китов.
 
Новости проекта.









Линейная классификация | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Линейная классификация
Оценка весов линейного классификатора
Бинарная логистическая регрессия
Многоклассовая логистическая регрессия
Метод опорных векторов
Дополнительная литература
Вопросы
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Линейная классификация
Линейная классификация
Содержание этой страницы
Линейная классификация


Напомним из 
более ранней главы
, что задача классификации состоит в предсказании дискретного отклика:





и осуществляется по правилу





где 

 - дискриминантные функции, измеряющие рейтинг класса для объекта 

.


Линейный многоклассовый классификатор
​


Линейный многоклассовый классификатор
 (linear multiclass classifier) - классификатор, у которого все дискриминантные функции могут быть представлены в виде линейных функций:





Для спецификации линейного классификатора нужно задать 

 смещений 

 и 

 векторов из коэффициентов при каждом признаке 

. Таким образом, для спецификации достаточно 

 параметров.


На самом деле меньше...
Поскольку дискриминантные функции определены с точностью до сдвига на произвольную функцию (докажите!), то можно всегда смещать на 

, получая, что рейтинг последнего класса будет равен тождественному нулю. И для эквивалентной спецификации линейного классификатора будет достаточно всего 

 параметров.


Граница между 

-м и 

-м классом определяется из условия:





Поскольку это линейное уравнение, то границы между парой классов всегда будет линейной гиперплоскостью, а областью отнесения объектов к определённому классу будет выпуклый многогранник как пересечение выделяющих этот класс полуплоскостей относительно каждого из альтернативных классов.


Линейный бинарный классификатор
​


Линейный бинарный классификатор
 (linear binary classifier) решает задачу классификации на два класса, называемые положительным и отрицательным:





Как правило, в качестве положительного класса выбирают целевой класс, представляющий интерес и требующий дальнейшей обработки, а в качестве отрицательного - фоновый. Например, при классификации, болен ли пациент или здоров, больных относят к положительному классу, а здоровых - к отрицательному. Обычно положительный класс встречается реже, чем отрицательный.


Прогноз для линейного бинарного классификатора строится по правилу:





где мы ввели обозначения:





а функция 

 извлекает знак аргумента:





Величина 

 является 
относительной дискриминантной функцией
 или 
относительным рейтингом
. Она характеризует насколько положительный класс лучше подходит для объекта 

, чем отрицательный.


Геометрическая интерпретация
​


Расстояние от 

 до гиперплоскости 

, задаваемым уравнением





можно посчитать как





Доказательство этого факта приведено ниже.


Обратим внимание, что это расстояние 
со знаком
, то есть оно может быть как положительным, так и отрицательным, в зависимости от того, 
с какой именно стороны точка лежит от гиперплоскости
.


Из последней формулы видно, что относительная дискриминантная функция пропорционально с коэффициентом 

 расстоянию (со знаком) от точки 

 до разделяющей гиперплоскости.






Если она принимает большие по модулю значения, то 

 лежит в глубине того или иного класса, а если малые - то у границы между классами.






По знаку дискриминантной функции можно судить о том, с какой именно стороны от разделяющей гиперплоскости оказался объект.






Если дискриминантная функция равна нулю, то объект попадает строго на границу между классами.






Вектор нормали
​


Утверждение:


Вектор 

, задающий гиперплоскость





является нормалью (перпендикулярным вектором) к этой гиперплоскости.


Доказательство:


Пусть 

 — две произвольные точки гиперплоскости. По определению гиперплоскости имеем:





Вычислим разность:





Перепишем:





Вектор 

 лежит в гиперплоскости 

 и является произвольным направляющим вектором этой плоскости. Из равенства выше следует, что 

 ортогонален любому вектору, лежащему в 

.


Следовательно, 

 является нормалью к гиперплоскости 

.





Расстояние до гиперплоскости
​


Утверждение:


Расстояние от точки 

 до гиперплоскости





выражается формулой





Доказательство:


Пусть 

 — ортогональная проекция точки 

 на гиперплоскость 

. Тогда, поскольку 

 - вектор нормали, существует число 

 такое, что





Поскольку 

, по определению гиперплоскости выполняется





Подставим выражение для 

:





Раскроем скобки:





Так как 

, выразим 

:





Расстояние от точки 

 до гиперплоскости равно длине вектора 

:








Литература
​




Math.stackexchange: distance from a point to a hyperplane.


Предыдущая страница
Линейная классификация
Следующая страница
Оценка весов линейного классификатора
Линейный многоклассовый классификатор
Линейный бинарный классификатор
Геометрическая интерпретация
Вектор нормали
Расстояние до гиперплоскости
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Оценка весов линейного классификатора | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Линейная классификация
Оценка весов линейного классификатора
Бинарная логистическая регрессия
Многоклассовая логистическая регрессия
Метод опорных векторов
Дополнительная литература
Вопросы
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Линейная классификация
Оценка весов линейного классификатора
Содержание этой страницы
Оценка весов линейного классификатора


Отступ линейного бинарного классификатора
​


Как выводилось 
ранее
, отступ бинарного классификатора 

 с относительной дискриминантной функцией 

 определяется как





В случае линейного бинарного классификатора 

 он записывается как





где 

.


По смыслу отступ служит непрерывной мерой качества классификации объекта 

 - чем он выше, тем классификация лучше. Если 

, то классификация корректна, а если 

, то некорректна.


Численная оценка весов линейного бинарного классификатора
​


Как подобрать оптимальные параметры 

 и 

? В общем случае оптимальные веса нельзя найти аналитически, поэтому для их нахождения используются 
численные методы
.


Их можно было бы подбирать таким образом, чтобы минимизировать число неправильных классификаций, что эквивалентно критерию





c функцией потерь 

.


Однако эта функция принимает всего два значения: единицу с одной стороны разделяющей гиперплоскости 

 и ноль с другой. В результате критерий  получится кусочно-постоянной (ступенчатой) функцией, у которой почти всюду градиент по весам 
будет равен нулю
, вследствие чего мы не сможем найти веса 
численными методами
, основанными на градиенте функции!


Поэтому на практике используется не представленная выше кусочно-постоянная функция потерь, а другие гладкие (
непрерывно-дифференцирируемые
) функции с невырожденными градиентами на широком спектре значений.


Основные функции потерь
​


Основные функции потерь, используемые для настройки линейных бинарных классификаторов, приведены ниже:


название
английское название
формула 

экспоненциальная
exponential

функция персептрона
perceptron

шарнирная
hinge

логистическая
logistic



Графики функций потерь показаны ниже:


[IMAGE]


Какая из представленных функций остановит обучение весов сразу, как только точность классификации достигнет 100% точности на обучающей выборке?
Функция персептрона, поскольку для верно классифицированных объектов отступ 

 будет положителен, а функция потерь станет равной нулю. Это 
не является оптимальной стратегией
, поскольку граница между классами может пройти очень близко к объектам, а новые объекты тестовой выборки могут попадать уже с неверной стороны от разделяющей гиперплоскости и неверно классифицироваться.
Другие же функции потерь продолжат обучение, чтобы провести линейную гиперплоскость дальше даже от верно классифицированных объектов. В результате они окажутся глубже в областях своих классов. И при появлении новых объектов, похожих на обучающие, они всё равно будут классифицироваться правильно.


Какая из представленных функций наименее устойчива к 
нетипичным объектам-выбросам
?
Объект-выброс лежит далеко от основной массы объектов и, соответственно, будет, скорее всего, лежать далеко от разделяющей гиперплоскости и иметь высокий отступ по абсолютной величине. А если он неверно классифицируется, то отступ будет большим по модулю и отрицательным. Сильнее всего это будет штрафоваться 
экспоненциальной функцией потерь
. Поэтому эта функция потерь не рекомендуется на практике, если в выборке могут быть нетипичные объекты-выбросы.


Регуляризация
​


Как и 
в случае линейной регрессии
, при настройке линейных классификаторов рекомендуется использовать регуляризацию:





Гиперпараметр 

 контролирует сложность (гибкость) модели. L1- и ElasticNet-регуляризации способны отбирать признаки, зануляя часть коэффициентов при признаках, а L2-регуляризация - нет. Однако L2-регуляризация равномернее распределяет влияние на отклик похожих признаков.


Влияние масштаба признаков
​


Прогнозы линейного классификатора без регуляризации не зависят от масштабирования признаков (при последующей перенастройке модели). Но если использовать регуляризацию, то больший эффект начинают оказывать признаки с большим разбросом значений.


Почему?
Потому что признакам с малым разбросом будут соответствовать более высокие по модулю значения весов, которые будут сильнее подвергаться регуляризации и прижиматься к нулю. Поэтому соответствующие признаки будут влиять на прогноз слабее.


В связи с этим рекомендуется предварительное приведение всех вещественных признаков к одному масштабу одним из 
методов нормализации признаков
.




Далее мы рассмотрим частные случаи бинарного классификатора - 
метод опорных векторов
 и 
логистическую регрессию
, после чего обобщим логистическую регрессию 
на многоклассовый случай
. В отдельном разделе учебника будут рассмотрены методы 
численной настройки
 параметров моделей.


Дополнительно погрузиться в тему вы можете, прочитав соответствующие главы учебника ШАД 
[1]
 и учебника А.Г. Дьяконова 
[2]
.


Литература
​






Учебник ШАД: линейные модели.






Дьяконов А.Г. Машинное обучение и анализ данных: линейные классификаторы.




Предыдущая страница
Линейная классификация
Следующая страница
Бинарная логистическая регрессия
Отступ линейного бинарного классификатора
Численная оценка весов линейного бинарного классификатора
Основные функции потерь
Регуляризация
Влияние масштаба признаков
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Бинарная логистическая регрессия | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Линейная классификация
Оценка весов линейного классификатора
Бинарная логистическая регрессия
Многоклассовая логистическая регрессия
Метод опорных векторов
Дополнительная литература
Вопросы
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Линейная классификация
Бинарная логистическая регрессия
Содержание этой страницы
Бинарная логистическая регрессия


Идея метода
​




Логистическая регрессия
 (logistic regression) - это частный случай 
линейной классификации
, когда для оценки весов используется 
логистическая функция потерь
.




Достоинством метода является то, что он может выдавать не только метки классов, но и  
их вероятности
.


Для удобства обозначений включим дополнительный признак, равный тождественной единице, в число признаков:





Тогда линейный бинарный классификатор можно переписать в более компактном виде:





Эквивалентно логистическая регрессия может быть переформулирована в виде 
вероятностной модели
, выдающей вероятность положительного класса по правилу:





где график сигмоидной функции 

 представлен ниже:


[IMAGE]


Она удовлетворяет следующему свойству:





поэтому





Таким образом, для 

 вероятностный прогноз строится по правилу:





Оценим 

 методом условного максимального правдоподобия:





Поскольку максимизация положительной функции эквивалентна минимизации обратной к ней, то исходная задача эквивалентна следующей:





Прологарифмировав критерий, получим классическую задачу минимизации эмпирического риска с 
логистической функцией потерь
 (logistic loss):





Пример запуска в Python
​


Логистическая регрессия для бинарной классификации:


from
 sklearn
.
linear_model 
import
 LogisticRegression
from
 sklearn
.
metrics 
import
 brier_score_loss
from
 sklearn
.
metrics 
import
 accuracy_score
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_classification_data
(
)
  
model 
=
 LogisticRegression
(
C
=
1
,
 penalty
=
'l2'
)
    
# инициализация модели, (1/C) - вес при регуляризаторе
model
.
fit
(
X_train
,
 Y_train
)
     
# обучение модели   
Y_hat 
=
 model
.
predict
(
X_test
)
   
# построение прогнозов
print
(
f'Точность прогнозов: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
  
P_hat 
=
 model
.
predict_proba
(
X_test
)
  
# можно предсказывать вероятности классов
loss 
=
 brier_score_loss
(
Y_test
,
 P_hat
[
:
,
1
]
)
  
# мера Бриера на вероятности положительного класса
print
(
f'Мера Бриера ошибки прогноза вероятностей: 
{
loss
:
.2f
}
'
)
  




Больше информации
. 
Полный код
.


Настраивать логистическую регрессию можно различными численными методами. Их сравнение приводится в 
[1]
. В следующей главе мы рассмотрим 
обобщение логистической регрессии
 для решения задачи многоклассовой классификации.


Больше информации о логистической регрессии вы можете прочитать в 
[2]
, [[3]](
Дьяконов А.Г. Машинное обучение и анализ данных: линейные классификаторы.
) и [4].


Литература
​




Minka T. P. A comparison of numerical optimizers for logistic regression //Unpublished draft. – 2003. – С. 1-18.


Предыдущая страница
Оценка весов линейного классификатора
Следующая страница
Многоклассовая логистическая регрессия
Идея метода
Пример запуска в Python
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Многоклассовая логистическая регрессия | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Линейная классификация
Оценка весов линейного классификатора
Бинарная логистическая регрессия
Многоклассовая логистическая регрессия
Метод опорных векторов
Дополнительная литература
Вопросы
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Линейная классификация
Многоклассовая логистическая регрессия
Многоклассовая логистическая регрессия


Существует обобщение логистической регрессии и для решения задачи 
многоклассовой классификации
, в которой прогнозируемая величина принадлежит одному из 

 классов:





Многоклассовый линейный классификатор
, как известно, определяется 

 дискриминантными функциями, измеряющими рейтинг каждого из классов:







Для компактности записи смещение не указано, поскольку здесь мы добавили константную единицу в число признаков.




В модели 
многоклассовой логистической регрессии
 предполагается связь 

 с вероятностями классов через 
SoftMax-преобразование
:





для каждого класса 

.


Как видим, SoftMax-преобразование переводит 

-мерный вектор рейтингов классов в 

-мерный вектор выходов, которые:






неотрицательны;






суммируются в единицу.






Таким образом, выходы SoftMax можно трактовать как 
вероятности классов
.


Веса полученной вероятностной модели нужно оценивать 
методом максимального правдоподобия
.


Более компактное представление
Поскольку дискриминантные функции определены с точностью до сдвига на общую функцию (обоснуйте!), то, сдвигая каждый раз найденные дискриминантные функции на 

, получим эквивалентный классификатор с рейтингом последнего класса, равным тождественному нулю.
Поэтому, не ограничивая общности, можно сразу положить 

 и находить только вектора весов 

. Число параметров модели тогда снизится с 

 до 

.
Предыдущая страница
Бинарная логистическая регрессия
Следующая страница
Метод опорных векторов
© 2023-25 
Виктор Китов.
 
Новости проекта.









Метод опорных векторов | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Линейная классификация
Оценка весов линейного классификатора
Бинарная логистическая регрессия
Многоклассовая логистическая регрессия
Метод опорных векторов
Дополнительная литература
Вопросы
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Линейная классификация
Метод опорных векторов
Содержание этой страницы
Метод опорных векторов


Метод опорных векторов
 (support vector machine, SVM 
[1]
) является одним из самых популярных метод классификации. Его популярности способствует:






Геометрическая интерпретация - в линейно разделимом случае бинарной классификации он разделяет классы таким образом, чтобы обеспечить 
максимальное расстояние от ближайших объектов разных классов до разделяющей гиперплоскости
, что способствует высокой 
обобщающей способности
 метода.






Возможность выразить формулу построения прогноза через скалярные произведения одних объектов на другие. Заменяя скалярные произведения на другие функции (из определённого класса) можно обобщить метод, 
превратив его из линейного классификатора в нелинейный
.






Далее мы рассмотрим геометрическое обоснование метода опорных векторов в случае, когда классы линейно разделимы. Потом обобщим метод на случай линейно неразделимых классов. В конце рассмотрим обобщение метода опорных векторов на многоклассовый случай и приведём пример запуска метода в python, используя библиотеку sklearn.


Бинарная классификация
​


Линейно разделимый случай
​


Рассмотрим бинарную классификацию в случае, когда классы 
линейно разделимы
 (linearly separable), то есть когда существует линейная гиперплоскость, безошибочно разделяющая классы на объектах обучающей выборки.


Как видно на рисунке ниже, в линейно разделимом случае решение будет неоднозначным - существует много гиперплоскостей, разделяющих объекты разных классов:


[IMAGE]


При этом способ разделения справа является более предпочтительным, поскольку 
зазор
 (margin, пограничная полоса между объектами разных классов) шире, что обеспечивает более высокую обобщающую способность классификатора при применении его к новым данным тестовой выборки.




Действительно, при предположении, что объекты одного класса похожи друг на друга, новые объекты красного класса будут появляться рядом с известными представителями красного класса. То же справедливо и для новых представителей зелёного класса. Если гиперплоскость проведена таким образом, чтобы быть максимально удалённой от представителей каждого класса, то 
вероятность ошибки на новых данных будет ниже
!




Формализуем критерий нахождения гиперплоскости таким образом, чтобы максимизировать расстояние до представителей каждого класса.


Гиперплоскость 

 разделяет классы 

, если выполнены следующие условия:





где 

 - некоторый параметр. Это проиллюстрировано ниже:


[IMAGE]


Параметры 

 определены с точностью до общего положительного множителя, поэтому, не ограничивая общности, условие разделимости можно записать в виде:





где мы разделили неравенства на 

. Это равнозначно выбору 

.


Условие разделимости классов можно эквивалентно записать одной строкой:





Теперь среди всех гиперплоскостей, разделяющих классы, мы бы хотели выбрать ту, которая будет 
максимизировать пограничную полосу между классами
, называемую 
зазором
 (margin). Для этого нужно, чтобы расстояние от ближайших объектов обучающей выборки 

  до гиперплоскости 

 оказалось наибольшим.


Как показывалось 
ранее
, это расстояние равно:





Поскольку ближайшие объекты будут лежать на гиперплоскостях 

, а 

 взят равным единице, то расстояние от гиперплоскости до ближайших объектов будет 

, а зазор будет равен 

.


Отсюда получаем оптимизационную задачу для нахождения безошибочного линейного классификатора, обеспечивающего максимизацию зазора:





Используя свойство





получим окончательный вид оптимизационной задачи для нахождения весов метода опорных векторов 
в линейно разделимом случае
:





Интуиция оптимизационной задачи
Оптимизационную задачу выше можно проинтерпретировать как нахождение такого линейного классификатора, который:




обеспечивает уверенную классификацию всех объектов (с отступом не ниже единицы)






является максимально простым за счёт минимизации L2-нормы весов.






Заметим, что решение будет зависеть только от объектов, имеющих отступ 

, которые лежат на гиперплоскостях





и называются 
опорными векторами
 (support vectors).




Включение/исключение других объектов с отступом 

 не будет оказывать влияния на решение, поэтому такие объекты называются 
неинформативными
 (non-informative).




Линейно неразделимый случай
​


В общем случае классы не будут линейно разделимыми, то есть не будет существовать гиперплоскости, безошибочно разделяющей классы, как показано ниже:


[IMAGE]


Синими векторами помечены объекты, нарушающие условия разделимости:







Если бы мы применили линейно разделимый метод опорных векторов к неразделимым данным, то получили бы пустое множество решений, поскольку обеспечить безошибочную классификацию (и неотрицательный отступ) для всех объектов невозможно!




Чтобы находить решение и для случая линейно неразделимых данных, каждому объекту разрешается отклоняться от требования





на величину нарушения 

. При этом, чтобы минимизировать возможные нарушения, суммарная величина всех нарушений штрафуется в оптимизационном критерии, что даёт оптимизационную задачу метода опорных векторов 
в линейно неразделимом случае
:





Эта задача для любых данных 
всегда имеет решение
 при достаточно больших нарушениях 

 и представляет собой итоговую оптимизационную задачу по умолчанию для метода опорных векторов.




Гиперпараметр 

 управляет противоречием между точностью модели и её простотой. Подумайте как именно.




В отличие от задачи (1), в (2) оптимизация 
дополнительно производится
 по величинам нарушений 

, оптимальные значения для которых легко найти:





поскольку







;






при 

 неравенство на отступ в (2) не нарушено, и 

;






при 

 

 должно выбираться минимально возможным, чтобы удовлетворить неравенству, то есть равным 

.






Подставляя оптимальные значения 

 из (3) в (2), получим эквивалентную 
безусловную
 задачу оптимизации:





что соответствует 
оценке линейного бинарного классификатора






с функцией потерь hinge;






и L2-регуляризацией.






L1-SVM
​


В качестве популярной вариации метода опорных векторов используется метод L1-SVM 
[2]
, в котором веса штрафуются не по квадрату L2-нормы, а по L1-норме, что даёт следующую задачу условной оптимизации:





которая эквивалентная безусловной оптимизации:





Штраф весов по L1-норме способен 
в точности занулять веса
 при оптимизации, что делает прогноз зависимым лишь от части наиболее информативных признаков. Такая возможность полезна, когда заранее известно, что используется 
много слабо информативных и нерелевантных признаков
.


Многоклассовая классификация
​


Рассмотрим многоклассовую классификацию, в которой 

. Решить эту задачу можно набором бинарных классификаторов, как описано в 
следующей главе
.


Однако для метода опорных векторов существует модификация, позволяющая производить многоклассовую классификацию напрямую (multiclass support vector machines 
[3]
).


В предложенном подходе настраиваются коэффициенты многоклассового классификатора с 
функциями рейтинга
 для каждого класса:





Прогноз строится, назначая класс, обладающий максимальным рейтингом.


Линейно разделимый случай
​


В 
линейно разделимом случае
 веса предлагается находить из следующей оптимизационной задачи:







По сути требуется найти найти максимально простой классификатор (по L2-норме весов), выдающий рейтинги для верных классов, которые хотя бы на единицу превосходят рейтинги для неправильных классов.




Линейно неразделимый случай
​


В более общем линейно неразделимом случае (по умолчанию) объектам разрешается отклоняться от ограничения на рейтинги на величины нарушений 

, которые штрафуются по величине:





Последнюю задачу можно эквивалентно переписать в виде безусловной оптимизации, как показано ниже.


Переход к безусловной оптимизации
​


Из второго ограничения (5):





Следовательно, чтобы удовлетворить всем условиям, 

 должно быть не меньше максимального нарушения по всем 

:





С учётом 

 получаем:





Это обобщение 
функции потерь hinge
 на многоклассовый случай:





где 

 — вектор оценок рейтингов для всех классов.


Подставив 

 в функционал, получим:





В 
[4]
 приводится эмпирическое сравнение различных вариантов многоклассового метода опорных векторов.


Обобщение метода через ядра
​


Решение условных задач оптимизации (2) и (5), используя условия Каруша-Куна-Таккера 
[5]
, можно свести к двойственной задаче оптимизации, из которой формулу построения прогноза можно выразить как зависимость не от самих признаковых описаний объектов, а от попарных скалярных произведений между объектами:





Это позволяет применить 
ядерное обобщение метода
 (kernel method, 
[6]
) заменяя операции стандартного скалярного произведения специальными функциями 

 - 
ядрами Мерсера
 (Mercer kernel 
[7]
):





Ядра Мерсера соответствуют обычному скалярному произведению, но не в исходном пространстве признаков 

, а в нелинейно преобразованном 

:





что соответствует превращению линейного метода опорных векторов в нелинейный метод классификации!


Дополнительно ознакомиться с методом опорных векторов можно 
[8]
.


Пример запуска в Python
​


Пример запуска метода опорных векторов для двух классов:


from
 sklearn
.
svm 
import
 SVC   
from
 sklearn
.
metrics 
import
 accuracy_score
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_classification_data
(
)
  
model 
=
 SVC
(
C
=
1
)
                
# инициализация модели, (1/C) - вес при регуляризаторе
model
.
fit
(
X_train
,
 Y_train
)
     
# обучение модели   
Y_hat 
=
 model
.
predict
(
X_test
)
   
# построение прогнозов
print
(
f'Точность прогнозов: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
  
# Можно считать информацию по опорным векторам:
print
(
f'Число опорных векторов к каждом классе: 
{
model
.
n_support_
}
'
)
print
(
model
.
support_vectors_
[
:
5
]
)
   
# выводим первые 5 опорных векторов
model 
=
 SVC
(
kernel
=
'rbf'
,
 gamma
=
1
)
   
# инициализация модели с использованием Гауссова ядра
model
.
fit
(
X_train
,
 Y_train
)
          
# обучение модели   
Y_hat 
=
 model
.
predict
(
X_test
)
        
# построение прогнозов
print
(
f'Точность прогнозов: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
    




Больше информации
. 
Полный код
.


Литература
​






Cortes C., Vapnik V. Support-vector networks //Machine learning. – 1995. – Т. 20. – С. 273-297.






Zhu J. et al. 1-norm support vector machines //Advances in neural information processing systems. – 2003. – Т. 16.






Crammer K., Singer Y. On the algorithmic implementation of multiclass kernel-based vector machines //Journal of machine learning research. – 2001. – Т. 2. – №. Dec. – С. 265-292.






Hsu C. W., Lin C. J. A comparison of methods for multiclass support vector machines //IEEE transactions on Neural Networks. – 2002. – Т. 13. – №. 2. – С. 415-425.






Wikipedia: Условия Каруша — Куна — Таккера.






Wikipedia: kernel method.






Викиконспекты ИТМО: Ядра.






Викиконспекты ИТМО: метод опорных векторов.




Предыдущая страница
Многоклассовая логистическая регрессия
Следующая страница
Дополнительная литература
Бинарная классификация
Линейно разделимый случай
Линейно неразделимый случай
L1-SVM
Многоклассовая классификация
Линейно разделимый случай
Линейно неразделимый случай
Переход к безусловной оптимизации
Обобщение метода через ядра
Пример запуска в Python
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Дополнительная литература | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Линейная классификация
Оценка весов линейного классификатора
Бинарная логистическая регрессия
Многоклассовая логистическая регрессия
Метод опорных векторов
Дополнительная литература
Вопросы
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Линейная классификация
Дополнительная литература
Содержание этой страницы
Дополнительная литература


Мы рассмотрели решение задачи классификации линейными методами, изучили самые популярные частные случаи: метод опорных векторов и логистическую регрессию. В отдельном разделе будут описаны методы 
численной оптимизации
 для настройки параметров моделей.


Дополнительно по теме вы можете прочитать соответствующие главы учебника ШАД 
[1]
, учебника А. Г. Дьяконова 
[2]
, а также [3] и [4].


Литература
​






Учебник ШАД: линейные модели.






Дьяконов А.Г. Машинное обучение и анализ данных: линейные классификаторы.






Webb A. R., Copsey K.D. Statistical pattern recognition. – John Wiley & Sons, 2011.






Мерков А. Б. Распознавание образов. Построение и обучение вероятностных моделей // Москва: Эдиториал УРСС. – 2014.




Предыдущая страница
Метод опорных векторов
Следующая страница
Вопросы
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Вопросы для самопроверки | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Линейная классификация
Оценка весов линейного классификатора
Бинарная логистическая регрессия
Многоклассовая логистическая регрессия
Метод опорных векторов
Дополнительная литература
Вопросы
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Линейная классификация
Вопросы
Вопросы для самопроверки




Сформулируйте модельные предположения линейного классификатора.


В чем преимущества и недостатки линейного классификатора по сравнению с классификацией методом K ближайших соседей?


Почему, если в классификаторе все дискриминантные функции сдвинуть на одинаковую функцию от 

, то получим эквивалентный классификатор?


Чему равно общее число настраиваемых параметров в линейном бинарном и линейном многоклассовом классификаторе?


Почему для настройки весов линейного бинарного классификатора нельзя использовать напрямую принцип минимизации числа ошибок прогноза?


В чём недостаток использования функции потерь персептрона для настройки линейного бинарного классификатора?


Каким геометрическим свойством обладает решение метода опорных векторов?


Предыдущая страница
Дополнительная литература
Следующая страница
Многоклассовая классификация набором бинарных классификаторов
© 2023-25 
Виктор Китов.
 
Новости проекта.









Метод один-против-всех | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Метод один-против-всех
Метод один-против-одного
Кодирование с исправлением ошибок
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Многоклассовая классификация набором бинарных классификаторов
Метод один-против-всех
Содержание этой страницы
Метод один-против-всех


Метод один-против-всех
 (one-vs-all, one-vs-rest) позволяет решать задачу многоклассовой классификации с помощью набора бинарных классификаторов.


Для этого для каждого класса 

 настраивается собственный бинарный классификатор отличать этот класс от всех остальных, то есть предсказывать отклик





Полученный классификатор будет определять, верно ли, что объект 

 принадлежит классу 

, или нет по правилу:





с некоторой обученной для этого 
относительной дискриминантной функцией
 

.


Тогда решающее правило для исходной многоклассовой классификации будет определяться по правилу





то есть будет назначаться тот класс, за который будет голосовать классификатор этого класса с самой большой уверенностью.


Это решающее правило очень похоже на 
общий вид многоклассового классификатора
 с тем лишь отличием, что для нахождения всех дискриминантных функций необходимо обучить 

 
отдельных бинарных классификаторов
 на одной и той же выборке, но с разными откликами.


Реализацию метода один-против-всех см. в документации sklearn 
[1]
.


Литература
​




Документация sklearn: OneVsRestClassifier.


Предыдущая страница
Многоклассовая классификация набором бинарных классификаторов
Следующая страница
Метод один-против-одного
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Метод один-против-одного | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Метод один-против-всех
Метод один-против-одного
Кодирование с исправлением ошибок
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Многоклассовая классификация набором бинарных классификаторов
Метод один-против-одного
Содержание этой страницы
Метод один-против-одного


Метод один-против-одного
 (one-vs-one) представляет собой альтернативный метод многоклассовой классификации с помощью набора бинарных классификаторов.


Для начала рассмотрим похожую задачу, когда у нас есть 

 футбольных команд, и нам нужно определить среди них самую сильную. Мы не можем заставить играть одновременно больше двух команд, поэтому проведём матчи между каждой парой команд. Всего таких пар будет 

. Самой сильной командой тогда можно назначить ту команду, которая победила в максимальном числе матчей. Если лучшие команды побеждали одинаковое число раз, то назначим самой лучшей среди них ту, которая при этом ещё забила в соревнованиях наибольшее число голов.


Аналогично работает и метод один-против-одного. Настраивается 

 бинарных классификаторов, определяющих, какой класс лучше подходит объекту, 
если выбирать только между 

-м и 

-м классом
:





Настройка каждого такого классификатора производится по подвыборке объектов, принадлежащих либо 

-му, либо 

-му классу.


Далее для нового объекта тестовой выборки назначается тот класс, 
который побеждает в максимальном числе попарных сравнений этого класса с другими классами
. Если несколько классов побеждают другие одинаковое число раз, то среди них выбирается тот, который побеждает остальных 
с максимальной суммой относительных дискриминантных функций соответствующих классификаторов.


Сложность оценивания
Метод один-против-одного требует оценки 

 бинарных классификаторов, в то время как метод один-против-всех - только 

 классификаторов. Однако в первом методе оценка производится каждый раз 
по подвыборке объектов
 двух соответствующих классов, в том время как во втором методе - каждый раз по всем объектам выборки.
Поэтому, несмотря на то, что классификаторов нужно оценить больше, совокупное время оценивания может получиться меньше, если сложность настройки модели нелинейно возрастает с объемом обучающей выборки, как, например, в 
ядерно обобщённом методе опорных векторов
.


Каким методом, одним-против-одного или одним-против-всех, вычислительно сложнее строить прогноз? 
Если считать, что сложность прогнозирования каждым бинарным классификатором примерно одинаковая, то метод один-против-одного сторит прогнозы быстрее, поскольку для него нужно пропустить объект через 

 классификаторов, в то время как для метода один-против-одного - уже через 

 классификаторов.


Реализацию метода на python см. в документации sklearn 
[1]
.


Литература
​




Документация sklearn: OneVsOneClassifier.


Предыдущая страница
Метод один-против-всех
Следующая страница
Кодирование с исправлением ошибок
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Кодирование с исправлением ошибок | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Метод один-против-всех
Метод один-против-одного
Кодирование с исправлением ошибок
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Многоклассовая классификация набором бинарных классификаторов
Кодирование с исправлением ошибок
Содержание этой страницы
Кодирование с исправлением ошибок


Метод кодирования с исправлением ошибок
 (error-correcting output codes 
[1]
) также решает задачу многоклассовой классификации с помощью набора бинарных классификаторов.


Для этого каждому классу назначается свой 
бинарный код
 (binary code) - 

-мерный вектор, состоящий только из нулей и единиц, которые, в отличие от 
one-hot кодирования
, могут содержать и несколько единиц в кодировке.


Пример кодирования классов 5-мерными бинарными кодами (

):


класс
код
1
[0,0,0,0,0]
2
[0,1,1,1,0]
3
[1,1,1,1,1]


Далее вектор откликов представляется кодировочной матрицей 

, полученной из исходного вектора классов 

 заменой каждого класса его бинарным кодом, как показано ниже:


y
Y'
1
[0,0,0,0,0]
1
[0,0,0,0,0]
2
[0,1,1,1,0]
3
[1,1,1,1,1]
2
[0,1,1,1,0]


После этого обучаются 

 бинарных классификаторов, обучающихся предсказывать отдельные биты бинарного представления класса для объектов.


Для классификации нового объекта эти 

 классификаторов применяются к объекту, предсказывая его бинарный код. В итоге назначается тот класс бинарный код которого ближе всего к предсказанному.




Заметим, что совпадение может быть не идеальным, поскольку часть бит могла быть предсказана неверно!




Вычислительная эффективность
Этот метод может работать с минимальной длиной кодовых слов (равной 

), обеспечивающей однозначное восстановление классов по их кодовым представлениям (обоснуйте, почему такого числа бит достаточно!). В этом случае он будет строить прогнозы 
вычислительно эффективнее
, чем методы один-против-всех и один-против-одного, требующие запуска 

 и 

 бинарных классификаторов соответственно.


Точность прогнозов
На практике используются более длинные кодовые слова, чем минимально необходимо для однозначного восстановления классов. В этом случае, даже если небольшая часть классификаторов ошибётся и неверно предскажет свои биты кодового слова, 
сохранится возможность восстановить верный класс
!


Стандартные реализации метода используют случайно сгенерированные кодовые слова. Повысить точность метода может использование кодовых слов, которые 
максимально удалёны друг от друга
 по 
расстоянию Хэмминга
.


Другой подход повышения точности - предсказывать не сами биты кодовой последовательности, а вероятность единицы в каждом бите. Именно в такой конфигурации метод и реализован в библиотеках. Точность повышается за счёт того, что учёт вероятностей позволяет более тонко различать 
уверенности прогнозов каждого бита
.


Например, для кодирования классов, представленного выше, мы могли получить для нового объекта следующее кодовое слово [0,0,0,1,0], которое ближе всего к [0,0,0,0,0], то есть к кодировке первого класса. Однако вероятности единицы могли оказаться [0,0.4,0.4,1,0], что указывает на то, что скорее всего это прогноз для [0,1,1,1,0], то есть второго класса, поскольку L1-норма расхождения вероятностей будет ниже:








Описание реализации метода в библиотеке sklearn см. в 
[2]
.


Литература
​






Dietterich T. G., Bakiri G. Solving multiclass learning problems via error-correcting output codes //Journal of artificial intelligence research. – 1994. – Т. 2. – С. 263-286.






Документация sklearn: OutputCodeClassifier.




Предыдущая страница
Метод один-против-одного
Следующая страница
Численная оптимизация
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Численные методы оптимизации | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Численные методы оптимизации
Метод градиентного спуска
Метод стохастического градиентного спуска
Мониторинг сходимости
Стохастический градиентный спуск с инерцией
Метод Ньютона
Вопросы
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Численная оптимизация
Численные методы оптимизации
Содержание этой страницы
Численные методы оптимизации


Оптимальные веса модели находятся 
методом минимизации средних потерь
 на обучающей выборке. Для функции потерь 

 общего вида это 
нельзя сделать аналитически
 и приходится использовать численные методы оптимизации.


Применение, даже если аналитическое решение существует
Интересно, что применение численных методов может быть вычислительно эффективнее, даже когда аналитическое решение существует! Например, решение линейной регрессии

хоть и можно выразить аналитически, но для расчёта оно требует обращения матрицы 

, требующего вычислений порядка 

. Численные методы могут найти приближённое решение, используя меньший объём вычислений!


Численные методы, описанные в этом разделе, основаны на вычислении 
градиента
 

, представляющего собой вектор из частных производных потерь по каждому параметру модели:





Градиент полезен, поскольку он указывает направление максимального возрастания функции 

 в пространстве весов, а 
антиградиент
 

 - направление максимального убывания 

.


Почему?
Разложим 

 в ряд Тейлора (см. 
[1]
) первого порядка, чтобы получить локально линейную аппроксимацию функции потерь:

Если перебирать всевозможные направления 

 единичной длины, то из неравенства Коши-Буняковского (см. 
[2]
) получим, что наибольший локальный рост (для малых 

) достигается, когда 

 сонаправлен 

, а максимальный спад - когда 

 и 

 направлены в противоположные стороны.
Используя это свойство, градиентные методы оптимизации уменьшают функцию потерь, 
многократно сдвигая веса в направлении антиградиента функции потерь с малым шагом
. Такие методы называются 
градиентными методами оптимизации
 (gradient based, см. 
[3]
) в противоположность 
безградиентным методам
 (gradient free).


Оптимизация без градиента
Иногда приходится оптимизировать функцию, 
не располагая её градиентом
. Такая ситуация возникает, когда мы можем функцию вычислить в каждой точке, но не можем представить в аналитическом виде, чтобы её можно было продифференцировать.
Например, это может быть выручка магазина при различных расположениях товаров на полках или качество решения задачи машинного обучения при различных значениях гиперпараметров. В этом случае используются безградиентные методы оптимизации, такие как Байесовская оптимизация, генетические (эволюционные) алгоритмы, метод Tree-structured Parzen Estimator, алгоритм имитации отжига, случайный поиск или перебор по сетке значений - см. 
[4]
.


Литература
​






Викиконспекты ИТМО: формула Тейлора для произвольной функции.






Wikipedia: Cauchy–Schwarz inequality.






Wikipedia: gradient method.






Wikipedia: derivative-free optimization.




Предыдущая страница
Численная оптимизация
Следующая страница
Метод градиентного спуска
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Метод градиентного спуска | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Численные методы оптимизации
Метод градиентного спуска
Метод стохастического градиентного спуска
Мониторинг сходимости
Стохастический градиентный спуск с инерцией
Метод Ньютона
Вопросы
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Численная оптимизация
Метод градиентного спуска
Содержание этой страницы
Метод градиентного спуска


Идея метода
​


Метод градиентного спуска
 (gradient descent 
[1]
) минимизирует функцию потерь, 
итеративно сдвигая веса на антиградиент этой функции с небольшим весом
.


Псевдокод метода:




инициализируем 

 случайно


пока не выполнено условие остановки:


                    





Здесь 

 - гиперпараметр, характеризующий 
шаг обновления весов
 (learning rate). Он выбирается небольшой константой.


В качестве 
условия остановки
 обычно выбирается условие, что от итерации к итерации функция потерь 
перестаёт существенно меняться
. Также можно допустить досрочное окончание оптимизации, если достигнуто максимальное число итераций.


Аналогия с путником в горах
Поскольку антиградиент 

 показывает 
локальное направление максимального уменьшения функции
, метод градиентного спуска можно уподобить путнику, заблудившемуся ночью в горах, который, пытаясь спуститься вниз как можно быстрее, каждый раз делает шаг в направлении наиболее крутого склона.
Кстати, так можно и скатиться с обрыва! Чтобы не улететь, путник использует альпинистское снаряжение, чтобы упасть не больше чем на длину страхующей веревки. Аналогично и в методе градиентного спуска, если рельеф функции потерь резко меняется, то можно допускать сдвиги по величие не больше, чем на заранее заданный порог безопасности, ограничивая  норму градиента, на который осуществляют сдвиг:

Такой подход называется 
обрезкой градиента
 (gradient clipping 
[1]
) и часто используется в настройке нейросетей, где функция потерь имеет сложный рельеф с резкими перепадами. Эта проблема особенно актуальна при настройке сложных нейросетевых моделей.


Выбор шага обучения
​


Гиперпараметр 

 выбирается пользователем и представляет собой небольшую величину, влияющую на характер сходимости. Если 

 выбрать слишком малым, то потребуется очень много шагов оптимизации, чтобы дойти до минимума. Если, наоборот, его выбрать слишком большим, то метод может расходиться. Эти ситуации показаны на рисунке слева и справа соответственно:


[IMAGE]


Для подбора 

 необходимо построить зависимость функции потерь 

 от номера итерации  

  и выбрать 

 таким, чтобы сходимость была максимально быстрой, и не возникало расходимости:


[IMAGE]


Ускорение сходимости
Дополнительно ускорить сходимость может 
нормализация признаков
 (приведение их к одному масштабу). Это позволяет отчасти решить проблему "вытянутых долин" в рельефе функции потерь, из-за которых приходится выбирать маленький шаг, чтобы не разойтись вдоль быстро меняющихся направлений.


Выбор начального приближения
​


В методе градиентного спуска начальное значение весов 

 инициализируется случайно. В случае выпуклой функции потерь любой глобальный минимум является глобальным (докажите!), поэтому старт из разных начальных приближений приведёт к решению того же качества.




Если же функция потерь невыпукла, то она может содержать много локальных минимумов, и выбор начального приближения 
может влиять на то, к какому минимуму алгоритм оптимизации в итоге сойдётся
! Поэтому для невыпуклых потерь предлагается запускать алгоритм несколько раз из разных начальных приближений, а потом выбрать наилучшее решение (обеспечивающее минимальное значение функции потерь).




Также стоит отметить, что выбор начального приближения ближе к предполагаемому минимуму уменьшит число итераций до сходимости и ускорит настройку модели.


Условия сходимости
​


Для сходимости метода достаточно, чтобы функция потерь была непрерывно-дифференцируема, выпукла вниз в окрестности оптимума, удовлетворяла условию Липшица (имела ограниченную производную), а шаг обучения был достаточно мал. Детальнее об методе градиентного спуска, условиях и скорости его сходимости можно прочитать в 
[3]
.


Литература
​






Wikipedia: gradient descent.






Geeksforgeeks: understanding gradient clipping.






Ахмеров Р.Р. Методы оптимизации гладких функций.




Предыдущая страница
Численные методы оптимизации
Следующая страница
Метод стохастического градиентного спуска
Идея метода
Выбор шага обучения
Выбор начального приближения
Условия сходимости
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Метод стохастического градиентного спуска | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Численные методы оптимизации
Метод градиентного спуска
Метод стохастического градиентного спуска
Мониторинг сходимости
Стохастический градиентный спуск с инерцией
Метод Ньютона
Вопросы
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Численная оптимизация
Метод стохастического градиентного спуска
Содержание этой страницы
Метод стохастического градиентного спуска


Идея метода
​


Вспомним, что функция потерь в машинном обучении представляет собой 
эмпирический риск
, то есть средние потери по объектам обучающей выборки:





Рассмотрим детальнее метод 
градиентного спуска
 с учётом вида функции потерь:




инициализируем 

 случайно


пока не выполнено условие остановки:


                    





Получается, что на каждом шаге алгоритма необходимо вычислять производные функции потерь 
на всех объектах обучающей выборки
, которых может быть очень много!


Это приводит к медленной работе метода. При этом, поскольку алгоритм состоит из многих итераций с малым шагом 

, нам совсем не обязательно вычислять точное значение градиента 

, а достаточно сдвигаться лишь 
примерно в сторону уменьшения функции
.


Идея метода 
стохастического градиентного спуска
 (stochastic gradient descent, SGD) заключается в использовании быстро вычислимой аппроксимации эмпирического риска для расчета градиента. Для этого используется приближение средними потерями на 

 
случайных объектах
:





где 

 - индексы 

 случайных объектов обучающей выборки, называемых 
минибатчом
 (minibatch). Используя эту аппроксимацию, получим  метод стохастического градиентного спуска:




инициализируем настраиваемые веса 

 случайно


пока не выполнено условие остановки:


             случайно выбрать 

 объектов 

 из 



                    





Как видим, одна итерация стохастического градиентного спуска выполняется за 

 операций, а не за 

, как в обычном методе градиентного спуска, причём 

 мы выбираем сами, и он берётся 
намного меньше
 

!


Поскольку по каждой итерации метода минибатч сэмплируется случайно, то, при достаточном числе итераций, алгоритм всё равно обойдет все объекты выборки.


На практике объекты обучающей выборки переставляются в случайном порядке, а затем извлекаются последовательно по 

 штук за раз. Однократный проход по всем объектам обучающей выборки называют 
эпохой
 (epoch).


Онлайн-обучение
В режиме онлайн-обучения (online learning 
[1]
) обучающие объекты поступают последовательно, а целевая зависимость часто динамически меняется со временем. Так происходит, например, при прогнозе цен на акции на бирже. В подобных сценариях вместо случайного сэмплирования объектов по всей истории наблюдений чаще сэмплируют недавние, более свежие наблюдения, лучше отражающие текущую зависимость в данных.


Выбор K
​


Если 

 велико, а объекты содержат повторяющуюся информацию, то точность аппроксимации будет высокой при более быстрой сходимости по сравнению с методом градиентного спуска.


Интересно, что метод будет сходиться даже при 

. Конечно, оценка эмпирического риска всего по одному объекту будет очень грубой. Однако, поскольку эта оценка является несмещённой (за счёт случайного выбора объекта), метод всё равно будет сходиться, надо лишь использовать более малый шаг обучения 

. Тогда за увеличенное количество итераций мы сможем обойти существенную часть объектов выборки и в итоге сместить веса в правильную сторону.


На практике 

 выбирают таким, чтобы минибатч помещался в память и векторные операции, связанные с его обработкой, производились за один такт параллельных вычислений устройства.


Сходимость
​


Для сходимости функция потерь должна быть непрерывно-дифференцируемой, выпуклой в окрестности оптимума и удовлетворять условию Липшица (иметь ограниченную производную 
[2]
). Детальнее об условиях сходимости можно прочитать в учебнике ШАД 
[3]
. Важным отличием условий сходимости стохастического градиентного спуска является то, что шаг сходимости должен быть 
не константой 

, а последовательностью 

, стремящейся к нулю в окрестности оптимума.


Действительно, при постоянном шаге, из-за того, что мы сдвигаемся 
не на точный градиент, а на его грубую аппроксимацию
, даже дойдя до оптимума, метод будет совершать случайное блуждание в его окрестности. Для сходимости нужно постепенно уменьшать шаг, как показано ниже справа:


[IMAGE]


Скорость уменьшения шага для сходимости
Формально метод сходится, если шаг удовлетворяет следующим двум условиям:

Например, этому условию удовлетворяет последовательность

На практике шаг часто берут небольшой константой, а потом её уменьшают, когда функция потерь перестаёт устойчиво уменьшаться, после чего продолжают обучение с уменьшенным шагом. Так делают несколько раз, и в библиотеках оптимизации, такой как PyTorch, такая стратегия уже реализована 
[4]
.




Далее в учебнике будет рассмотрено повышение скорости и устойчивости метода стохастического спуска за счёт 
внесения инерции
, а также 
метод Ньютона
 оптимизации второго порядка. Также во второй части учебника по глубокому обучению будут описаны 
специализированные методы оптимизации
 для настройки нейросетей.


Вы также можете прочитать про метод градиентного и стохастического градиентного спуска у викиконспектах ИТМО 
[5]
 и учебнике ШАД 
[6]
. В статье 
[7]
 детально разбираются различные алгоритмы оптимизации и анализируются их преимущества и недостатки.


Литература
​






Wikipedia: online machine learning.






Wikipedia: Lipschitz continuity.






Учебник ШАД: сходимость SGD.






Документация PyTorch: ReduceLROnPlateau.






Викиконспекты ИТМО: cтохастический градиентный спуск.






Учебник ШАД: оптимизация в ML.






Ruder S. An overview of gradient descent optimization algorithms //arXiv preprint arXiv:1609.04747. – 2016.




Предыдущая страница
Метод градиентного спуска
Следующая страница
Мониторинг сходимости
Идея метода
Выбор K
Сходимость
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Мониторинг сходимости | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Численные методы оптимизации
Метод градиентного спуска
Метод стохастического градиентного спуска
Мониторинг сходимости
Стохастический градиентный спуск с инерцией
Метод Ньютона
Вопросы
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Численная оптимизация
Мониторинг сходимости
Содержание этой страницы
Мониторинг сходимости


Для анализа сходимости метода 
стохастического градиентного спуска
 важно смотреть на динамику потерь на каждой итерации алгоритма. Особенно это важно при долгой и трудоёмкой настройке нейросетей,  чтобы на ранней стадии оптимизации увидеть некорректную настройку определённых параметров. Поскольку в стохастическом градиентном спуске сдвиг весов производится на антиградиент по случайному минибатчу объектов, то и величина этого сдвига будет подвержена случайным колебаниям, как в примере ниже:


[IMAGE]


Для большей наглядности нам хотелось бы отслеживать сглаженную версию этой динамики, показанную зелёной кривой. Для этого существуют два подхода - скользящее среднее и экспоненциальное сглаживание. Оба метода на вход принимают зашумлённый временной ряд 

 (в нашем случае - потерь на объектах минибатча), а на выходе выдают его сглаженную версию 

, причем сглаживание осуществляется динамически в каждый момент времени.


Скользящее среднее
​


Идея 
скользящего среднего
 заключается в выдаче усреднения по 

 последним наблюдениям:





Это среднее можно эффективно пересчитывать по формуле





Вначале, пока 

 наблюдений еще не накоплены, нужно усреднять по всем располагаемым наблюдениям.


Экспоненциальное сглаживание
​


Экспоненциальное сглаживание
 вычисляет сглаженную версию временного ряда по следующей формуле:





Гиперпараметр 

 управляет степенью сглаживания.


Как именно 

 влияет на результат?
Увеличение 

 приводит к более слабому учёту новых данных и к более сильному - исторических. Поэтому сглаженный временной ряд 

 будет получаться более гладким. Уменьшение 

 уменьшает сглаживание. В частности, при 

, сглаженный ряд совпадает с исходным.


Если рекуррентно переписать зависимость 

 только от 

, то получим, что экспоненциальное сглаживание выдаёт взвешенное усреднение по всем прошлым наблюдениям с экспоненциально убывающими весами:





Более детально об экспоненциальном сглаживании и его связи со скользящим средним можно прочитать в 
[1]
.


Литература
​




Wikipedia: exponential smoothing.


Предыдущая страница
Метод стохастического градиентного спуска
Следующая страница
Стохастический градиентный спуск с инерцией
Скользящее среднее
Экспоненциальное сглаживание
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Стохастический градиентный спуск с инерцией | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Численные методы оптимизации
Метод градиентного спуска
Метод стохастического градиентного спуска
Мониторинг сходимости
Стохастический градиентный спуск с инерцией
Метод Ньютона
Вопросы
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Численная оптимизация
Стохастический градиентный спуск с инерцией
Содержание этой страницы
Стохастический градиентный спуск с инерцией


Метод стохастического градиентного спуска с инерцией
 (stochastic gradient descent with momentum, SGD+momentum 
[1]
) - это небольшое усложнение 
метода стохастического градиентного спуска
, которое позволяет ускорить сходимость и предотвратить застревание в локальных минимумах с небольшой окрестностью. Также он позволяет быстрее проскакивать точки перегиба и другие области медленных изменений функции потерь.


Напомним метод обычного стохастического градиентного спуска:




инициализируем 

, а начальные веса 

 случайно


пока не выполнено условие остановки:


            сэмплируем случайные объекты 

 из 



            



            



            





Метод стохастического градиентного спуска с инерцией считается аналогично, но в качестве вектора сдвига весов используется не только градиент по объектам минибатча, но и ранее посчитанные градиенты с небольшим весом, задаваемым гиперпараметром 

:




инициализируем 

, а начальные веса 

 случайно


пока не выполнено условие остановки:


            сэмплируем случайные объекты 

 из 



            



            



            





Компонента 

 называется 
инерцией
 (momentum) и позволяет ускорить сходимость за счёт объединения информации о текущем градиенте с ранее посчитанными градиентами. За счёт этого градиент получается менее зашумлённым случайностью выбора объектов текущего минибатча, что позволяет использовать более высокий шаг обучения и ускорить сходимость.




Отметим, однако, что выбор высокого 

 делает метод менее чувствительным к текущему направлению максимального снижения функции, что может, наоборот, замедлить сходимость. На практике чаще всего используют 

.




Рекурсивно подставляя вместо 

 формулу их расчёта, получим, что изменение весов 

 зависит от всех ранее посчитанных градиентов с экспоненциально убывающими весами по номеру итерации (докажите!).


Учёт инерции позволяет проскакивать локальные минимумы с малой окрестностью, сходясь к более устойчивым минимумам с большей окрестностью, как показано на рисунке:


[IMAGE]


Детальное обоснование и анализ метода стохастического градиентного спуска представлено в 
[2]
.


Инерция Нестерова
​


Метод инерции Нестерова (Nestrov momentum 
[3]
) позволяет ещё немного ускорить сходимость за счёт того, что градиент вычисляется в точке, 
более близкой к новой оценке весов
 на следующей итерации:




инициализируем 

, а начальные веса 

 случайно


пока не выполнено условие остановки:


            сэмплируем случайные объекты 

 из 



            



            



            





На шаге 

 мы уже заранее знаем, что веса сдвинутся на величину инерции, поэтому можем считать градиент уже в сдвинутой точке. Подобное заглядывание вперёд позволяет 
заранее сместить градиент
, если на следующей итерации предвидится изменение рельефа функции потерь.


Более продвинутые техники
Для оптимизируемых функций со сложным рельефом (особенно в настройке нейросетей) применяются более продвинутые методы, такие как RMSprop и Adam, ключевая идея которых заключается в том, что шаг обучения 

 вычисляется независимо для каждой компоненты вектора весов. Это связано с тем, что вдоль одних осей в пространстве весов функция потерь меняется быстро, а вдоль других - медленно, поэтому, для ускорения сходимости, целесообразно адаптировать шаг обучения индивидуально для каждой оси. Эти методы 
описаны
 во второй части учебника, посвящённой нейросетям.


Литература
​






Поляк Б. Т. О некоторых способах ускорения сходимости итерационных методов //Журнал вычислительной математики и математической физики. – 1964. – Т. 4. – №. 5. – С. 791-803.






Shi B. On the hyperparameters in stochastic gradient descent with momentum //Journal of Machine Learning Research. – 2024. – Т. 25. – №. 236. – С. 1-40.






Нестеров Ю. Е. Метод минимизации выпуклых функций со скоростью
сходимости O(1/k2) // Доклады АН СССР. 1983. Т. 269, № 3. С. 543–547.




Предыдущая страница
Мониторинг сходимости
Следующая страница
Метод Ньютона
Инерция Нестерова
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Метод Ньютона | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Численные методы оптимизации
Метод градиентного спуска
Метод стохастического градиентного спуска
Мониторинг сходимости
Стохастический градиентный спуск с инерцией
Метод Ньютона
Вопросы
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Численная оптимизация
Метод Ньютона
Содержание этой страницы
Метод Ньютона


Метод оптимизации Ньютона
 (Newton's optimization method) позволяет ускорить метод 
градиентного спуска
 за счёт использования информации не только о градиенте, 
но и о матрице вторых производных
, называемой 
матрицей Гессе
 (Hessian):





Использование вторых производный позволяет ускорить сходимость, поскольку содержит 
информацию о скорости изменения градиента
. Там, где градиент меняется медленно, можно увеличить шаг обучения, а там, где быстро, - замедлить.


Метод Ньютона выглядит следующим образом:




инициализируем настраиваемые веса 

 случайно


пока не выполнено условие остановки:


             





Как видим, за счёт использования информации о вторых производных удалось избавиться от явной спецификации шага обучения - он настраивается автоматически по скорости изменения градиента домножением на матрицу Гессе, состоящую из всех вторых производных функции потерь.




Обратим внимание, что домножение на матрицу подстраивает скорость изменения 
вдоль каждой оси
, используя градиенты 
вдоль всех осей
.




Геометрически метод Ньютона в каждой точке строит параболу (в многомерном пространстве - параболоид), после чего смещает оценку весов в точку минимума этой параболы:


[IMAGE]


Обоснование метода Ньютона
​


Рассмотрим минимизацию дважды дифференцируемой функции потерь 



Пусть 



Тогда 



Разложение Тейлора 

 относительно 

 в точке 

:





откуда





Получаем итоговое правило обновления весов, чтобы (приближённо!) переместиться в точку минимума:





При минимизации 
квадратичной функции
 погрешности 

, её квадратичная аппроксимация будет точной, поэтому метод Ньютона сойдётся за один шаг.


Достоинства и недостатки метода
​


Метод Ньютона обладает более высокой скоростью сходимости, чем метод градиентного спуска. В частности, он находит минимум квадратичного функционала всего лишь за одну итерацию. Однако практическому применению этого метода в машинному обучении мешают два аспекта:






Необходимость хранить в памяти матрицу Гессе, размера 

, а 

 обычно велико при большом числе признаков и при использовании таких перепараметризованных моделей, как нейросети.






Необходимость обращать матрицу Гессе на каждой итерации, что имеет вычислительную сложность 

.








Детальнее о проблемах применения метода Ньютона в машинном обучении можно прочитать обсуждении 
[1]
. Из-за перечисленных проблем на практике чаще используют квазиньютоновские методы 
[2]
, которые используют вычислительно эффективную аппроксимацию метода Ньютона.


Детальнее о методе Ньютона, условиях сходимости и альтернативных методах второго порядка рекомендуется прочитать в учебнике ШАД 
[3]
.


Литература
​






Stats.stackexchange: Why is Newton's method not widely used in machine learning?






Wikipedia: Quasi-Newton method.






Учебник ШАД: методы второго порядка.




Предыдущая страница
Стохастический градиентный спуск с инерцией
Следующая страница
Вопросы
Обоснование метода Ньютона
Достоинства и недостатки метода
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Вопросы для самопроверки | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Численные методы оптимизации
Метод градиентного спуска
Метод стохастического градиентного спуска
Мониторинг сходимости
Стохастический градиентный спуск с инерцией
Метод Ньютона
Вопросы
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Численная оптимизация
Вопросы
Вопросы для самопроверки




Почему веса в градиентных методах оптимизации смещают на антиградиент функции потерь?


В чём заключено преимущество метода стохастического градиентного спуска по сравнению с обычным методом градиентного спуска?


В чем мотивация использования стохастического градиентного спуска с инерцией? При каких условиях он может сходиться медленнее, чем метод градиентного спуска?


Как гиперпараметр 

 влияет на степень экспоненциального сглаживания?


Перечислите преимущества и недостатки метода Ньютона по сравнению с методом градиентного спуска. Обоснуйте, почему он найдёт минимум квадратичной функции всего за одну итерацию.


Предыдущая страница
Метод Ньютона
Следующая страница
Оценка качества классификации
© 2023-25 
Виктор Китов.
 
Новости проекта.









Базовые меры качества многоклассовой классификации | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Базовые меры качества многоклассовой классификации
Специальные меры качества для бинарной классификации
Обобщение бинарных мер качества на многоклассовый случай
ROC-кривая
Лучший классификатор на ROC кривой
Эквивалентное определение AUC
Контроль качества предсказания вероятностей
Дополнительная литература
Вопросы
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Оценка качества классификации
Базовые меры качества многоклассовой классификации
Содержание этой страницы
Базовые меры качества многоклассовой классификации


Ранее мы уже рассматривали 
оценку качества регрессионных прогнозов
, когда целевой отклик - вещественное число 

. Теперь рассмотрим оценку качества прогнозов в задаче классификации, в которой целевая величина принимает одно из 

 дискретных величин:





Несмещённая оценка
Напомним, что качество классификации необходимо оценивать не на обучающей, а на 
отдельной валидационной выборке
, иначе мы получим смещённую оценку качества! Если же валидационная выборка также использовалась для настройки гиперпараметров, то для оценки качества потребуется третья 
независимая выборка
, которая не использовалась ни для настройки параметров, ни для настройки гиперпараметров.


Далее будут приведены различные стандартные меры оценки качества классификации. При этом важно отслеживать их связь с 
конечными мерами качества
 определяющими эффективность задачи, решаемой классификационными моделями.


Точность и частота ошибок
​


Самой простой и популярной мерой качества является 
точность классификации
 (accuracy), которая измеряет долю верных предсказаний:





Максимизация точности эквивалентна минимизации 
частоты ошибок
 (error rate) классификатора, поскольку они связаны следующим соотношением:





Матрица ошибок классификации
​


Точность и частота ошибок дают агрегированную картину по всем классам, по которой мы не можем понять, 
на каких именно классах модель чаще всего ошибалась
.


Для более детального анализа используется матрица ошибок (confusion matrix) 

 , где каждый элемент 

 показывает количество случаев, когда истинный класс был равен 

, но при этом был предсказан классом 

.




На диагонали будут находиться корректные классификации, а внедиагональные элементы будут показывать число ошибок разных типов.




Ниже приведён пример этой матрицы для 3-х классов:






10
3
0

0
20
15

2
5
30


По этой матрице видно, что в целом классификатор хорошо справился с  прогнозированием (диагональные элементы относительно большие). А большая часть ошибок классификатора вызвана тем, что объекты 2-го класса он ошибочно классифицирует 3-м классом. Если классов много, то полезно визуализировать матрицу ошибок в виде 
тепловой карты
 значений (heatmap), как на примере ниже:


[IMAGE]


Как по матрице ошибок вычислить точность классификации (accuracy)?
Для расчёта точности нужно просуммировать все диагональные элементы (общее число верных классификаций) и разделить его на сумму всех элементов матрицы (равную общему числу объектов выборки).


Матрица цен
​


Ошибки классификации различаются тем, какой класс с каким был перепутан. Чаще всего эти ошибки 
неравноценны между собой
.




Например, при классификации электронных писем на "важные", "рассылки" и "спам" не так страшно принять спам за важное письмо и его оставить. Гораздо неприятнее принять важное письмо за спам и его удалить.




Цена ошибки при классификации рассылок меньше, чем при классификации важных писем. Поэтому определяется понятие матрицы ошибок 

, где каждый элемент 

 показывает штраф за неверную классификацию объекта 

-го класса 

-м классом. Диагональные элементы матрицы полагаются равными нулю, поскольку они соответствуют корректным классификациям. Используя матрицу цен, можно вычислять 
средний штраф
 (average cost) при классификации всей выборки:





При какой матрице цен средний штраф совпадёт с частотой ошибок?
При штрафе равном нулю для верных классификаций и единице для неверных.
Предыдущая страница
Оценка качества классификации
Следующая страница
Специальные меры качества для бинарной классификации
Точность и частота ошибок
Матрица ошибок классификации
Матрица цен
© 2023-25 
Виктор Китов.
 
Новости проекта.









Специальные меры качества для бинарной классификации | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Базовые меры качества многоклассовой классификации
Специальные меры качества для бинарной классификации
Обобщение бинарных мер качества на многоклассовый случай
ROC-кривая
Лучший классификатор на ROC кривой
Эквивалентное определение AUC
Контроль качества предсказания вероятностей
Дополнительная литература
Вопросы
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Оценка качества классификации
Специальные меры качества для бинарной классификации
Содержание этой страницы
Специальные меры качества для бинарной классификации


В случае бинарной классификации 

, а соответствующие классы называются положительными и отрицательными. Положительному классу обычно сопоставляют более редкий целевой класс, который мы стремимся обнаружить.




Например, при распознавании болезни пациентов по симптомам положительным классом будет наличие заболевания, а отрицательным - отсутствие.




Матрица ошибок будет размера 

 и каждый элемент этой матрицы имеет своё название:





TP (true positives)
FN (false negatives)

FP (false positives)
TN (true negatives)


Второе слово в названии обозначает прогноз, а первое - за его корректность. Например, ложно-положительные объекты (FP штук) - это объекты, ошибочно предсказанные как положительные, в то время как истинный класс был отрицательный. А ложно-отрицательные объекты (FN штук) были предсказаны как отрицательные, в то время как на самом деле они принадлежали положительному классу.


Как по значениям TP,TN,FP, FN вычислить точность и частоту ошибок классификации?




Меры качества для несбалансированных классов
​


Точность и полнота
​


В случае 
несбалансированных классов
 (unbalanced classes), когда положительный класс встречается 
существенно реже
, чем отрицательный, предложенные меры недостаточны для оценки модели!




Например, если положительный класс встречается в 1% случаев, а отрицательный - в оставшихся 99%, то константный прогноз, всегда назначающий отрицательный класс, будет показывать точность 99%, а частоту ошибок - всего 1%. Однако это никак не будет свидетельствовать об адекватности модели, поскольку она даже не пыталась выделить положительный класс!




Поэтому для таких ситуаций используются специальные меры качества - 
точность
 (precision, не путать с 
accuracy
!) и 
полнота
 (recall):








где мы использовали обозначения:







 - общее число положительный объектов;







 - общее число объектов, 
предсказанных
 как положительные.






Precision показывает долю верно-положительных объектов 
среди всех объектов, предсказанных как положительные
. Например, при классификации болезни - это доля действительно больных пациентов среди всех предсказанных как больные. Precision важен, если мы хотим минимизировать число ложных срабатываний классификатора (предсказаний болезни для здоровых пациентов).


Recall показывает долю верно-положительных объектов среди всех объектов, 
в действительности принадлежащих положительному классу
. В примере выше recall важен, если мы хотим обнаружить всех больных пациентов, пусть и с некоторой долей ложных срабатываний.


Таким образом, precision и recall измеряют различные аспекты качества модели.


F-мера
​


На практике важен и precision, и recall, поэтому считают их среднее гармоническое 
[1]
, называемое F-мерой (F-measure, 

-score):





Почему не используют среднее арифметическое?
Преимущество F-меры по сравнению с обычным усреднением заключается в том, что F-мера будет штрафовать как низкие значения precision, так и низкие значения recall 
одновременно
. В частности, она будет равна нулю, если 
хотя бы один
 из показателей равен нулю.


Обычное же усреднение будет давать 0.5 в случае плохо настроенной модели, когда






Precision 

 1, Recall = 0 (когда только одного пациента, в болезни которого мы максимально уверены, считаем больным);






Precision 

 0, Recall = 1 (когда назначаем больными всех пациентов без разбора).






Будет ли этому свойству удовлетворять среднее геометрическое?
Да, будет, поскольку зависит от произведения этих величин.


Взвешенная F-мера
​


На практике точность и полнота имеют 
разную важность
 для конечной задачи. При идентификации болезни по симптомам важнее полнота (хотим отпустить минимальное число больных с диагнозом "здоров"), а в интернет-поиске важнее точность (хотим вернуть в поисковой выдаче только те страницы, которые действительно релевантны поисковому запросу, пусть и не все релевантные, поскольку их слишком много). Поэтому используется 
взвешенная F-мера
 (weighted F-measure, 

-score):





Более высокое значение 

 будет повышать значение Precision и занижать вклад Recall при агрегации.


Использование мер качества в ранжировании
​


Классификатор часто используется не для прогнозов меток классов, а для сортировки объектов по степени уверенности модели в том, что они принадлежат положительному классу.




Например, компания в первую очередь обзванивает тех клиентов, кому спецпреложение будет максимально интересно. В информационном поиске документы соритруются от более релевантных к менее релевантным.




Поскольку каждый бинарный классификатор 
представим в виде
:





то относительная дискриминантная функция 

 как раз и будет служить оценкой уверенности классификатора в положительном классе для объекта 

, по которой можно отранжировать объекты. Рассмотрим для определённости информационный поиск, в котором по запросу пользователя возвращаются релевантные документы. В подобных задачах задают некоторый порог 

 (предельное число документов, которые пользователь просмотрит в поисковой выдаче), после чего считают меры:






precision@K - долю релевантных документов среди первых 

 в выдаче;






recall@K - долю показанных релевантных документов среди всех релевантных.






Далее можно по ним можно считать взвешенную F-меру. Примеры расчётов precision@K и recall@K можно прочитать в 
[2]
.


Недостатком precision@K и recall@K является то, что эти меры 
никак не зависят
 от порядка следования корректных классификаций среди 

 представленных. А нам бы хотелось, чтобы релевантные объекты (положительного класса) шли именно в начале списка. Мерой, поощряющей выдачу релевантных объектов именно в начале отранжированного списка является 
average precision
.


Average Precision
​


Если варьировать K, то получим 
зависимость точности от полноты
 (precision-recall curve), пример которой приведён ниже:


[IMAGE]


Мы бы хотели получить выше precision при каждом уровне recall, поэтому чем выше этот график, тем качественнее работает классификатор. Агрегированной мерой качества классификации служит площадь под графиком зависимости точности от полноты, которая называется 
Average Precision
 (AP). Она поощряет ситуацию, когда при ранжировании объектов по степени принадлежности положительному классу 
в начале списка идут именно представители положительного класса
.




В случае информационного поиска это будут документы, релевантные поисковому запросу. Поскольку нас интересует качество ранжирующей системы для разных пользователей и поисковых запросов, то величины Average Precision 
усредняют по пользователям и запросам
, получая величину 
Mean Average Precision
.




Пример расчёта Average Precision и Mean Average Precision можно посмотреть в 
[3]
.


Литература
​






Википедия: среднее гармоническое.






EvidentlyAI: Precision and recall at K in ranking and recommendations.






EvidentlyAI: Mean Average Precision (MAP) in ranking and recommendations.




Предыдущая страница
Базовые меры качества многоклассовой классификации
Следующая страница
Обобщение бинарных мер качества на многоклассовый случай
Меры качества для несбалансированных классов
Точность и полнота
F-мера
Взвешенная F-мера
Использование мер качества в ранжировании
Average Precision
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Обобщение бинарных мер качества на многоклассовый случай | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Базовые меры качества многоклассовой классификации
Специальные меры качества для бинарной классификации
Обобщение бинарных мер качества на многоклассовый случай
ROC-кривая
Лучший классификатор на ROC кривой
Эквивалентное определение AUC
Контроль качества предсказания вероятностей
Дополнительная литература
Вопросы
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Оценка качества классификации
Обобщение бинарных мер качества на многоклассовый случай
Содержание этой страницы
Обобщение бинарных мер качества на многоклассовый случай


Меры качества бинарных классификаторов, рассмотренные 
в предыдущем разделе
, могут быть обобщены на многоклассовый случай 

 через 
макроусреднение
 (macroaveraging) т.е. простое усреднение бинарных мер качества по классам:








где







 - количество верных классификаций объектов класса 

,







 - количество объектов класса 

,







 - количество объектов, предсказанных классом 

.






Если же считать 
микроусреднение
 (microaveraging) этих величин, то получим одно и то же число, равное многоклассовой accuracy:








где 

 - общее число объектов в выборке.


Детальный разбор этих характеристик с примерами расчёта можно прочитать в 
[1]
.


Разница между микро- и макроусреднением
Макроусреднение усредняет 
по классам
, независимо от их размера. Если мера качества высокая на частотных классах и низкая на редких, то макроусреднение даст низкий результат, в отличие от микроусреднения, которое усредняет 
по объектам
.


Макроусреднённая по классам величина средней точности 
average precision
 называется 
mean average precision
 (mAP):





Литература
​




EvidentlyAI: accuracy, precision, and recall in multi-class classification.


Предыдущая страница
Специальные меры качества для бинарной классификации
Следующая страница
ROC-кривая
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









ROC-кривая | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Базовые меры качества многоклассовой классификации
Специальные меры качества для бинарной классификации
Обобщение бинарных мер качества на многоклассовый случай
ROC-кривая
Лучший классификатор на ROC кривой
Эквивалентное определение AUC
Контроль качества предсказания вероятностей
Дополнительная литература
Вопросы
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Оценка качества классификации
ROC-кривая
Содержание этой страницы
ROC-кривая


Управление готовностью назначать положительный класс
​


Рассмотрим 
бинарный классификатор
:





Его относительная дискриминантная функция 

 характеризует степень уверенности классификатора в том, что объект принадлежит положительному классу.


Решающее правило можно обобщить, введя порог 

, с которым производится сравнение:





Чем 

 выше, тем более осторожно классификатор начинает предсказывать положительный класс для тех же самых объектов, и наоборот, для более низких 

 положительный класс назначается более охотно. Это полезный параметр, чтобы управлять готовностью назначать объектам положительный класс 
без перенастройки самой модели
.




Рассмотрим задачу кредитного скоринга, в которой для клиентов (объектов 

) нужно предсказывать, вернут они кредит 

 или нет 

, на основе чего принимается решение о выдаче им кредита. Для низких 

 мы более склонны давать кредиты, и это обосновано в периоды экономического подъёма. В периоды же экономического спада разумно выдавать кредиты более осторожно, повысив гиперпараметр 

, причём саму модель при этом перенастраивать не нужно!




Меры TPR и FPR
​


Определим две меры качества бинарной классификации - true positive rate (TPR) и false positive rate (FPR):





где 

 - число объектов положительного и отрицательного класса соответственно.


Мера TPR
 совпадает с 
ранее изученной
 мерой Recall. Также её называют recognition rate, поскольку по смыслу она характеризует долю верных (положительных) детекций 
среди объектов положительного класса
.


Мера FRP
 также называется false alarm rate, поскольку она характеризует долю неверных детекций (положительным классом) 
среди объектов отрицательного класса
.




В примере с кредитным скорингом TPR будет измерять долю клиентов, которые могли бы вернуть кредит, и мы действительно сочли их кредитоспособными. FPR же будет измерять долю клиентов, которые не способны вернуть кредит, но которых мы ошибочно сочли кредитоспособными.




ROC-кривая
​


ROC-кривая
 (ROC-curve, receiver operating characteristic) показывает зависимость 

 от 

 при изменении порога 

. Обе величины изменяются от нуля до единицы по неубывающему закону, как показано на графике:


[IMAGE]


При высоком 

 классификатор будет очень редко назначать положительный класс - только в тех случаях, когда он очень уверен в положительности класса. Тогда:






TPR будет близок к нулю (будет мало верно распознанных объектов положительного класса)






FPR также будет мал (поскольку положительный класс будет назначаться редко).






Если же уменьшать 

, то частота назначения положительного класса будет увеличиваться, увеличивая и TPR, и FPR, 
в результате чего мы прочертим ROC-кривую
.


ROC-кривая для случайного угадывания
Рассмотрим классификатор, который случайно назначает классы, независимо от вектора признаков 

, по формуле

где 

 - равномерно распределённая случайная величина на отрезке 

. Докажите, что ROC-кривая, соответствующая этому классификатору, будет диагональю TPR=FPR. Существуют ли классификаторы, для которых ROC-кривая проходит ниже этой прямой? Можем ли мы извлечь пользу из таких классификаторов?


Построение ROC-кривой по данным
​


При практическом построении ROC-кривой нам не нужно перебирать все вещественные пороги 

, поскольку мы работаем с конечной выборкой





Мы рассчитываем относительную дискриминантную функцию нашего классификатора 

 для каждого объекта и отсортируем все объекты по возрастанию этой функции:





Далее ROC-кривая строится итеративно, стартуя из точки (

)=(0,0) при движении вдоль значений 

 от больших значений к меньшим, перебирая в качестве пороговых 

 только следующие значения:





При сдвиге порога 

 от 

 до 

 прогноз для объект 

 по правилу (1) поменяется с отрицательного на положительный класс. В зависимости от реального класса 

 это будет соответствовать двум разным изменениям на ROC-кривой:






При 

 следующая точка ROC-кривой получается сдвигом вверх на 

, поскольку при этом на один верно-положительный объект станет больше при том же уровне FPR.






При 

 следующая точка ROC-кривой получается сдвигом вправо на 

, поскольку стало на один объект больше среди ложно-положительных срабатываний. FPR увеличится, а TPR останется неизменным.






Пример построения ROC-кривой показан на рисунке:


[IMAGE]




Далее ROC-кривая может сглаживаться линейной интерполяцией между точками.




Площадь под ROC-кривой
​


Чем выше ROC-кривая, тем 
лучше
 классификатор, поскольку нам бы хотелось иметь более высокий TPR при том же уровне FPR.


Агрегированной мерой качества классификации служит 
площадь под ROC-кривой
, называемая 
AUC
 (area under curve).




Классификатору, назначающему классы случайно независимо от входа, будет соответствовать диагональная ROC-кривая, площадь под которой равна 0.5 - см. ROC-кривую для случайного угадывания.






Поскольку ROC-кривая описывает не один классификатор, а целое 
семейство классификаторов
, параметризованных гиперпараметром 

, далее мы рассмотрим 
нахождение наилучшего классификатора
 из этого семейства.


Мы также изучим эквивалентное 
определение величины AUC и способ её численной оптимизации
.
Предыдущая страница
Обобщение бинарных мер качества на многоклассовый случай
Следующая страница
Лучший классификатор на ROC кривой
Управление готовностью назначать положительный класс
Меры TPR и FPR
ROC-кривая
Построение ROC-кривой по данным
Площадь под ROC-кривой
© 2023-25 
Виктор Китов.
 
Новости проекта.









Лучший классификатор на ROC кривой | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Базовые меры качества многоклассовой классификации
Специальные меры качества для бинарной классификации
Обобщение бинарных мер качества на многоклассовый случай
ROC-кривая
Лучший классификатор на ROC кривой
Эквивалентное определение AUC
Контроль качества предсказания вероятностей
Дополнительная литература
Вопросы
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Оценка качества классификации
Лучший классификатор на ROC кривой
Лучший классификатор на ROC кривой


ROC-кривая
 описывает семейство классификаторов, параметризованных параметром 

:





Но как выбрать лучший экземпляр этого семейства?


В бинарной классификации 

, поэтому есть только два типа ошибок:






Назначить объекту положительного класса отрицательный класс
, что реализуется с вероятностью 

. Обозначим штраф за такую ошибку 

.






Назначить объекту отрицательного класса положительный класс
, что реализуется с вероятностью 

. Штраф за эту ошибку обозначим 

.






Тогда средние потери классификатора будут





Отсюда в осях 

 можно получить 
изолинии потерь
 (loss isolines), т.е. множество точек (FPR,TPR), приводящих к одинаковому уровню средних потерь 

:





Поскольку полученная зависимость TRP(FPR) линейна, то это будет прямая линия с положительным наклоном, а более высоким линиям будут отвечать более низкие ожидаемые потери, как показано на рисунке:


[IMAGE]


Отсюда следует, что оптимальным классификатором при заданных парамерах





будет классификатор, соответствующий 
точке касания изолинии потерь и ROC-кривой
.


При изменении одного из этих параметров необязательно перенастраивать модель, а достаточно выбрать другую точку на ROC-кривой, т.е. взять классификатор с другим пороговым значением 

.




Например, в задаче кредитного скоринга в кризис вероятность невозврата кредита 

 существенно вырастает, а для адаптации к этому изменению достаточно лишь изменить порог 

.


Предыдущая страница
ROC-кривая
Следующая страница
Эквивалентное определение AUC
© 2023-25 
Виктор Китов.
 
Новости проекта.









Эквивалентное определение AUC | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Базовые меры качества многоклассовой классификации
Специальные меры качества для бинарной классификации
Обобщение бинарных мер качества на многоклассовый случай
ROC-кривая
Лучший классификатор на ROC кривой
Эквивалентное определение AUC
Контроль качества предсказания вероятностей
Дополнительная литература
Вопросы
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Оценка качества классификации
Эквивалентное определение AUC
Содержание этой страницы
Эквивалентное определение AUC


Каждой точке на 
ROC-кривой
 будет соответствовать классификатор 

 со своим выбором 

. Агрегированной мерой этого семейства классификаторов (при всевозможных значениях 

) выступает 
площадь под ROC-кривой
 (area under curve, AUC).


Идеальный случай
​


Максимальное значение величины AUC=1 и, как следует из 
алгоритма построения ROC-кривой
, оно соответствует ROC-кривой, идущей в осях (FPR,TPR) из (0,0) в (0,1), а затем из (0,1) в (1,1). Классификатор в этом случае идеально упорядочит объекты так, что все объекты с низкими 

 будут принадлежать отрицательному классу, а все объекты с высоким 

 будут принадлежать положительному классу, как показано на рисунке:


[IMAGE]


Для безошибочной классификации достаточно лишь выбрать порог 

, способный безошибочно разделять классы.


Общий случай
​


В общем случае 

 и мера AUC оценивает, насколько сильно ROC-кривая выпукла вверх, что соответствует качеству упорядочивания объектов вдоль оси 

, когда объектам с более низкими 

 соответствуют отрицательные классы, а с более высокими 

 - положительные классы. Сформулируем это утверждение более формально.


AUC как качество упорядочивания объектов
​


Предположим для простоты, что каждому объекту соответствует своё 
уникальное
 значение относительной дискриминантной функции 

.


Рассмотрим пару объектов 

 и 

 отрицательного и положительного классов. Такую пару будем называть:






верно упорядоченной
, если 

;






неверно упорядоченной
, если 

.






Если 

 - общее число объектов положительного и отрицательного класса, то общее количество пар объектов отрицательного и положительного классов будет 

.


Справедливо следующее утверждение:




Площадь под ROC-кривой (AUC) равна доле верно упорядоченных пар объектов выборки:







Доказательство
:  пусть 

 - объекты, упорядоченные по рейтингу:





Каждой точке на ROC-кривой будет соответствовать классификатор:





с показателями качества





Обратим внимание, что 

 не возрастают по 

. Случаю 

 будет соответствовать первая точка на ROC-кривой, а случаю 

 - последняя.


Проинтегрируем справа налево площадь под ROC-кривой по 
формуле трапеций
:





Мы доказали, что 
площадь под ROC-кривой равна доле верно упорядоченных пар объектов
, в которых первый первый объект принадлежит отрицательному классу, а второй - положительному. Таким образом, мера 
AUC оценивает качество упорядочивания объектов
 вдоль значений относительной дискриминантной функции 

.




Отсюда, в частности, следует, что величина AUC не будет изменяться при монотонно возрастающих преобразованиях относительной дискриминантной функции:







Оптимизация AUC
​


Если AUC является конечным критерием качества, то разумно максимизировать именно её, а не другие меры качества. Для этого нужно применять 
численную оптимизацию
.


Сложность заключается в том, что поскольку AUC зависит от индикаторных функций:





Поэтому она является является кусочно-постоянной, поэтому её нельзя оптимизировать градиентными методами оптимизации напрямую.


Зато мы можем приблизить каждый индикатор 

  сигмоидой 

, где 

 - сигмоидная функция (sigmoid), а 

 - гиперпараметр, выбираемый пользователем.


Оценка AUC при этом приближении будет иметь вид





Такая оценка уже будет дифференцируемой функцией, и её можно максимизировать напрямую 
градиентными методами
!




Чем 

 выше, тем точнее будет аппроксимация ступенчатой функции ценой более резких изменений производной и более нестабильного обучения.


Предыдущая страница
Лучший классификатор на ROC кривой
Следующая страница
Контроль качества предсказания вероятностей
Идеальный случай
Общий случай
AUC как качество упорядочивания объектов
Оптимизация AUC
© 2023-25 
Виктор Китов.
 
Новости проекта.









Контроль качества предсказания вероятностей | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Базовые меры качества многоклассовой классификации
Специальные меры качества для бинарной классификации
Обобщение бинарных мер качества на многоклассовый случай
ROC-кривая
Лучший классификатор на ROC кривой
Эквивалентное определение AUC
Контроль качества предсказания вероятностей
Дополнительная литература
Вопросы
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Оценка качества классификации
Контроль качества предсказания вероятностей
Содержание этой страницы
Контроль качества предсказания вероятностей


Калибровка вероятностей
​


Во многих задачах классификации важно не только уметь предсказывать метки классов, 
но и их вероятности
. Например:






При обнаружении неправомерных злонамеренных действий в сети важно оценивать их вероятность, чтобы балансировать между ложными срабатываниями и пропущенными инцидентами.






При медицинской диагностике важно оценивать вероятность болезни по снимкам/анализам, чтобы принимать решение о дальнейшей диагностике.






Подбор преобразования 

 и его параметров 

, переводящего рейтинг класса 

  в его вероятность, называется 
калибровкой вероятностей
 (probability calibaration).


График калибровки
​


Для контроля качества калибровки бинарной классификации строят 
график калибровки
 (calibration-plot), показанный ниже 
[1]
:


[IMAGE]


По оси X откладывают предсказанную вероятность положительного класса, а по оси Y - фактическую. Чем получаемая зависимость ближе к диагонали Y=X, тем лучше классификатор предсказывает вероятности.




Например, на графике выше видно, что метод Naive Bayes недооценивает истинную вероятность, когда предсказывает её малое значение, и, наоборот, переоценивает вероятность, когда предсказывает её большое значение.




Поскольку в обучающей выборке нам даны только истинные классы, а не их вероятности, то для расчета истинных вероятностей множество предсказанных вероятностей разбивают на отрезки, например:





В рамках каждого отрезка вычисляют фактическую вероятность положительного класса как
 долю объектов, принадлежащих этому классу
.


Качество прогнозов меток и вероятностей классов
​


Подчеркнём, что даже если классификатор хорошо предсказывает метки классов, вероятности классов он может предсказывать плохо, как, например, на рисунке ниже:


[IMAGE]


Классификатор верно настроился на то, что:






При 

 вероятность положительного класса меньше 0.5, и надо предсказывать отрицательный класс.






При 

  положительный класс более вероятен, и нужно предсказывать его.






Поэтому точность предсказания меток класса будет высокой, однако вероятности классов предсказываются неверно, поскольку 

!


Базовые меры качества классификации, такие как accuracy, error rate, precision, recall и др., оценивают только качество предсказания меток классов.


Для оценки качества предсказания вероятностей можно использовать среднее значение логарифма правдоподобия или оценку Бриера. Эти меры будут описаны ниже.


Переобучение
Во избежание переобучения необходимо, как и для других мер качества, проводить оценку на 
внешней выборке
, а не на обучающей (по которой настраивались параметры) и валидационной (по которой настраивались гиперпараметры)!


Средний логарифм правдоподобия
​


Наша вероятностная модель 

 сопоставляет каждому наблюдению 

 вероятность пронаблюдать именно такой класс 

. При предположении, что объекты выборки распределены независимо, вероятность пронаблюдать ответы на всей выборке 

 факторизуется в произведение вероятностей пронаблюдать ответ на каждом объекте выборки:





Чем выше 
правдоподобие
 
[2]
, тем больше прогнозы модели согласуются с фактическими наблюдениями, и тем лучше модель прогнозирует вероятности классов. Поскольку произведение большого числа вероятностей будет вырождаться в машинный ноль из-за ограничения точности переменных с плавающей запятой, то на практике анализируют средний 
логарифм правдоподобия
 (log-likelihood):





Оценка Бриера
​


Оценка Бриера
 представляет собой другой популярный способ оценки качества предсказанных вероятностей с помощью 
функции потерь Бриера
 (Brier score 
[3]
), равной среднему квадрату отклонений вектора предсказанных вероятностей от вектора истинных вероятностей по L2-норме.


Пусть 

 - вектор предсказанных моделью вероятностей, а 

 - вектор истинных вероятностей.




Например, если для объекта 

 реализуется 

-й класс, то 

 будет представлять собой вектор из нулей, в котором на 

-й позиции стоит единица.




Тогда оценка Бриера вычисляется по формуле:





Вопрос
Правдоподобие выборки, логарифм правдоподобия и оценка Бриера измеряют степень ошибки (чем больше, тем хуже) или качество прогноза вероятностей (чем больше, тем лучше)?


Для лучшего понимания процесса калибровки вероятностей рекомендуется ознакомиться с демонстрационным кодом 
[4]
.


Литература
​






Документация sklearn: probability calibration.






Wikipedia: функция_правдоподобия.






Wikipedia: Brier score.






Kaggle: probability calibration tutorial.




Предыдущая страница
Эквивалентное определение AUC
Следующая страница
Дополнительная литература
Калибровка вероятностей
График калибровки
Качество прогнозов меток и вероятностей классов
Средний логарифм правдоподобия
Оценка Бриера
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Дополнительная литература | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Базовые меры качества многоклассовой классификации
Специальные меры качества для бинарной классификации
Обобщение бинарных мер качества на многоклассовый случай
ROC-кривая
Лучший классификатор на ROC кривой
Эквивалентное определение AUC
Контроль качества предсказания вероятностей
Дополнительная литература
Вопросы
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Оценка качества классификации
Дополнительная литература
Содержание этой страницы
Дополнительная литература


Оценка качества классификации подробно описана в 
[1]
, также можете прочитать соответствующий раздел в учебнике ШАД 
[2]
.


Детальнее о ROC-кривой, истории её появления и альтернативных мерах качества можно прочитать в 
[3]
. С реализацией всевозможных мер качества на python можно ознакомиться в 
[4]
.


Литература
​




Дьяконов А.Г. Машинное обучение и анализ данных: кривые в машинном обучении.


Учебник ШАД: метрики классификации и регрессии.


Wikipedia: receiver operating characteristic.


Документация sklearn: classification metrics.


Предыдущая страница
Контроль качества предсказания вероятностей
Следующая страница
Вопросы
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Вопросы для самопроверки | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Базовые меры качества многоклассовой классификации
Специальные меры качества для бинарной классификации
Обобщение бинарных мер качества на многоклассовый случай
ROC-кривая
Лучший классификатор на ROC кривой
Эквивалентное определение AUC
Контроль качества предсказания вероятностей
Дополнительная литература
Вопросы
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Оценка качества классификации
Вопросы
Вопросы для самопроверки




Почему качество классификации измеряют F-мерой, а не средним арифметическим от точности (precision) и полноты (recall)?


Приведите пример задачи, в которой мера precision важнее recall. И наоборот, где recall важнее precision.


Рассмотрим задачу ранжирования документов по релевантности поисковому запросу. В чём преимущества и недостатки меры precision@K по сравнению с мерой Average Precision для оценки качества ранжирования?


Чему равна ROC-кривая и площадь под ней для случайного угадывания? Существуют ли классификаторы, дающие ещё более низкую меру AUC?


Будет ли изменяться ROC-кривая и площадь под ней после применения монотонно возрастающего преобразования к относительной дискриминантной функции классификатора?


Предыдущая страница
Дополнительная литература
Следующая страница
Решающие деревья
© 2023-25 
Виктор Китов.
 
Новости проекта.









Решающие деревья | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Решающие деревья
Особенности прогнозов решающего дерева
Настройка решающего дерева
Функции неопределённости
Учёт пользовательской функции потерь
Обрезка решающих деревьев
Обработка пропущенных значений
Важность признаков
Анализ решающих деревьев
Обобщения решающих деревьев
Дополнительная литература
Вопросы
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Решающие деревья
Решающие деревья
Содержание этой страницы
Решающие деревья


Решающее дерево
 (decision tree 
[1]
) представляет собой алгоритм прогнозирования, основанный на применении иерархической системы правил. Пример простого решающего дерева для банковской задачи кредитного скоринга показан ниже:


[IMAGE]


Для построения прогноза объект спускается вниз по дереву, начиная с корневой вершины. При спуске по определённому маршруту объект проходит внутренние узлы (inner nodes), а заканчивается спуск на одном из терминальных узлов (листья, terminal nodes, leaves) внизу дерева.






Во внутренних узлах производится проверка условия вида "признак

порог". Если условие выполнено, то осуществляется спуск в левую дочернюю вершину, а если не выполнено, то в правую, пока не дойдём до терминальной вершины.






Каждой терминальной вершине сопоставлен константный прогноз:






в случае регрессии - это число;






в случае классификации - это метка класса либо вектор распределения вероятностей классов.










Дерево как правиловый алгоритм
Работу решающего дерева можно представить непересекающейся системой правил. Например, для дерева из иллюстрации это будет:
ЕСЛИ (доход 

 30.000) ИЛИ (есть просрочки) И (задолженность>10.000) ТО отказать.
ЕСЛИ (доход>30.000) ИЛИ (нет просрочек) ИЛИ (есть просрочки) И (задолженность 

 10.000) ТО дать кредит.
Существует целый класс 
правиловых алгоритмов машинного обучения
 (
rule induction
), которые строят интерпретируемые, но не очень точные прогнозы. Сейчас из них используются, в основном, только решающие деревья, недостаточную точность которых компенсируют применением не одного, а целого набора решающих деревьев (ансамбля). Построению 
ансамблей моделей
 и, в частности, 
алгоритму бустинга
 посвящены отдельные разделы учебника.


Здесь будет рассматриваться самый популярный алгоритм решающего дерева CART (classification and regression tree, 
[2]
, впервые предложен в 
[3]
). Тем не менее, существуют и другие алгоритмы, такие как ID3 и C4.5, в которых число потомков внутренних вершин может быть больше двух, а внутри вершин могут применяться другие решающие правила.




Далее мы рассмотрим 
примеры и особенности работы
 решающих деревьев для задачи регрессии и классификации, 
алгоритм обучения
 и 
обрезки
 решающих деревьев, а также изучим, 
как оценивать важность признаков
 по решающему дереву. В конце изучим 
основные достоинства и недостатки
 этого метода.


Литература
​






Wikipedia: decision tree learning.






Geeksforgeeks: CART (Classification And Regression Tree) in machine learning.






Breiman, L., Friedman, J., Olshen, R.A., & Stone, C.J. (1984). Classification and Regression Trees (1st ed.). Chapman and Hall/CRC.




Предыдущая страница
Решающие деревья
Следующая страница
Особенности прогнозов решающего дерева
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Особенности прогнозов решающего дерева | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Решающие деревья
Особенности прогнозов решающего дерева
Настройка решающего дерева
Функции неопределённости
Учёт пользовательской функции потерь
Обрезка решающих деревьев
Обработка пропущенных значений
Важность признаков
Анализ решающих деревьев
Обобщения решающих деревьев
Дополнительная литература
Вопросы
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Решающие деревья
Особенности прогнозов решающего дерева
Содержание этой страницы
Особенности прогнозов решающего дерева


В силу 
структуры прогнозов решающего дерева CART
 прогнозирующая функция делит всё пространство признаков на непересекающиеся прямоугольники, каждый из которых соответствует своему листу дерева. Поскольку дерево назначает свои прогнозы каждой точке пространства признаков, некоторые прямоугольники будут иметь бесконечно вытянутые стороны в одном из направлений. В каждом прямоугольнике предсказывается некоторое константное значение целевой переменной.


Прогнозы для классификации
​


Рассмотрим задачу бинарной классификации на красный и синий класс в пространстве двух признаков.


Ниже приведены прогнозы для решающего дерева глубины 1,2,3,10:


[IMAGE]


[IMAGE]


[IMAGE]


[IMAGE]


Как видим, дерево получается слишком простым при глубине 1,2, а при глубине 10 уже переобучается на отдельные наблюдения.


Стороны прямоугольников перпендикулярны осям координат, поскольку сами прямоугольники получаются пересечением условий вида [признак 

 порог] и [признак>порога]. Прогнозная функция 

 имеет ступенчатый кусочно-постоянный вид, показанной на графике ниже в центре 
[1]
:


[IMAGE]


В результате решающее дерево хорошо аппроксимирует целевую величину, только если изменение происходит резко вдоль одного из признаков. Если же изменения отклика происходят постепенно или под углом к осям признаков, то решающему дереву 
потребуется переобучаться под данные и сделать много разбиений
, чтобы их приблизить.


Ниже показан пример наклонной границы между классами, которую дереву будет сложно аппроксимировать:


[IMAGE]


Прогнозы для регрессии
​


Пусть целевая регрессионная зависимость имеет вид





где 

 - одномерный признак, а 

 - небольшой Гауссов шум. Построим решающее дерево глубины 1,2,3,4,5,10. Целевую зависимость 

 обозначим пунктирной линией, обучающие объекты - черными точками, а прогнозную функцию дерева - синей кривой. Тогда получим следующую визуализацию прогнозов дерева разной глубины:


[IMAGE]


[IMAGE]


Видим, что при глубине 1,2 дерево недообучено, а при глубине 10 уже сильно переобучено под отдельные наблюдения. Прогнозная функция, как и в случае классификации, имеет кусочно-постоянный вид.


В многомерном случае предиктивная функция также будет иметь кусочно-постоянный вид с резкими перепадами значений вдоль осей. В результате дереву потребуется много разбиений для аппроксимации изменений отклика, происходящих под углом к осям признаков.


Композиция алгоритмов
Решающему дереву сложно моделировать линейные зависимости между признаками и откликом, но это легко делать линейным моделям. Зато решающие деревья легко настраиваются на зависимости, в которых признаки оказывают совместное влияние на отклик (например, способны обработать совместный случай, когда число просрочек по кредиту>0 и объем задолженности 

 10.000 в 
задаче кредитного скоринга
). Линейные же модели учитывают вклад каждого признака независимо от значений остальных признаков. За счёт этого модели 
хорошо компенсируют ошибки друг друга
, если действуют в композиции друг с другом. Построение прогнозов набором моделей будет изучено в 
отдельном разделе
 учебника.


Вариант комбинации линейных моделей и решающих деревьев
Также для комбинации линейных моделей и решающих деревьев в своё время был предложен алгоритм RuleFit 
[2]
, который:




настраивает решающие деревья;






по ним извлекает набор бинарных признаков соответствующих  индикаторам попадания объекта в каждый из узлов образовавшихся деревьев;






строит линейную модель по исходным 
и извлечённым бинарным признакам
.






Пример запуска в Python
​


Решающее дерево CART для классификации:


from
 sklearn
.
tree 
import
 DecisionTreeClassifier
from
 sklearn
.
metrics 
import
 accuracy_score
from
 sklearn
.
metrics 
import
 brier_score_loss
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_classification_data
(
)
  
# инициализация дерева (criterion - функция неопределённости):
model 
=
 DecisionTreeClassifier
(
criterion
=
'gini'
)
  
model
.
fit
(
X_train
,
 Y_train
)
    
# обучение модели   
Y_hat 
=
 model
.
predict
(
X_test
)
  
# построение прогнозов
print
(
f'Точность прогнозов: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
P_hat 
=
 model
.
predict_proba
(
X_test
)
  
# можно предсказывать вероятности классов
loss 
=
 brier_score_loss
(
Y_test
,
 P_hat
[
:
,
1
]
)
  
# мера Бриера на вер-ти положительного класса
print
(
f'Мера Бриера ошибки прогноза вероятностей: 
{
loss
:
.2f
}
'
)




Больше информации
. 
Полный код
.


Решающее дерево CART для регрессии:


from
 sklearn
.
tree 
import
 DecisionTreeRegressor
from
 sklearn
.
metrics 
import
 mean_absolute_error
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_regression_data
(
)
  
# инициализация дерева (criterion - функция неопределённости):
model 
=
 DecisionTreeRegressor
(
criterion
=
'absolute_error'
)
  
model
.
fit
(
X_train
,
 Y_train
)
    
# обучение модели   
Y_hat 
=
 model
.
predict
(
X_test
)
  
# построение прогнозов
print
(
f'Средний модуль ошибки 
(
MAE
)
:
 \
        
{
mean_absolute_error
(
Y_test
,
 Y_hat
)
:
.
2f
}
'
)
  




Больше информации
. 
Полный код
.


Литература
​




Wikipedia: decision tree learning.


Friedman J. H., Popescu B. E. Predictive learning via rule ensembles //The Annals of Applied Statistics. – 2008. – Т. 2. – №. 3. – С. 916-954.


Предыдущая страница
Решающие деревья
Следующая страница
Настройка решающего дерева
Прогнозы для классификации
Прогнозы для регрессии
Пример запуска в Python
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Настройка решающего дерева | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Решающие деревья
Особенности прогнозов решающего дерева
Настройка решающего дерева
Функции неопределённости
Учёт пользовательской функции потерь
Обрезка решающих деревьев
Обработка пропущенных значений
Важность признаков
Анализ решающих деревьев
Обобщения решающих деревьев
Дополнительная литература
Вопросы
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Решающие деревья
Настройка решающего дерева
Содержание этой страницы
Настройка решающего дерева


Решающее дерево строится сверху вниз, начиная от корневой вершины, содержащей все объекты обучающей выборки. Сначала настраивается правило для корня, разделяющее эти объекты на две группы, первая из которых уходит левому потомку, а вторая - правому. Затем процесс расщепления вершин производится рекурсивно для каждой из образовавшихся вершин, как показано на рисунке:


[IMAGE]


Синим показаны внутренние узлы (inner nodes), в которых подбираются правила вида





а красным - листовые вершины (terminal nodes, leaves), в которых строится итоговый прогноз.


подсказка
Обратим внимание, что указанные правила в узлах 
одинаково хорошо работают и для вещественных, и для бинарных признаков
. В последнем случае как раз образуются две ветки в зависимости от значения бинарного признака. Категориальные признаки можно закодировать через 
one-hot кодирование
, тогда спуск по дереву будет осуществляться вправо, если категориальный признак равен определённой категории, и влево иначе. Если категорий много, то потребуется много сравнений, и всё равно не все значения категорий окажутся перепробованными.
Поэтому для решающих деревьев рекомендуется 
кодирование средним
. Тогда при использовании образовавшегося признака объекты с высоким средним значением отклика пойдут вправо, а с низким - влево, что резко упростит прогнозирование для последующих этапов.


Выбор решающего правила во внутренних узлах дерева
​


Чтобы задать решающее правило в каждом внутреннем узле дерева 

, необходимо специфицировать, 
какой именно признак с каким порогом сравнивать
. Для этого вводится 
функция неопределённости
 (impurity fuction) 

, характеризующая степень неопределённости откликов для объектов, попавших в соответствующий узел 

. Примеры основных таких функций будут даны в 
следующей главе
, а пока достаточно знать, что






эта функция равна нулю, когда все объекты, попавшие в лист, имеют одинаковый отклик (соответствуют одному значению в регрессии или одному классу в классификации);






функция тем выше, чем сильнее неопределённость в откликах (выше дисперсия для вещественных откликов, а в случае классификации - когда распределение классов ближе к равномерному).






Для 

-го признака и порога 

 решающее правило 

 разобьёт узел 

 на два дочерних узла: левый 

 и правый 

. Если изначально в узле 

 было 

 объектов, то они распределятся между левым и правым потомков в количествах 

 и 

.


Тогда применение правила изменит неопределённость откликов с 

 в родительском узле на 

 в дочерних, в результате чего получим общее изменение неопределённости:





Подбор признака и порога осуществляется перебором всевозможных признаков 

 и значений порога 

 (среди уникальных значений 

-го признака для объектов, попавших в узел 

) и выбором такой пары 

, для которых достигается 
минимальная неопределённость в дочерних узлах
 или (что то же самое) достигается 
максимальное изменение неопределённости
 при переходе от родительского узла к дочерним:





Неравнозначность признаков
Стоит отметить, что в алгоритме вещественные признаки будут выбираться чаще, чем бинарные, поскольку для них больше уникальных значений порога, что даёт оптимизации 
больше гибкости подогнаться по порогу именно по вещественному признаку
.


Сложность расчета 

, как будет видно из 
следующей главы
, имеет порядок 

, поэтому сложность подбора решающего правила равна 

, поскольку для каждого признака в качестве порога нужно перебрать его всевозможные уникальные значения, число которых не превосходит 

.


Более эффективный расчёт
Эту сложность можно снизить двумя способами:




Перебирать не все возможные пороги, а только основные. В качестве таковых можно взять 10%,20%,...90% 
персентиль
 в распределении признака. Тогда сложность подбора правила снизится до 

, поскольку мы будем перебирать всего 9 значений порога. Правда, для расчёта персентилей потребуется предварительно отсортировать значения каждого признака, что имеет порядок 

. Разумеется, можно брать и более детализированную сетку значений. Перебор по более грубой сетке значений повысит влияние бинарных признаков, т.к. они станут более конкурентоспособными в сравнении с вещественными. Также это повысит ожидаемую глубину дерева, необходимую для точного приближения данных.






Предварительно отсортировать каждый признак. Это наложит дополнительные вычислительные расходы на сортировку, зато позволит более эффективно пересчитывать значения функций неопределённости за 

, поскольку мы будем знать, какой объект переходит из правой дочерней вершины в левую при каждом изменении порога без сканирования всех 

 объектов, и сможем пересчитывать 

 за 

, используя кумулятивные статистики. Итоговая сложность подбора правила по всем порогам тогда будет 

.






Используя второй метод эффективного подбора правила, совокупная сложность построения всех правил на уровне 

 будет иметь сложность 

 (поскольку все 

 объектов выборки проходят через один из узлов на каждом уровне), а общая сложность построения дерева глубины 

 будет иметь порядок 

.


Остановка при наращивании дерева
​


При построении дерева сверху вниз необходимо решить, когда оканчивать дробление узлов и превращать текущие узлы в листовые. Конечно, нет смысла продолжать разбиение, если все объекты текущего узла дают одинаковый отклик. В частности, это достигается, когда в листе остался всего один объект. Но также используются и досрочная остановка по одному из следующих критериев:






достигнута целевая глубина 

;






число объектов в узле меньше 

;






число объектов в одном из дочерних узлов после оптимального разбиения оказалась меньше 

;






неопределённость отклика в узле меньше порога 

;






максимальное изменение неопределённости при разбиении узла меньше порога: 

.






Сравнение критериев
​


Досрочная остановка целесообразна, чтобы контролировать сложность получаемого дерева, когда мы стремимся выровнять сложность модели и сложность реальных данных. Иначе дерево, обученное до самого низа, станет переобученным и будет иметь плохую 
обобщающую способность
 на новых наблюдениях.


Критерии 2 и 3 близки по смыслу, однако критерий 3 предпочтительнее тем, что он, в отличие от критерия 2, гарантирует, что 
в каждом листовом узле будет достаточное количество объектов
 (

), чтобы делать статистически значимые выводы о прогнозе в листе.


Критерий 1 приводит в общем случае к построению сбалансированного дерева (расстояние от корня до каждого листа одно и то же), однако может оказаться 
неоптимальным с точки зрения числа объектов в листе
: какие-то листы окажутся переполненными объектами, а какие-то - недозаполненными. Поэтому среди критериев 1,2,3 следует пользоваться третьим критерием.


Критерий 5 кажется максимально релевантным оптимизации, в котором мы стремимся минимизировать 

 и досрочно прерываем процесс настройки, если видим, что не удаётся достичь существенного изменения в неопределённости. Однако тут стоит помнить, что остановка по этому критерию 
субоптимальна
, поскольку в начале построения дерева мы можем видеть малое изменение неопределённости, которое может стать большим при более поздних разбиениях, как показано на рисунке для случая бинарной классификации, используя два признака:


[IMAGE]


Изначальное распределение классов 50/50%, и какое бы разбиение вдоль какой бы оси мы ни выбрали, оно примерно таким и останется, поэтому изменение неопределённости 

. Однако, если бы мы не останавливались, а стали бы производить последующие разбиения, то мы могли бы прийти к 100% точности прогнозов!


Из-за этого, для достижения максимальной точности прогнозов, рекомендуется строить дерево 
до самого низа
 (пока объекты в каждом узле не станут иметь одинаковый отклик), а потом производить обрезку лишних ветвей (tree pruning), описанную 
далее
. Что, впрочем, не отменяет досрочную остановку по критерию 3, чтобы 
обеспечить в каждом листе минимальное количество объектов
 для построения статистически достоверных прогнозов.


Назначение прогноза в листах
​


Как только принято решение об остановке процесса построения дерева, текущий узел дерева превращается в листовую вершину, которой нужно назначить прогноз. Для этого используют простые правила:






в задаче регрессии назначают среднее или медиану откликов для объектов, попавших в узел.






в задаче классификации:






в качестве прогноза метки класса выдают самый распространённый класс узла;






если нужно выдать вероятности классов, то возвращают частотное распределение классов для объектов, попавших в узел.










Настройка на определённую функцию потерь
Для минимизации пользовательской функции потерь 

 эффективнее назначать такой прогноз в листьях дерева, который будет её минимизировать напрямую, о чем будет рассказано 
далее
.
Предыдущая страница
Особенности прогнозов решающего дерева
Следующая страница
Функции неопределённости
Выбор решающего правила во внутренних узлах дерева
Остановка при наращивании дерева
Сравнение критериев
Назначение прогноза в листах
© 2023-25 
Виктор Китов.
 
Новости проекта.









Функции неопределённости решающих деревьев | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Решающие деревья
Особенности прогнозов решающего дерева
Настройка решающего дерева
Функции неопределённости
Учёт пользовательской функции потерь
Обрезка решающих деревьев
Обработка пропущенных значений
Важность признаков
Анализ решающих деревьев
Обобщения решающих деревьев
Дополнительная литература
Вопросы
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Решающие деревья
Функции неопределённости
Содержание этой страницы
Функции неопределённости решающих деревьев


Задача регрессии
​


При предсказании вещественного отклика 

 в качестве функции неопределённости (impurity function) используется 
дисперсия откликов
:





где







 - множество индексов объектов, попадающих в узел 

,







 - количество таких объектов,







 - выборочное среднее по откликам объектов, попадающих в узел 

.






Также используется 
среднее абсолютное отклонение
 (mean absolute deviation):





где 

 - выборочная 
медиана
 откликов объектов узла 

.




Для более неопределённых данных с изменяющимся откликом обе меры неопределённости будут давать высокие значения. А в случае одинаковых откликов они будут равны нулю.




Задача классификации
​


Для классификации функции неопределённости 

 будут зависеть 
от вероятностей классов
 для объектов, попавших в узел 

. Ниже представлены популярные варианты этих функций:


название
на английском
формула
классификационная ошибка
classification error

критерий Джини
Gini

энтропийный критерий
entropy



Обоснование функций неопределённости
​


Рассмотрим бинарную классификацию и некоторый узел дерева 

.


Пусть вероятность положительного класса  

, а отрицательного  

.


Зависимости функций неопределённости от 

 приведены ниже:


[IMAGE]




Как видим, максимальная неопределённость функций достигается в наиболее неопределённом случае, когда 

 и оба класса равновероятны. А минимум неопределённости достигается, когда 

 либо 

. В этих случаях все объекты узла принадлежат одному из классов, и неопределённость классификации отсутствует.




Для многоклассового случая представленные функции также измеряют степень неопределённости классов, достигая максимума при равномерном распределении классов, когда 

, а минимума, когда все объекты принадлежат одному из классов:





Интуитивно это можно понять следующим образом:


Классификационная ошибка
 измеряет ожидаемое число ошибок при классификации всех объектов 
максимально вероятным классом
, у которого вероятность появления 

. Очевидно, что вероятность ошибки при такой классификации будет 

. Классификация будет безошибочной, когда в узле присутствуют объекты только одного класса, а максимум ошибок будет достигаться, когда все классы будут равновероятны.


Критерий Джини
 (Gini criterion) измеряет вероятность ошибки 
при случайном угадывании класса
 по правилу:





Тогда, расписывая вероятность ошибки по формуле полной вероятности 
[1]
, как раз и получим критерий Джини:





Эта ошибка будет максимальной, когда все классы равновероятны, и равняться нулю, когда все объекты принадлежат одному из классов.


Энтропийный критерий
 (entropy criterion) вычисляет энтропию случайной величины 

:





которая служит 
мерой её неопределённости
. Покажем это.


Определим количество информации, которую мы получаем при случайном событии, реализующимся с вероятностью 

, по формуле





График этой зависимости показан ниже:


[IMAGE]


Именно так определить получаемую информацию разумно, поскольку такая функция:






будет выдавать нулевую информацию при реализации события, у которого вероятность наступления равна 1 (происходит всегда);






стремится к бесконечности при 

 (событие происходит редко);






для двух независимых событий 

 и 

 будет выполнено свойство аддитивности:









Тогда энтропия случайной величины 

 будет равна 
ожидаемому количеству информации
, которую мы получим, узнав реализацию этой случайной величины:





Максимум информации мы будем получать для случая, когда все классы равновероятны, а минимум - когда реализуется всегда только один из классов.


Задача
Докажите формально, что энтропия максимизируется, когда все классы равновероятны. Для этого нужно её промаксимизировать при ограничении, что вероятности суммируются в единицу. Технически для этого используется метод множителей Лагранжа 
[2]
.


Литература
​






Wikipedia: формула полной вероятности.






Wikipedia: метод множителей Лагранжа.




Предыдущая страница
Настройка решающего дерева
Следующая страница
Учёт пользовательской функции потерь
Задача регрессии
Задача классификации
Обоснование функций неопределённости
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Учёт пользовательской функции потерь | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Решающие деревья
Особенности прогнозов решающего дерева
Настройка решающего дерева
Функции неопределённости
Учёт пользовательской функции потерь
Обрезка решающих деревьев
Обработка пропущенных значений
Важность признаков
Анализ решающих деревьев
Обобщения решающих деревьев
Дополнительная литература
Вопросы
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Решающие деревья
Учёт пользовательской функции потерь
Содержание этой страницы
Учёт пользовательской функции потерь


Функции неопределённости как минимальные значения потерь
​


Все представленные ранее 
функции неопределённости
 решающих деревьев получаются в результате расчёта 
средних потерь при оптимальном константном прогнозе для этих потерь
.


Пусть 

 - индексы объектов, попавших в узел 

, а 

 - количество таких объектов.


Тогда 
дисперсия откликов
 представляет собой минимально возможные 
среднеквадратичные потери
 при константном прогнозе 

. Оптимальной константой, минимизирующей средний квадрат ошибки, будет выборочное среднее (докажите!):





Среднее абсолютное отклонение от медианы
 минимизирует 
модуль отклонений
 от оптимальной константы 

, в качестве которой выступает медиана (докажите!):







Классификационная ошибка
 минимизирует 
частоту ошибок классификации
, когда класс всегда предсказывается также оптимальной константой. В качестве таковой выступает самый часто встречающийся класс (докажите!):





Энтропия
 представляет собой наилучшее значение 
кросс-энропийных потерь
 (
cross-entropy loss
 между фактическими вероятностями классов и их предсказанными значениями для всех объектов узла 

. Оптимальными вероятностями оказываются при этом фактические частоты классов в узле 

 (докажите!):





Критерий Джини
 выступает в качестве оптимального значения 
функции потерь Бриера
 между фактическими и предсказываемыми вероятностями. Наилучшими вероятностями также выступают фактические частоты каждого класса среди объектов узла (докажите!):





Задача
Докажите, что энтропия и критерий Джини минимизируют соответствующие функции потерь. Для этого необходимо воспользоваться методом множителей Лагранжа 
[1]
, поскольку оптимизация по вектору 

 будет производиться при условии, что 

.


Функции неопределённости для пользовательской функции потерь
​


При минимизации нестандартной функции потерь 

 оптимальной функцией неопределённости 

 будет минимальное среднее значение значение 
этой функции потерь
 при константном прогнозе 

:







Именно такая функция неопределённости будет оптимальна для минимизации потерь 

.




Такой подход, несмотря на его оптимальность, не реализован в большинстве библиотек машинного обучения в связи с тем, что для стандартных функций потерь оптимальный 

 вычислим аналитически и известен заранее, что позволяет рассчитать функцию неопределённости за 

, в то время как для произвольной функции потерь необходимо производить каждый раз переборную оптимизацию 

, из-за чего сложность вычисления 

 возрастает до 

.




Стоит отметить, что сложность возрастает до квадратичной от числа объектов в узле 
только во время настройки
 дерева. Сложность 
построения прогнозов
 при этом не меняется, поскольку решающие правила узлов уже фиксированы.




Листовые прогнозы для пользовательской функции потерь
​


При использовании пользовательской функции потерь 

 прогнозы в листах также оптимально назначать как минимизаторы 
именно этой функции
:





В частном случае задачи регрессии с 

 оптимально назначать прогнозом листа выборочное среднее, а при 

 медиану (докажите!).


В задаче классификации оптимально назначать прогнозом самый часто встречающийся класс среди объектов листа только для функции потерь 

  (докажите!). Для другой функции потерь это правило уже перестаёт быть оптимальным.


Литература
​




Wikipedia: метод множителей Лагранжа.


Предыдущая страница
Функции неопределённости
Следующая страница
Обрезка решающих деревьев
Функции неопределённости как минимальные значения потерь
Функции неопределённости для пользовательской функции потерь
Листовые прогнозы для пользовательской функции потерь
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Обрезка решающих деревьев | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Решающие деревья
Особенности прогнозов решающего дерева
Настройка решающего дерева
Функции неопределённости
Учёт пользовательской функции потерь
Обрезка решающих деревьев
Обработка пропущенных значений
Важность признаков
Анализ решающих деревьев
Обобщения решающих деревьев
Дополнительная литература
Вопросы
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Решающие деревья
Обрезка решающих деревьев
Содержание этой страницы
Обрезка решающих деревьев


Идея метода
​


В итеративном построении решающих деревьев сверху вниз мы анализировали 
различные правила остановки
, и был приведён пример, когда ранняя остановка может приводить к неоптимальным решениям, поскольку начальные правила разбиения не приводят к снижению неопределённости, а последующие - приводят.


Это ситуация весьма распространена на практике, поэтому для повышения точности прогнозов:






деревья строят до самого низа (пока в узлах не останется по одному объекту или все объекты листа не будут иметь один и тот же отклик);






потом обрезают лишние ветви дерева, что называется 
обрезкой дерева
 (tree pruning).






Простые подходы
​


В обрезке дерева его поддеревья заменяются их корнями, которые назначаются листовыми вершинами (с константным прогнозом). Делать это можно полным перебором, сравнивая качество прогнозов полного решающего дерева с обрезанным на 
валидационной выборке
, однако придётся перебирать слишком много вариантов.


Поэтому в качестве кандидатов на обрезку можно перебирать только предпоследние вершины, потом предпредпоследние и так далее снизу вверх по дереву, однако это также требует большого числа вычислений.


Чтобы сделать поиск кандидатов на обрезку более направленным и эффективным используется алгоритм 
обрезки по минимальной цене
.


Алгоритм обрезки по минимальной цене
​


В алгоритме 
обрезки по минимальной цене
 (minimal cost complexity pruning), являющегося составной частью алгоритма CART 
[1]
 дерево строится до самого низа (хотя также можно применять досрочный останов, например, по минимальному числу объектов в листьях), после чего для каждой внутренней вершины полного дерева оценивается целесообразность разрастания вершины до поддерева, сравнивая 2 ситуации:






когда эта вершина имеет под собой исходное поддерево;






когда эта вершина является терминальной (без поддерева под ним).






Эти ситуации проиллюстрированы ниже для вершины 

:


[IMAGE]


Обозначим через 

 поддерево с корнем во внутренней вершине 

. Зададим штраф 

, вычисляющий неточность прогнозов поддерева 

 как среднюю функцию неопределённости в листовых вершинах поддерева 

. Например, для регрессии это может быть дисперсия откликов, а для классификации - частота ошибок. Усреднение необходимо производить 
пропорционально числу объектов
, попадающих в каждый лист дерева.


Дополнительно определим регуляризованный штраф 

, который, помимо штрафа за неточность прогнозов, штрафует поддерево за сложность, вычисляемую как количество листьев 

 в этом поддереве. Гиперпараметр 

 обозначает штраф за каждый дополнительный лист поддерева.


Найдём равновесное значение 

, при котором регуляризованный штраф за поддерево 

 совпадёт с регуляризованным штрафом, когда поддерево 

 заменяется на его корень 

  (в котором сразу будет строиться прогноз, как на рисунке выше):





Это можно переписать в виде





поскольку поддерево 

 состоит всего из одного листа.


Отсюда равновесное 

 будет равно:





Равновесное 

 задаёт 
целесообразность разрастания
 внутренней вершины 

 в поддерево 

.




Если оно равно нулю, то разрастание полностью нецелесообразно, поскольку одиночная вершина 

 и образованное из неё поддерево 

 даёт одинаковый уровень ошибок. Но чем выше 

, тем построение поддерева 

 целесообразнее, поскольку, чтобы компенсировать более высокую точность поддерева по сравнению с корнем, приходится сильнее штрафовать увеличение числа листов.




В алгоритме обрезки по минимальной цене вычисляются целесообразности 

 для каждого поддерева 

 полного дерева, после чего 
удаляется поддерево с минимальной целесообразностью
. Далее 

 пересчитываются для всех оставшихся вершин (достаточно пересчитывать не для всех, а только для поддеревьев, затронутых удалением с предыдущего шага), и процесс повторяется до тех пор, пока не останется одна корневая вершина исходного дерева. Таким образом, алгоритм выдаст систему вложенных друг в друга поддеревьев:





среди которых выбирается поддерево, дающее максимальную точность на 
валидационной выборке
.




Дополнительно об алгоритмах обрезки решающих деревьях вы можете прочитать в 
[2]
. В 
[3]
 подробно разобран пример расчёт алгоритма обрезки по минимальной цене и приведены вариации алгоритма. В 
[4]
 описано применение алгоритма в библиотеке sklearn.


Литература
​






Breiman, L., Friedman, J., Olshen, R.A., & Stone, C.J. (1984). Classification and Regression Trees (1st ed.). Chapman and Hall/CRC.






Wikipedia: decision tree pruning.






Webb A. R., Copsey K.D. Statistical pattern recognition. – John Wiley & Sons, 2011.






Документация sklearn: post pruning decision trees with cost complexity pruning.




Предыдущая страница
Учёт пользовательской функции потерь
Следующая страница
Обработка пропущенных значений
Идея метода
Простые подходы
Алгоритм обрезки по минимальной цене
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Обработка пропущенных значений | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Решающие деревья
Особенности прогнозов решающего дерева
Настройка решающего дерева
Функции неопределённости
Учёт пользовательской функции потерь
Обрезка решающих деревьев
Обработка пропущенных значений
Важность признаков
Анализ решающих деревьев
Обобщения решающих деревьев
Дополнительная литература
Вопросы
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Решающие деревья
Обработка пропущенных значений
Содержание этой страницы
Обработка пропущенных значений


Часто некоторые признаки в данных могут отсутствовать. Например, в медицинской диагностике пациент мог не проходить определённых обследований, при анализе анкет респондент мог не указать возраст, а при обработке данных домов может отсутствовать дата постройки.


Пропущенные значения можно заполнить одним из ранее изученных 
стандартных методов
. Однако специфика работы решающих деревьев позволяет обрабатывать пропуски по-особенному.


Если 
пропущенный признак присутствуют только в тестовых данных
 (но не в обучающих), то при проверке правила





объект можно направить в дочерний узел, содержащий больше объектов обучающей выборки, т.е. в априорно более вероятный.


Однако возможны разные стратегии, когда 
в обучающей выборке также присутствуют пропуски
.




В следующих двух способах предлагается настраивать дерево, используя только известные значения признаков.




Суррогатные разбиения
​


В классическом алгоритме CART 
[1]
 предлагалась процедура суррогатных разбиений (surrogate splits). Поскольку при 
выборе правила
 [признак

порог] перебираются все варианты признаков, то можно запомнить, какой другой признак обеспечивал наилучшее качество, а какой оказывался наилучшим на втором месте. Такой признак назовём суррогатным. При появлении пропуска в классическом дереве CART исходное правило заменяется на правило с суррогатным признаком (и соответствующим ему порогом). Если и суррогатный признак отсутствует, то применяется следующий суррогатный признак (уже третий по качеству) и т.д., пока мы не дойдёт до признака с известным значением.


Распределённая стратегия
​


Вместо того, чтобы направлять объект с пропущенным значением либо влево, либо вправо его можно направить все объекты с пропущенными значениями всегда в левый или правый дочерний узел, в зависимости от того, какой из способов приводит к большему уменьшению функции неопределённости на обучающей выборке.


Вместо того, чтобы направлять объекты с пропущенным признаком всегда влево или вправо, можно его направить одновременно и влево (получив прогноз 

), и вправо (получив прогноз 

), а в качестве итогового прогноза выдать





где 

 - число обучающих объектов, попавших в узел, в котором проверяется значение пропущенного признака, а 

 и 

 - количества обучающих объектов, спускающихся в левую и правую дочернюю вершину соответственно.




Представленные два способа опираются на предположение, что факт пропуска значения признака не влияет на его распределение. В реальности оно может быть не выполнено. Например, в анкете человек мог не указывать зарплату не потому что забыл, а потому что она аномальная малая или большая.


Далее будет описана стратегия, которая обрабатывает объекты с пропусками отдельно, обеспечивая учёт возможной специфики их распределения.




Отдельная обработка пропусков
​


При настройке решающего правила в каждом узле предлагается сравнить три стратегии по тому, какая из них приводит к наибольшему снижению 
функции неопределённости
:






когда все объекты с пропущенным значением идут влево, а с заполненным значением - вправо;






когда все объекты с пропуском идут влево;






когда все объекты с пропуском идут вправо.






Это замедляет настройку, зато по её итогам даёт чёткий алгоритм обработки пропущенных значений. Именно такая стратегия реализована в решающих деревьях библиотеки sklearn 
[2]
.


Литература
​




Breiman, L., Friedman, J., Olshen, R.A., & Stone, C.J. (1984). Classification and Regression Trees (1st ed.). Chapman and Hall/CRC.


Документация sklearn: missing values support.


Предыдущая страница
Обрезка решающих деревьев
Следующая страница
Важность признаков
Суррогатные разбиения
Распределённая стратегия
Отдельная обработка пропусков
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Важность признаков | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Решающие деревья
Особенности прогнозов решающего дерева
Настройка решающего дерева
Функции неопределённости
Учёт пользовательской функции потерь
Обрезка решающих деревьев
Обработка пропущенных значений
Важность признаков
Анализ решающих деревьев
Обобщения решающих деревьев
Дополнительная литература
Вопросы
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Решающие деревья
Важность признаков
Содержание этой страницы
Важность признаков


Важность в решающем дереве
​


Работу решающего дерева можно проинтерпретировать непосредственно, если дерево не слишком глубокое. Для интерпретации деревьев произвольной глубины можно анализировать, какое влияние оказывает каждый из признаков на его прогнозы. На значимость каждого признака влияют:






как часто признак использовался в правилах во внутренних узлах дерева;






какое число обучающих объектов прошло через узлы, использующие признак;






насколько правилам в этих узлах удавалось снизить неопределённость прогнозов.






Объединяя эти факторы вместе, важность признака 

 для решающего дерева (feature importance) рассчитывается по формуле:





где:







 - множество всех узлов дерева, использовавших признак 

 в своих правилах ветвления;







 - число объектов выборки, проходящих через узел 

;







 - 
изменение функции неопределённости
 после применения правила ветвления в узле 

;







 - общее число объектов в обучающей выборке.






Эта мера важности признака называется 
средним изменением неопределённости
 (
mean decrease in impurity
 или MDI 
[1]
, 
[2]
).


MDI-важность рассчитывается на этапе первичного анализа данных и на этапе отбора признаков перед применением других нелинейных моделей. Причём эту меру считают не по единичному дереву, а по 
ансамблю случайных деревьев
, поскольку единичное дерево склонно переобучаться при построении до самого низа. С методом расчёта MDI-меры в библиотеке sklearn, используя алгоритм случайного леса, можно ознакомиться в 
[3]
 и 
[4]
, где этот метод сравнивается с 
перестановочным методом оценки важности
.


Важность в линейных моделях
​


Для измерения важности признаков также можно настроить линейную модель и анализировать полученные веса при признаках - чем они больше по модулю, тем признак важнее.




Поскольку веса при признаках обратно пропорциональны масштабу признаков, важно предварительно приводить признаки к единой шкале 
нормализацией
.




Однако эта мера покажет важность признака только в контексте 
линейного влияния на отклик
! Если признак оказывает существенное нелинейное влияние, то MDI-важность даст более адекватную оценку степени его влияния на прогноз.


Литература
​






Louppe G. et al. Understanding variable importances in forests of randomized trees //Advances in neural information processing systems. – 2013. – Т. 26.






Breiman L. Random forests //Machine learning. – 2001. – Т. 45. – С. 5-32.






Документация sklearn: feature importances with a forest of trees.






Документация sklearn: permutation Importance vs random forest feature Importance (MDI).




Предыдущая страница
Обработка пропущенных значений
Следующая страница
Анализ решающих деревьев
Важность в решающем дереве
Важность в линейных моделях
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Анализ решающих деревьев | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Решающие деревья
Особенности прогнозов решающего дерева
Настройка решающего дерева
Функции неопределённости
Учёт пользовательской функции потерь
Обрезка решающих деревьев
Обработка пропущенных значений
Важность признаков
Анализ решающих деревьев
Обобщения решающих деревьев
Дополнительная литература
Вопросы
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Решающие деревья
Анализ решающих деревьев
Содержание этой страницы
Анализ решающих деревьев


Решающие деревья являются одними из самых используемых алгоритмов классического машинного обучения. Проанализируем их достоинства и недостатки.


Достоинства метода
​






Это 
нелинейная модель с гибкой настройкой сложности
 по максимальной глубине и минимальному числу объектов в листе. Настраивая деревья достаточной глубины, можно сколь угодно точно подогнать модель под данные (если одинаковым объектам не соответствуют разные отклики).






Модель 
самостоятельно отбирает важные признаки
. Неинформативные признаки не будут использованы в прогнозах.






Модель универсально 
работает с признаками разной природы
, поскольку правила [признак

порог] одинаково применимы и к вещественным, и к бинарным, и к порядковым (упорядоченным категориальным) признакам. Категориальные же признаки всегда можно предварительно преобразовать в бинарные или вещественные одним из 
стандартных способов
. Это важное качество, поскольку в большинстве задач мы будем иметь дело с признаками разных типов!






По дереву можно рассчитать 
важность каждого признака
 для построения прогнозов, что может использоваться как для анализа самого решающего дерева, так и для отбора признаков для моделей других типов (например, нейросетей).






Деревья 
инвариантны к масштабу и монотонным преобразованиям признаков
, поскольку к ним инвариантны заложенные в них правила [признак

порог] после перенастройки моделей.






Прогнозы строятся быстро
, поскольку прогнозирующая функция требует только сравнения определённых признаков с порогом.






Решающие деревья небольшой глубины можно 
визуализировать и проинтерпретировать
 даже не специалистам.






Недостатки метода
​






У решающих деревьев 
нет динамической подстройки под потоковые данные
. При поступлении новых данных дерево необходимо перестраивать с самого начала до самого конца. При этом решающие правила могут поменяться, начиная с самого верха дерева! То есть это 
неустойчивый алгоритм
 даже к небольшим изменениям обучающей выборки.






У деревьев сравнительно невысокая точность. Это связано со следующими свойствами:






Дерево настраивается жадным способом сверху вниз, последовательно выбирая оптимальные правила разбиения, заглядывая 
лишь на один шаг вперёд
. В результате дерево, как целое, будет оказываться неоптимальным - можно достичь более высокой точности при меньшем числе разбиений.






Правила [признак

порог] разделяют признаковое пространство гиперплоскостями, перпендикулярными осям координат, в результате чего получается кусочно-постоянная функция прогноза. Такая функция будет 
неточно прогнозировать
 плавные изменения отклика, а также изменения, происходящие не вдоль отдельного признака, а под углом к осям координат признакового пространства.










Увеличение точности деревьев
Точность решающих деревьев можно существенно повысить, если использовать для прогнозов не одно дерево, а набор из нескольких деревьев (ансамбль). О построении ансамблей моделей будет рассказано 
в следующей главе
. Отдельный раздел учебника посвящён построению ансамблей с помощью 
алгоритма бустинга
.
Ансамбли над решающими деревьями - это 
самый часто используемый метод классического машинного обучения
!
Предыдущая страница
Важность признаков
Следующая страница
Обобщения решающих деревьев
Достоинства метода
Недостатки метода
© 2023-25 
Виктор Китов.
 
Новости проекта.









Обобщения решающих деревьев | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Решающие деревья
Особенности прогнозов решающего дерева
Настройка решающего дерева
Функции неопределённости
Учёт пользовательской функции потерь
Обрезка решающих деревьев
Обработка пропущенных значений
Важность признаков
Анализ решающих деревьев
Обобщения решающих деревьев
Дополнительная литература
Вопросы
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Решающие деревья
Обобщения решающих деревьев
Содержание этой страницы
Обобщения решающих деревьев


Обобщение правил ветвления
​


Вместо правил 

 (признак меньше порога) во внутренних узлах дерева можно применять и другие правила:






Например, при использовании категориального признака 

 можно построить столько дочерних вершин, сколько есть уникальных категорий, и, в зависимости от категории 

, спускаться в соответствующую вершину. Дерево тогда уже не будет бинарным 
[1]
. Именно такой подход используется в решающем дереве ID3 
[2]
 и его более продвинутой версии C4.5 
[3]
.






Можно разбить множество значений признака на набор из 

 непересекающихся полуинтервалов: 

 и осуществлять спуск в  дочернюю вершину 

, если признак 

 попадает в 

-й полуинтервал.






В каждом внутреннем узле 

 можно спускаться в левую или правую дочернюю вершину на основе правила





при этом вектора коэффициентов 

 и пороги 

 у каждого узла будут свои. Тогда каждый внутренний узел сможет разделять признаковое пространство не только перпендикулярно осям, но и под произвольным углом на основе линейной классификации.






В качестве проверяемой функции в узле 

 можно брать произвольную функцию 

. Например, если взять 

, то правило 

 будет направлять объекты в левую либо правую дочернюю вершину в зависимости от того, попал ли объект внутрь шара определённого радиуса или нет.






Обобщение правил прогнозирования в листьях
​


Вместо назначения константного прогноза в листьях дерева в каждом листе 

 можно строить прогноз по некоторой функции (например, линейной):





Параметры этой функции можно настроить, используя обучающие объекты, попавшие в лист 

.


Более оптимальная настройка дерева
​


Стандартное решающее дерево строится последовательно сверху вниз, выбирая локально оптимальное разбиение 
на один шаг вперёд
. Поиск можно сделать более полным и точным (ценой увеличения вычислительной сложности), если настраивать правило разбиения в каждой вершине, заглядывая не на один шаг вперёд, а на два: для этого нужно перебирать всевозможные признаки и пороги не только в текущем узле, но и в образовавшихся левой и правой дочерних вершинах, максимизируя изменение неопределённости сразу на два шага вперёд между вершиной и потомками от её потомков. Можно анализировать влияние разбиений, заглядывая и на большее число шагов вперёд. Детально с алгоритмом можно ознакомиться в 
[4]
.


Мягкие решающие деревья
​


В стандартном решающем дереве спуск каждого объекта производится только по одному пути. В мягких решающих деревьях (soft decision trees 
[5]
) объект спускается одновременно по всем путям сразу с вероятностями, рассчитываемыму логистической регрессией в каждом узле.


Литература
​






Wikipedia: двоичное дерево.






Wikipedia: ID3 algorithm.






Wikipedia: C4.5 algorithm.






Esmeir S., Markovitch S. Lookahead-based algorithms for anytime induction of decision trees //Proceedings of the 21 international conference on Machine learning. – 2004. – С. 33.






Irsoy O., Yıldız O. T., Alpaydın E. Soft decision trees //Proceedings of the 21st international conference on pattern recognition (ICPR2012). – IEEE, 2012. – С. 1819-1822.




Предыдущая страница
Анализ решающих деревьев
Следующая страница
Дополнительная литература
Обобщение правил ветвления
Обобщение правил прогнозирования в листьях
Более оптимальная настройка дерева
Мягкие решающие деревья
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Дополнительная литература | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Решающие деревья
Особенности прогнозов решающего дерева
Настройка решающего дерева
Функции неопределённости
Учёт пользовательской функции потерь
Обрезка решающих деревьев
Обработка пропущенных значений
Важность признаков
Анализ решающих деревьев
Обобщения решающих деревьев
Дополнительная литература
Вопросы
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Решающие деревья
Дополнительная литература
Содержание этой страницы
Дополнительная литература


Дополнительно о решающих деревьях рекомендуется прочитать в документации sklearn 
[1]
, где представлены не только описания алгоритмов, но примеры использования решающих деревьев в python.


Также решающие деревья подробно описаны в учебнике ШАД 
[2]
, учебнике А.Г. Дьяконова 
[3]
, а также в 
[4]
.


Литература
​




Документация sklearn: decision trees.


Учебник ШАД: решающие деревья.


Дьяконов А.Г. Машинное обучение и анализ данных: решающие деревья.


Webb A. R., Copsey K.D. Statistical pattern recognition. – John Wiley & Sons, 2011.


Предыдущая страница
Обобщения решающих деревьев
Следующая страница
Вопросы
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Вопросы для самопроверки | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Решающие деревья
Особенности прогнозов решающего дерева
Настройка решающего дерева
Функции неопределённости
Учёт пользовательской функции потерь
Обрезка решающих деревьев
Обработка пропущенных значений
Важность признаков
Анализ решающих деревьев
Обобщения решающих деревьев
Дополнительная литература
Вопросы
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Решающие деревья
Вопросы
Вопросы для самопроверки




Почему прогнозы решающего дерева CART не будут зависеть от монотонного преобразования признаков (после повторного обучения модели на преобразованных данных)?


Может ли потенциально генерация новых признаков вида 

 и 

 улучшить прогнозы




решающего дерева?


линейной регрессии?


линейного классификатора?


метода K ближайших соседей?






В каких типах задач использование решающего дерева предпочтительнее использования линейных методов прогнозирования?


Докажите, что критерий классификационной ошибки, критерий Джини и энтропийный критерий максимизируются, когда все классы узла равновероятны.


Какие гиперпараметры решающего дерева определяют его сложность (гибкость), то есть способность подстраиваться под объекты обучающей выборки? Как изменение этих гиперпараметров влияет на сложность модели?


Предыдущая страница
Дополнительная литература
Следующая страница
Переобучение и недообучение
© 2023-25 
Виктор Китов.
 
Новости проекта.









Сложность прогнозирующих моделей | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Сложность прогнозирующих моделей
Разложение на смещение и разброс
Доказательство разложения
Дополнительная литература
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Переобучение и недообучение
Сложность прогнозирующих моделей
Сложность прогнозирующих моделей


Зафиксируем прогностическую модель и начнём варьировать её сложность (гибкость), то есть способность подстраиваться под объекты обучающей выборки. В случае линейных моделей это будет множитель при регуляризаторе; в случае метода 

 ближайших соседей - параметр 

; в случае решающего дерева это может быть максимальная глубина дерева или минимальное число объектов в листьях.


Общий вид зависимости средних потерь от сложности модели машинного обучения выглядит следующим образом:


[IMAGE]


Средние потери на тестовой выборке в общем случае выше, чем на обучающей выборке, поскольку параметры модели настраиваются именно под обучающую выборку.


При увеличении сложности модели растёт её способность подстраиваться под обучающие данные, поэтому 
средние потери на обучении снижаются
. А вот средние потери на тестовой выборке:






Сначала снижаются
, когда модельная зависимость всё ещё слишком проста и не может в полной мере приближать реальную зависимость в данных. Такие модели называют 
недообученными
 (underfitted models).






Потом начинают повышаться
, когда выразительная сложность модели становится выше сложности реальной зависимости в данных. Избыточную гибкость модель тратит на поточечную подстройку под специфику обучающей выборки, которая была сформирована случайно. То есть модель начинает выявлять ложные зависимости, которых нет в тестовой выборке. Такие модели называют 
переобученными
 (overfitted models).






Поэтому в каждом алгоритме важно настроить гиперпараметр, отвечающий за его сложность, чтобы сложность модели соответствовала сложности реальной зависимости в данных. На графике выше оптимальная сложность модели показана точкой A.


А ниже приведён пример данных для регрессионной задачи с примерно квадратичной зависимостью между признаком и откликом. Слева показан пример недообученной модели, а справа - переобученной:


[IMAGE]


В 
следующей главе
 мы изучим понятие переобучения и недообучения модели более формально, используя 
разложение на смещение и разброс
 (bias-variance decomposition).
Предыдущая страница
Переобучение и недообучение
Следующая страница
Разложение на смещение и разброс
© 2023-25 
Виктор Китов.
 
Новости проекта.









Разложение на смещение и разброс | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Сложность прогнозирующих моделей
Разложение на смещение и разброс
Доказательство разложения
Дополнительная литература
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Переобучение и недообучение
Разложение на смещение и разброс
Содержание этой страницы
Разложение на смещение и разброс


Разложение на смещение и разброс
 (bias-variance decomposition 
[1]
, впервые предложено в 
[2]
) позволяет более формально описать 
недообучение
 (underfitting) и 
переобучение
 (overfitting)  моделей машинного обучения.


Рассмотрим некоторую реальную задачу зависимость





где 

, 

 - некоторая функция, а 

 - случайный шум, не зависящий от объектов 

 и имеющий нулевой среднее.


Эту зависимость мы будем приближать модельной зависимостью 

 по имеющейся обучающей выборке





Зафиксируем объект 

, для которого мы строим прогноз, и оценим ожидаемый квадрат ошибки 

, усредняя по реализациям случайного шума 

 и обучающей выборки 

. Последнее представляет интерес, поскольку на практике в обучающую выборку попадают 
случайные объекты
 из генеральной совокупности.




Например, при классификации новостей мы выгружаем из интернета случайные 

 новостей и их размечаем вручную. Но мы могли бы разметить и другие 

 новостей, получив при этом другую обучающую выборку, по которой модель настроилась бы немного по-другому!




Лучшее, что мы можем сделать, это приблизить 

, поскольку шум 

 не зависит от объектов и его мы прогнозировать не можем.


Разложение на смещение и разброс
 (bias-variance decomposition) декомпозирует ошибку прогноза на различные причины этой ошибки.


Разложение на смещение и разброс







Выражение в первой компоненте, возводимое в квадрат, называется 
смещением модели
 (bias) и показывает, насколько сильно 
модель будет систематически отклоняться от целевой зависимости
 

, если мы будем использовать различные обучающие выборки.






Вторая компонента разложения называется 
дисперсией модели
 (variance) и показывает, насколько сильно 
прогнозы модели будут различаться, если её настраивать на различных обучающих выборках
.






Третья компонента называется 
неснижаемой ошибкой
 (irreducible error) и определяется шумом в данных, который мы предсказать не можем.






Это можно проиллюстрировать игрой в дартс, где мы стремимся попасть дротиком в центр цели. Ошибка попадания в цель может объясняться большим смещением (например, ветер систематически сдувает дротик в сторону) или большой дисперсией (неточные броски). Смещение и дисперсия могут присутствовать и совместно.




[IMAGE]




Рассмотрим задачу прогнозирования для квадратичной зависимости 

.






У 
недообученных моделей
 (например, линейной регрессии от 

) ошибка будет вызвана 
высоким смещением
, поскольку прямая будет систематически отклоняться от целевой квадратичной зависимости. При этом дисперсия модели будет невелика, поскольку в ней присутствуют всего два параметра 

 и они будут примерно похожими для различных обучающих выборок.






У 
переобученных моделей
 (например, при прогнозировании квадратичной зависимости полиномом высокой степени или решающим деревом, которое мы строим до самого низа), напротив, смещение будет близким к нулю, поскольку они будут почти безошибочно подгоняться под обучающие данные, а ошибка прогнозирования будет вызвана 
высокой дисперсией
, связанной с переобучением модели под конкретную реализацию обучающей выборки (модель её запоминает).






В 
следующей главе
 мы докажем разложение на смещение и разброс.


Литература
​




Wikipedia: bias–variance tradeoff.


Geman S., Bienenstock E., Doursat R. Neural networks and the bias/variance dilemma //Neural computation. – 1992. – Т. 4. – №. 1. – С. 1-58.


Предыдущая страница
Сложность прогнозирующих моделей
Следующая страница
Доказательство разложения
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Доказательство разложения | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Сложность прогнозирующих моделей
Разложение на смещение и разброс
Доказательство разложения
Дополнительная литература
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Переобучение и недообучение
Доказательство разложения
Доказательство разложения


Докажем разложение на смещение и разброс:





Зафиксируем 

, для которого строится прогноз. Далее везде в математических ожиданиях будет производиться усреднение 
по всевозможным реализациям обучающей выборки и случайного шума
, то есть





Для начала разложим следующее выражение:





где мы воспользовались тем, что 

 - константа, а значит,





Следовательно,





где, в силу независимости случайных величин 

 (которая зависит только от 

) и 

:



Предыдущая страница
Разложение на смещение и разброс
Следующая страница
Дополнительная литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Дополнительная литература | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Сложность прогнозирующих моделей
Разложение на смещение и разброс
Доказательство разложения
Дополнительная литература
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Переобучение и недообучение
Дополнительная литература
Содержание этой страницы
Дополнительная литература


О разложении на смещение и разброс вы можете дополнительно прочитать в учебнике  А.Г.Дьяконова 
[1]
, где также представлены способы борьбы с переобучением, а также в учебнике ШАД 
[2]
, где дополнительно описан феномен double descent curve, на основе которого успешно работают современные перепараметризованные нейросетевые модели.


Способы борьбы с недообучением и переобучением хорошо структурированы в 
[3]
, а в 
[4]
 представлен код, вычисляющий смещение и дисперсию моделей на практике.


Литература
​




Дьяконов А.Г. Машинное обучение и анализ данных: сложность алгоритмов, переобучение, смещение и разброс.


Учебник ШАД: Bias-variance decomposition.


Geeksforgeeks: underfitting and overfitting.


Geeksforgeeks: bias and variance in machine learning.


Предыдущая страница
Доказательство разложения
Следующая страница
Ансамбли моделей
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Ансамбли моделей | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Ансамбли моделей
Математическое обоснование ансамблей
Простая агрегация в ансамблях
Методы построения базовых моделей
Настройка на разных фрагментах обучающей выборки
Ансамбли рандомизированных деревьев
Стэкинг
Дополнительная литература
Вопросы
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Ансамбли моделей
Ансамбли моделей
Содержание этой страницы
Ансамбли моделей


Идея
​


Ансамбли моделей
 (model ensembles), называемые также 
композициями алгоритмов
, строят прогноз, используя не одну модель 

, а совокупность 
базовых моделей
 (base learners) 

 и 
агрегирующую мета-модель
 (meta-model) 

, которая агрегирует прогнозы базовых моделей:





Далее рассмотрим проблемы, которые могут успешно решаться с помощью ансамблей моделей.


Борьба с переобучением
​


Ансамбли позволяют бороться с  
переобучением
 (overfitting) базовых моделей под обучающую выборку.




Используя ансамбль, мы надеемся, что одни модели будут недооценивать целевую переменную, другие - переоценивать, в результате чего ошибки разных моделей взаимно скомпенсируются, и мы получим более точный итоговый прогноз.




Агрегирующей моделью 

 в этом случае выступает простая функция, такая как усреднение прогнозов базовых моделей.




[IMAGE]


Борьба с недообучением
​


Также ансамбли позволяют бороться с 
недообучением
 (undefitting) базовых моделей, поскольку использование сложной агрегирующей модели 

 позволяет внести дополнительную гибкость в процесс построения прогнозов.


Рассмотрим пример классификации, представленный на рисунке ниже. Как видим, данные линейно неразделимы, поэтому первый линейный классификатор размечает лишь часть объектов корректно, аналогично и второй классификатор. Если же объединить прогнозы двух классификаторов по правилу логического AND, то есть назначать красный класс лишь в случаях, когда оба классификатора предсказывают красный класс, то получим безошибочную классификацию, выделенную тёмно-синим на рисунке:


[IMAGE]


Повышение устойчивости
​


Также ансамбли позволяют уменьшить риски, связанные с той или иной стратегией моделирования. У каждой модели есть свои предположения о данных, которые в реальности будут лишь ограниченно выполняться и приводить к систематическому смещению. Использование не одной, а сразу нескольких моделей, использующих разные предположения о распределении данных, позволяет уменьшить несоответствие итоговой модели реальному распределению. 
Поэтому рекомендуется использовать в ансамбле модели разных классов
 - решающие деревья, линейные модели и метрические методы.


Аналогия с инвестициями
Один из основных принципов инвестирования заключается в диверсификации рисков ("не складывать все яйца в одну корзину"), состоящий в том, что инвестиционный портфель должен состоять из разнородных активов. Даже если один из активов упадёт в цене, совокупный портфель подешевеет не сильно, поскольку будет включать в себя различные активы.


Разные типы данных


Необходимость использования ансамблей может вытекать из свойств самой задачи. Например, при многоклассовой классификации, когда используется 
набор бинарных классификаторов
. Или когда уже построены отдельные базовые модели (например, идентификаторы человека по голосу, по лицу, по отпечатку пальцев), и мы хотим уточнить итоговый прогноз, учитывая мнения всех моделей.
Предыдущая страница
Ансамбли моделей
Следующая страница
Математическое обоснование ансамблей
Идея
Борьба с переобучением
Борьба с недообучением
Повышение устойчивости
© 2023-25 
Виктор Китов.
 
Новости проекта.









Математическое обоснование ансамблей | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Ансамбли моделей
Математическое обоснование ансамблей
Простая агрегация в ансамблях
Методы построения базовых моделей
Настройка на разных фрагментах обучающей выборки
Ансамбли рандомизированных деревьев
Стэкинг
Дополнительная литература
Вопросы
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Ансамбли моделей
Математическое обоснование ансамблей
Содержание этой страницы
Математическое обоснование ансамблей


Уточнение прогнозов при равномерном усреднении
​


Рассмотрим задачу регрессии с усредняющим ансамблем:





Пусть 

 - ошибки прогнозирования базовыми моделями 

 со средним ноль, дисперсией 

, и пусть эти ошибки имеют попарную корреляцию 

. Тогда ковариации ошибок будут:





а ожидаемый квадрат ошибки отдельной базовой модели:





Можно показать, что ожидаемый квадрат ошибки усредняющего ансамбля будет следующим:





Доказательство



Анализ
​


При 

 ожидаемый квадрат ошибки ансамбля будет в 

 раз меньше, чем квадрат ошибки отдельной базовой модели, а при 

 он может быть ещё меньше за счёт рассогласованности прогнозов и взаимной компенсации ошибок разных моделей!


При максимальной скоррелированности ошибок (

) ожидаемо получим, что квадрат ошибки ансамбля совпадёт с квадратом ошибки отдельной базовой модели, и использование ансамбля преимущества не даст.


На практике базовые модели будут различными, а их прогнозы в общем случае будут обладать положительной корреляцией 

, поэтому квадрат ошибки ансамбля будет 
меньше
, чем квадрат ошибки одной базовой модели.




Положительная скоррелированность вызвана тем, что эти базовые модели будут обучаться предсказывать одну и ту же целевую переменную на одной и той же обучающей выборке. Чтобы уменьшить корреляцию, рекомендуется выбирать базовые модели из разных классов (линейные, метрические, решающие деревья).




Уточнение прогнозов при неравномерном усреднении
​


Рассмотрим задачу регрессии, решаемую ансамблем





где 

 - веса, с которыми мы учитываем базовые модели.


В простейшем случае можно взять равномерное усреднение:





однако взвешенный учёт позволяет 
более точным базовым моделям назначать больший вес
.


Результат выше (для ожидаемого квадрата ошибки) можно обобщить и на случай взвешенного учёта базовых моделей (выведите!) с обоснованием эффективности ансамблей. Однако здесь мы продемонстрируем другое иллюстративное разложение квадрата ошибки, справедливое даже не для мат. ожидания, а для отдельного объекта 

, называемое 
разложением неоднозначности
 (ambiguity decomposition 
[1]
):





Доказательство



Из этого разложения видно, что ансамбль даёт точные прогнозы, когда базовые модели достаточно точны. Но даже если они не точны, мы всё равно имеем возможность уменьшить квадрат ошибки за счёт использования базовых моделей, дающих 
более рассогласованные прогнозы
 с высоким значением неоднозначности. Отсюда следует, как и раньше, что выгодно усреднять как можно более непохожие друг на друга базовые модели: модели из разных классов с разными значениями гиперпараметров!




Также при настройке новой модели, помимо критерия средних потерь, можно включать регуляризацию, 
в явном виде поощряющую рассогласованность прогнозов
 базовых моделей. Например, в 
[2]
 предложено обучать несколько моделей, штрафуя не только квадраты отклонений от целевой переменной, но и корреляции между прогнозами.




Классификация
​


Рассмотрим задачу бинарной классификации базовыми моделями 

. Пусть для каждой базовой модели вероятность предсказать правильный класс равна 

. Предположим, что модели ошибаются независимо друг от друга, а агрегирующая модель 

 - 
голосование по большинству
 (majority voting), в котором итоговым классом назначается тот класс, за который проголосовало большинство базовых моделей.


При указанных предположениях оказывается, что, увеличивая число базовых моделей, вероятность ошибки можно сделать сколь угодно малой:







Это переформулировка теоремы Кондорсе 
[3]
 о присяжных в терминах машинного обучения.




Доказательство
Рассмотрим случайную величину 

, принимающую значение 1, если m-й классификатор верно угадал класс, и значение 0, если неверно.
Тогда среднее этих случайных величин 

 будет больше 0.5 тогда и только тогда, когда прогноз всего ансамбля будет верным, поскольку это условие характеризует ситуацию, когда большинство базовых классификаторов не ошиблись и назначили верный класс. Вероятность верного прогноза для всего ансамбля будет 

.
По центральной предельной теореме

Поэтому 

 при 

.
Обратим внимание, что  

 и 

, откуда следует, что 

 по 
неравенству Чебышева
.
Задача
Сформулируйте и докажите это утверждение для многоклассового случая.


Отметим, что мы потребовали, чтобы базовые модели угадывали верный класс при 

. Например, при 

. Для бинарного случая это означает, что базовые классификаторы могут быть лишь немного лучше случайного угадывания для получения сколь угодно точного прогноза ансамблем!


В чём проблема этого достичь на практике?
На практике ошибки классификаторов нельзя считать независимыми - они пытаются предсказывать одну и ту же целевую величину и настраиваются по одинаковой обучающей выборке. Но мы, тем не менее, можем снизить их зависимость, если будем брать базовые классификаторы из разных классов или с разными конфигурациями гиперпараметров.


Литература
​






Krogh A., Vedelsby J. Neural network ensembles, cross validation, and active learning //Advances in neural information processing systems. – 1994. – Т. 7.






Liu Y., Yao X. Ensemble learning via negative correlation //Neural networks. – 1999. – Т. 12. – №. 10. – С. 1399-1404.






Викиконспекты ИТМО: виды ансамблей.




Предыдущая страница
Ансамбли моделей
Следующая страница
Простая агрегация в ансамблях
Уточнение прогнозов при равномерном усреднении
Анализ
Уточнение прогнозов при неравномерном усреднении
Классификация
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Простая агрегация в ансамблях | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Ансамбли моделей
Математическое обоснование ансамблей
Простая агрегация в ансамблях
Методы построения базовых моделей
Настройка на разных фрагментах обучающей выборки
Ансамбли рандомизированных деревьев
Стэкинг
Дополнительная литература
Вопросы
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Ансамбли моделей
Простая агрегация в ансамблях
Содержание этой страницы
Простая агрегация в ансамблях


При борьбе с 
переобучением
 (overfitting) базовых моделей 

 используются простые агрегирующие функции 

. Рассмотрим основные типы таких агрегаций для задач регрессии и классификации.


Регрессия
​


При решении задачи регрессии прогнозы базовых алгоритмов можно усреднять:







Как вариант, среднее можно заменить на вычисление 
медианы
 прогнозов. Это имеет смысл при наличии выбросов в данных и использовании неустойчивых к выбросам моделей. Тогда, даже если одна из моделей выдаст аномально низкий или высокий прогноз, это не сильно изменит итоговый прогноз ансамбля.




Другим и гораздо более популярным вариантом усреднения является взвешенное среднее:





Взвешенное среднее лучше, когда 
базовые модели сильно различаются по точности
. В этом случае целесообразно задать 
больший вес более точной модели
.


Усложнение взвешенного усреднения
При взвешенном усреднении веса могут быть не фиксированными константами, а функциями, зависящими от вектора признаков:

Например, веса могут считаться как 
SoftMax преобразование
 от линейных функций от признаков. В этом случае разные модели будут более предпочтительными в разных участках признакового пространства. Этот подход называется 
смесь экспертов
 (mixture of experts 
[1]
).


Классификация
​


При агрегации прогнозов классификаторов необходимо различать три случая, когда классификаторы выдают:






вероятности классов,






метки классов






рейтинги классов (
дискриминантные функции
).






Рассмотрим агрегирование прогнозов для каждого из этих случаев.


Классификаторы выдают вероятности классов
​


В этом случае каждый классификатор выдаст вектор вероятностей классов, которые мы можем усреднить, чтобы получить итоговое распределение классов.


Вероятность класса 

 в этом случае будет средним по предсказанным вероятностям этого класса для всех классификаторов:







Аналогично регрессии,  равномерное усреднение можно заменить взвешенным.




Классификаторы выдают метки классов
​


В этом случае в качестве агрегирующей функции можно взять 
голосование по большинству
 (majority vote), то есть назначать тот класс, за который проголосовало большинство базовых классификаторов.


Если классификаторы неравнозначны между собой (за счёт сильных различий в точности), то лучше использовать взвешенное голосование, при котором голоса более точных классификаторов учитываются с б
о
льшим весом.


Бинарная классификация
​


Когда классов всего два, то можно предсказывать положительный класс, когда этот класс предсказывают






все базовые классификаторы  (правило AND),






хотя бы один из классификаторов (правило OR),






по крайней мере K классификаторов (правило K-out-of-N).






Последнее правило обобщает стратегии AND и OR при K=N и K=1 соответственно. Правило OR используется при обнаружении аномалий отдельными классификаторами: если хотя бы один базовый классификатор увидел что-то необычное в объекте, то он считается аномалией.


Классификаторы выдают рейтинги
​


Как мы знаем, каждый классификатор внутри себя рассчитывает 
рейтинги классов
 при построении прогноза. Соответственно, можно извлекать не окончательные метки, а вектора рейтингов классов 

 для соответствующих базовых классификаторов 

, после чего их усреднять:





получая вектор рейтингов для ансамбля:





Далее, как обычно, прогнозируется класс, обладающий максимальным рейтингом:





Ограничения подхода
Этот подход работает только для классификаторов из одного семейства, у которых рейтинги изменяются в одной шкале! Для моделей разных типов так делать нельзя, поскольку тогда ранжирование будет доминироваться классификатором с рейтингами, принимающими 
максимально широкий диапазон значений
.


Корректировка для классификаторов разных типов
​


В общем случае классификаторы разных типов выдают рейтинги в разном диапазоне, поэтому усреднять их нельзя, как показано в примере ниже:







100
70
34
-25

15
0
-14
-10

0.05
0.6
0.2
0.15


Рейтинги первой модели имеют максимальный разброс значений, поэтому при усреднении в основном определять прогноз будут именно они! Чтобы такого не происходило, перед усреднением рейтингов их необходимо 
привести к единой шкале
.


Для этого применяется 
ранговое преобразование
, в котором новый рейтинг класса считается как количество других классов, которые рассматриваемый класс доминирует по рейтингу (принимая более высокое значение дискриминантной функции). Преобразованный рейтинги называется Borda counts 
[2]
.


В примере выше модели ранжируют классы следующим образом:


модель
ранжирование классов








Преобразованные рейтинги будут:







3
2
1
0

3
2
0
1

0
3
2
1


Они принадлежат уже 
одинаковой шкале значений
 

, поэтому их можно усреднять. В результате усреднения получим следующие рейтинги для ансамбля:






6/3
7/3
3/3
2/3


Далее, как обычно, назначается класс с максимальным средним рейтингом. Это будет класс 2.




Заметим, что прогноз отличается от прогноза голосованием по большинству, когда был назначен класс 1. Класс 2 победил новым способом, поскольку класс 2 считается вероятным всеми тремя классификаторами, а класс 1 считается самым маловероятным третьей моделью 

.




Учёт классификаторов с разной степенью
Как и раньше, если классификаторы сильно различаются по точности, их рейтинги  можно усреднять не равномерно, а с весами, назначая более высокий вес более точным классификаторам.


Пример запуска в Python
​


Усредняющий ансамбль для классификации:


from
 sklearn
.
linear_model 
import
 LogisticRegression
from
 sklearn
.
tree 
import
 DecisionTreeClassifier
from
 sklearn
.
ensemble 
import
 VotingClassifier
from
 sklearn
.
metrics 
import
 accuracy_score
from
 sklearn
.
metrics 
import
 brier_score_loss
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_classification_data
(
)
# Инициализируем базовые модели и проверим их качество
log_model 
=
 LogisticRegression
(
)
   
# инициализация модели
log_model
.
fit
(
X_train
,
 Y_train
)
    
# обучение модели   
Y_hat 
=
 log_model
.
predict
(
X_test
)
  
# построение прогнозов
print
(
f'Точность LogisticRegression: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
  
tree_model 
=
 DecisionTreeClassifier
(
)
  
# инициализация дерева
tree_model
.
fit
(
X_train
,
 Y_train
)
       
# обучение модели   
Y_hat 
=
 tree_model
.
predict
(
X_test
)
     
# построение прогнозов
print
(
f'Точность DecisionTree: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
  
# Инициализируем ансамбль, усредняющий метки классов
ensemble 
=
 VotingClassifier
(
estimators
=
[
(
'logistic regression'
,
 log_model
)
,
 
                                        
(
'decision tree'
,
 tree_model
)
]
,
 
                            voting
=
'hard'
,
      
# усредняем метки классов
                            weights
=
[
0.5
,
0.5
]
)
  
# веса учёта базовых моделей
ensemble
.
fit
(
X_train
,
 Y_train
)
     
# обучение базовых моделей ансамбля
Y_hat 
=
 ensemble
.
predict
(
X_test
)
   
# построение прогнозов
print
(
f'Точность VotingClassifier: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
  
# Инициализируем ансамбль, усредняющий вероятности классов
ensemble 
=
 VotingClassifier
(
estimators
=
[
(
'logistic regression'
,
 log_model
)
,
 
                                        
(
'decision tree'
,
 tree_model
)
]
,
 
                            voting
=
'soft'
,
      
# усредняем вероятности классов
                            weights
=
[
0.5
,
0.5
]
)
  
# веса учёта базовых моделей
ensemble
.
fit
(
X_train
,
 Y_train
)
     
# обучение базовых моделей ансамбля
Y_hat 
=
 ensemble
.
predict
(
X_test
)
   
# построение прогнозов
print
(
f'Точность VotingClassifier: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
  
P_hat 
=
 ensemble
.
predict_proba
(
X_test
)
  
# можно предсказывать вероятности классов
loss 
=
 brier_score_loss
(
Y_test
,
 P_hat
[
:
,
1
]
)
  
# мера Бриера на вероятности положительного класса
print
(
f'Мера Бриера ошибки прогноза вероятностей: 
{
loss
:
.2f
}
'
)




Больше информации
. 
Полный код
.


Усредняющий ансамбль для регрессии:


from
 sklearn
.
neighbors 
import
 KNeighborsRegressor
from
 sklearn
.
tree 
import
 DecisionTreeRegressor
from
 sklearn
.
ensemble 
import
 VotingRegressor
from
 sklearn
.
metrics 
import
 mean_absolute_error
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_classification_data
(
)
# Инициализируем базовые модели и проверим их качество
knn 
=
 KNeighborsRegressor
(
n_neighbors
=
100
)
    
# инициализация модели
log_model
.
fit
(
X_train
,
 Y_train
)
     
# обучение модели   
Y_hat 
=
 log_model
.
predict
(
X_test
)
   
# построение прогнозов
print
(
f'Средний модуль ошибки (MAE): 
{
mean_absolute_error
(
Y_test
,
 Y_hat
)
:
.2f
}
'
)
   
tree_model 
=
 DecisionTreeRegressor
(
)
 
# инициализация дерева
tree_model
.
fit
(
X_train
,
 Y_train
)
     
# обучение модели   
Y_hat 
=
 tree_model
.
predict
(
X_test
)
   
# построение прогнозов
print
(
f'Средний модуль ошибки (MAE): 
{
mean_absolute_error
(
Y_test
,
 Y_hat
)
:
.2f
}
'
)
    
# Инициализируем усредняющий ансамбль
ensemble 
=
 VotingRegressor
(
estimators
=
[
(
'K nearest neighbours'
,
 knn
)
,
 
                                       
(
'decision tree'
,
 tree_model
)
]
,
 
                           weights
=
[
0.5
,
0.5
]
)
  
# веса учёта базовых моделей
ensemble
.
fit
(
X_train
,
 Y_train
)
     
# обучение базовых моделей ансамбля
Y_hat 
=
 ensemble
.
predict
(
X_test
)
   
# построение прогнозов
print
(
f'Средний модуль ошибки (MAE): 
{
mean_absolute_error
(
Y_test
,
 Y_hat
)
:
.2f
}
'
)
     




Больше информации
. 
Полный код
.


Также с примером работы усредняющего классификатора можно ознакомиться в 
[3]
.


Более подробно работа простых ансамблей описана в 
[4]
.


Литература
​






Wikipedia: Mixture of experts.






Wikipedia: Borda count.






Geeksforgeeks: Voting Classifier.






Webb A. R., Copsey K.D. Statistical pattern recognition. – John Wiley & Sons, 2011.




Предыдущая страница
Математическое обоснование ансамблей
Следующая страница
Методы построения базовых моделей
Регрессия
Классификация
Классификаторы выдают вероятности классов
Классификаторы выдают метки классов
Классификаторы выдают рейтинги
Пример запуска в Python
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Методы построения базовых моделей | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Ансамбли моделей
Математическое обоснование ансамблей
Простая агрегация в ансамблях
Методы построения базовых моделей
Настройка на разных фрагментах обучающей выборки
Ансамбли рандомизированных деревьев
Стэкинг
Дополнительная литература
Вопросы
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Ансамбли моделей
Методы построения базовых моделей
Методы построения базовых моделей


Для построения ансамбля необходимо строить много базовых моделей. Можно брать модели из разных семейств (решающие деревья, линейные модели, метод K ближайших соседей и др.), но базовые модели можно строить и в рамках одного семейства следующими способами:






Использовать разные гиперпараметры
. Например, разное 

 в методе 

 ближайших соседей или разную допустимую глубину при настройке решающих деревьев.






Использовать разные начальные инициализации при настройке градиентными методами
. Этот метод приводит к разным прогнозирующим алгоритмам, если целевая функция невыпукла, например, при настройке нейросетей.






Использовать разную инициализацию для генератора случайных чисел (random seed)
. Этот метод применим только для для рандомизированных моделей, то есть моделей, использующих случайность в процессе своей настройки, такими как 
случайный лес или особо случайные деревья
.






Предсказывать целевую переменную с разными функциями потерь
. Использование различных функций потерь приведёт к настройке разных окончательных моделей даже по одинаковым данным. Например, можно настраивать классификаторы по одинаковым данным, но с экспоненциальной, логистической и hinge функцией потерь!






Настраивать модель предсказывать различные преобразования целевой переменной
, например 

. За счёт аппроксимации по-разному преобразованной целевой переменной базовые модели будут получаться разными. К прогнозам базовых моделей нужно потом применить обратное преобразование для возврата к исходной шкале 

 перед последующим усреднением.






Настраивать одну модель на разных фрагментах обучающей выборки
. Фрагменты можно выбирать по-разному, и этому посвящён следующий раздел.






Параллелизация вычислений
Каждая базовая модель настраивается 
независимо от остальных
, поэтому их можно 
настраивать параллельно
, используя разные ядра процессора либо даже на разных компьютерах.
Предыдущая страница
Простая агрегация в ансамблях
Следующая страница
Настройка на разных фрагментах обучающей выборки
© 2023-25 
Виктор Китов.
 
Новости проекта.









Настройка на разных фрагментах обучающей выборки | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Ансамбли моделей
Математическое обоснование ансамблей
Простая агрегация в ансамблях
Методы построения базовых моделей
Настройка на разных фрагментах обучающей выборки
Ансамбли рандомизированных деревьев
Стэкинг
Дополнительная литература
Вопросы
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Ансамбли моделей
Настройка на разных фрагментах обучающей выборки
Содержание этой страницы
Настройка на разных фрагментах обучающей выборки


Идеи методов
​


Пусть исходная обучающая выборка состоит из 

 объектов. Для генерации разнообразных моделей из одного семейства чаще всего используется настройка моделей 
на разных фрагментах обучающей выборки
 

.


Чтобы настроить 

 моделей, необходимо по единообразной схеме сгенерировать M фрагментов выборки 

, называемых 
псевдовыборками
. На каждой псевдовыборке настраивается модель одного класса (как правило, решающее дерево). Но настроенные модели будут получаться разными, поскольку они настраиваются на разных наборах объектов!


Агрегация базовых моделей
Поскольку все псевдовыборки строятся по единообразной схеме, а базовые модели берутся из одного семейства, полученные базовые алгоритмы будут однородны и равнозначны между собой. Поэтому в качестве агрегирующей функции используется 
равномерное усреднение
:



Процесс построения ансамбля по разным псевдовыборкам показан на схеме ниже:


[IMAGE]


Для генерации псевдовыборок используются следующие подходы:






Кросс-валидация
 (cross-validation): вся выборка разбивается по объектам на 

 случайных блоков одного размера. 

-я псевдовыборка включает все блоки, кроме блока 

, 

. Это аналогично 
кросс-валидации
 при оценке качества прогнозов. В результате каждая модель будет настраиваться, используя примерно 

 объектов.






Бэггинг
 (bagging): псевдовыборка генерируется такого же размера, что и исходная выборка, с помощью 
сэмплирования объектов с возвращением
 (with replacement). В результате некоторые объекты могут появиться в псевдовыборке несколько раз, а некоторые - ни разу. Если быть точнее, то вероятность не выбрать определённый объект равна 

, а вероятность не выбрать его 

 раз равна 

. При 

 она будет стремиться к 

 (докажите!), в результате чего псевдовыборка будет содержать примерно 2/3 исходных объектов, но её размер будет по-прежнему 

 за счёт того, что некоторые объекты используются несколько раз. Псевдовыборка, полученная таким образом, называется 
бустраповской псевдовыборкой
 (bootstrap sample 
[1]
, предложена в 
[2]
) и широко используется в статистике для получения эмпирических распределений тестовых статистик.






Пэйстинг
 (pasting): псевдовыборка генерируется из исходной с помощью 
сэмплирования объектов без возвращения
 (without replacement). Чтобы псевдовыборка получалась отличной от исходной, необходимо, чтобы размер псевдовыборки был строго меньше 

. Пэйстинг удобен для больших данных, где бэггинг слишком ресурсоёмок.






Метод случайных подпространств
 (random subspaces): в этом методе берутся все объекты исходной выборки, а 
сэмплируются признаки без возвращения
. Модель, обученная на такой выборке, будет использовать лишь часть от всех располагаемых признаков.






Метод случайных фрагментов
 (random patches 
[3]
): комбинируется сэмплирование объектов и признаков без возвращения. Это практично, когда приходится работать как с большим объёмом объектов, так и признаков. Вариация метода - сэмплировать объекты с возвращением, как в бэггинге.






Ниже показано сравнение регрессионных прогнозов для одного решающего дерева и для бэггинга над решающими деревьями:


[IMAGE]


Видно, что одно решающее дерево даёт кусочно-постоянное решение с более резкими перепадами прогнозов по сравнению с ансамблем над многими деревьями.


Во всех представленных методах можно варьировать число псевдовыборок 

. Поскольку на каждой псевдовыборке настраивается модель одного типа, то все базовые алгоритмы равнозначны, поэтому их прогнозы в итоге 
усредняются с равными весами
.


При увеличении числа базовых алгоритмов качество может только увеличиваться. Вначале оно резко падает (поскольку малое число псевдовыборок охватывает далеко не все данные), а потом выходит на стабильную асимптоту, как показано на рисунке ниже:


[IMAGE]




Поэтому по гиперпараметру 

 нельзя переобучиться: качество может только вырасти или остаться прежним, если 

 взять слишком большим.




Однако сложность настройки ансамбля и построения прогнозов 
линейно растёт с ростом числа базовых моделей
. Поэтому на практике подбирают оптимальные значения других гиперпараметров (например, функцию неопределённости, минимальное число объектов в листах при настройке ансамбля над решающими деревьями) при невысоком 

, а в финальной версии модели увеличивают 

 при 
уже настроенных гиперпараметрах
.


Неопределённость прогноза
Поскольку все базовые модели равнозначны между собой, можно рассчитывать не только среднее от их прогнозов 

, но и стандартное отклонение, которое будет показывать неопределённость прогноза. Это повышает прозрачность использования модели, поскольку даёт возможность дифференцировать ситуации, когда ансамбль уверен в своём прогнозе, а когда - нет. В последнем случае можно передать объект на обработку другому более продвинутому методу.


С представленными методами генерации ансамблей можно также ознакомиться в 
[4]
.


Оценка Out-of-Bag
​


Честная оценка качества модели требует выделения отдельной валидационной выборки или процедуры кросс-валидации, что сокращает объём данных для обучения модели. 
Метод оценивания out-of-bag
 (OOB estimate) позволяет использовать 
ту же обучающую выборку для оценивания качества ансамбля, что использовалась для его настройки
, и применим к методам, в которых базовые модели обучаются на подмножествах объектов: кросс-валидация, бэггинг, пэйстинг и метод случайных фрагментов.


Поскольку каждая базовая модель использует не все, а лишь подмножество объектов обучающей выборки, то для каждого объекта 

 можно составить множество 

 тех псевдовыборок (и соответствующих базовых моделей), куда этот объект не попал. Далее мы можем получить честный прогноз для 

, усредняя не по всем базовым моделям, а только по 
подмножеству моделей, обучающие псевдовыборки которых не содержали выбранный объект
:





Для моделей, проиндексированных 

, объект 

 будет новым, и в результате мы построим честный вневыборочный прогноз, 
не прибегая к отдельной валидационной выборке
. Out-of-Bag-оценка (OOB-estimate 
[5]
) строится указанным способом, усредняя out-of-bag прогнозы по всем объектам обучающей выборки.


Как в среднем связана OOB-оценка со средними потерями на тестовой выборке?
OOB-оценка несмещённо оценивает качество ансамбля, использующего не все, а лишь 
подмножество базовых моделей
. Итоговая же модель использует все базовые модели. Чем количество базовых моделей больше, тем прогноз получается точнее в общем случае, поэтому реальное качество на тестовой выборке будет в среднем даже немного выше, чем оценка out-of-bag.


Пример запуска на Python
​


Бэггинг для классификации:


from
 sklearn
.
ensemble 
import
 BaggingClassifier
from
 sklearn
.
tree 
import
 DecisionTreeClassifier
from
 sklearn
.
metrics 
import
 accuracy_score
from
 sklearn
.
metrics 
import
 brier_score_loss
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_classification_data
(
)
  
# инициализация модели:
model 
=
 BaggingClassifier
(
DecisionTreeClassifier
(
)
,
  
# базовая модель
                          max_samples
=
0.8
,
           
# доля случайных объектов для обучения
                          max_features
=
1.0
,
          
# доля случайных признаков для обучения
                          n_jobs
=
-
1
)
                 
# использовать все ядра процессора
model
.
fit
(
X_train
,
 Y_train
)
    
# обучение модели   
Y_hat 
=
 model
.
predict
(
X_test
)
  
# построение прогнозов
print
(
f'Точность прогнозов: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
P_hat 
=
 model
.
predict_proba
(
X_test
)
  
# можно предсказывать вероятности классов
loss 
=
 brier_score_loss
(
Y_test
,
 P_hat
[
:
,
1
]
)
  
# мера Бриера на вероятности положительного класса
print
(
f'Мера Бриера ошибки прогноза вероятностей: 
{
loss
:
.2f
}
'
)






Бэггинг для регрессии:


from
 sklearn
.
ensemble 
import
 BaggingRegressor
from
 sklearn
.
tree 
import
 DecisionTreeRegressor
from
 sklearn
.
metrics 
import
 mean_absolute_error
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_classification_data
(
)
  
# инициализация модели:
model 
=
 BaggingRegressor
(
DecisionTreeRegressor
(
)
,
  
# базовая модель
                         max_samples
=
0.8
,
          
# доля случайных объектов для обучения
                         max_features
=
1.0
,
         
# доля случайных признаков для обучения
                         n_jobs
=
-
1
)
                
# использовать все ядра процессора
model
.
fit
(
X_train
,
 Y_train
)
    
# обучение модели   
Y_hat 
=
 model
.
predict
(
X_test
)
  
# построение прогнозов
print
(
f'Средний модуль ошибки (MAE): 
{
mean_absolute_error
(
Y_test
,
 Y_hat
)
:
.2f
}
'
)
    




Больше информации
. 
Полный код
.


Литература
​






Wikipedia: Bootstrapping.






Efron B. Bootstrap methods: another look at the jackknife //The Annals of Statistics. 1979. – С. 1–26.






Louppe G., Geurts P. Ensembles on random patches //Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2012, Bristol, UK, September 24-28, 2012. Proceedings, Part I 23. – Springer Berlin Heidelberg, 2012. – С. 346-361.






Medium: ensemble techniques part 1-bagging & pasting.






Wikipedia: out-of-bag error.




Предыдущая страница
Методы построения базовых моделей
Следующая страница
Ансамбли рандомизированных деревьев
Идеи методов
Оценка Out-of-Bag
Пример запуска на Python
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Ансамбли рандомизированных деревьев | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Ансамбли моделей
Математическое обоснование ансамблей
Простая агрегация в ансамблях
Методы построения базовых моделей
Настройка на разных фрагментах обучающей выборки
Ансамбли рандомизированных деревьев
Стэкинг
Дополнительная литература
Вопросы
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Ансамбли моделей
Ансамбли рандомизированных деревьев
Содержание этой страницы
Ансамбли рандомизированных деревьев


Как известно из 
разложения неоднозначности
 (ambiguity decomposition), ансамбли моделей дают более точные прогнозы, если базовые модели оказываются 
более непохожими друг на друга
, производя более рассогласованные прогнозы. Когда строится ансамбль над решающими деревьями, то для повышения разнообразия предлагается строить деревья 
рандомизированным способом
, то есть включая элемент случайности при их построении. На этом основаны алгоритмы 
решающего леса
 (random forest) и 
особо случайных деревьев
 (extra random trees), представляющие собой сильные базовые решения (baseline) для работы с табличными данными.


Настройка решающих правил в деревьях
​


При 
настройке классических решающих деревьев
 в каждом внутреннем узле нужно выбрать правило вида 

: если 

-й признак больше порога 

, то происходит переход в правую дочернюю вершину, иначе - в левую. Выбор номера признака и порога в узле 

 осуществляется по правилу:





где 

 - изменение функции неопределённости в вершине 

 после разбиения.


Обычное дерево
​


В формуле (1) 

 представляет собой набор пар (признак, порог), формирующийся перебором всех возможных пар (признак, порог):





 
для каждого 

 in 

 




для каждого 

 из 














Оператор 

 возвращает все уникальные значения признака 

 для объектов, попавших в узел 

.


Настройка правил в случайном лесе
​


Случайный лес
 (random forest 
[1]
) строится как бэггинг над решающими деревьями, но правила в каждом узле (1) каждого дерева настраиваются 
по случайному подмножеству признаков и всем допустимым порогам для них
:





, 

 
сэмплируем без возвращения 

 случайно из 

 
для каждого 

 из 

:




для каждого 

 из 

:














 - гиперпараметр метода, характеризующий долю признаков, по которым происходит настройка правила в узле.




Например, при 

 для каждого узла дерева будет сэмплироваться только половина всех признаков, по которым будет настраиваться правило (1).




Обратим внимание, что в каждом узле дерева сэмплируется своё случайное подмножество признаков, поэтому дерево как целое может зависеть от всех признаков. Это отличает деревья случайного леса от деревьев в 
методе случайных подпространств
 (random subspaces), в котором каждое дерево целиком будет зависеть от случайного подмножества признаков.




Гиперпараметр 

 - 
основной гиперпараметр случайного леса
, контролирующий выразительную сложность модели!




Чем ниже 

, тем меньше свободы у каждого решающего дерева в подборе оптимального правила, и тем оно получается менее гибким и смещённым (недообученным). Зато прогнозы деревьев получаются менее похожими за счёт большего разнообразия правил, по которым строятся решающие деревья.


Если же увеличивать 

, то деревья гибче подстраиваются под данные и становятся более переобученными и менее разнообразными.


Оптимальная точность ансамбля достигается при некотором балансе между точностью отдельных моделей и разнообразием их прогнозов.


Нужен ли бэггинг?
В силу случайности, заложенной в построение каждого дерева случайного леса, использование 
бэггинга
 становится необязательным, так как даже на одинаковых выборках базовые алгоритмы будут получаться различными. Поэтому бэггинг можно как использовать, так и нет, в зависимости от того, какой вариант себя лучше покажет на валидационной выборке.


Настройка правил в особо случайных деревьях
​


Особо случайные деревья
 (extra trees, extremely randomized trees 
[2]
) также представляют собой бэггинг над решающими деревьями. Но если в деревьях решающего леса правила настраивались по подмножеству признаков 
и всем допустимым для них порогам
, то в особо случайном дереве 
пороги сэмплируются случайно вместе с признаками
, и настройка по порогу не производится. Это делает оптимизацию правил в каждом узле дерева еще более ограниченной, в результате чего деревья получаются ещё менее гибкими, зато дополнительно повышается их разнообразие.


Ниже приведён псевдокод для формирования пар (признак, порог), по которым производится настройка решающих правил в узле по правилу (1) каждого особо случайного дерева:





, 

 
сэмплируем без возвращения 

 случайно из 

 
для каждого 

 из 

:




сэмплируем 

 случайно без возвращения из 

 









Так же, как и в случае решающего леса, 

 - главный гиперпараметр метода, контролирующий сложность модели.




Поскольку деревья используют случайность при настройке, они будут получаться разнообразными даже при перенастройке на одной и той же обучающей выборке, поэтому процедура бэггинга для генерации разных обучающих псевдовыборок необязательна. Использовать её или нет определяется тем, какой вариант лучше себя покажет на валидационной выборке.




Пример запуска на Python
​


Случайный лес для классификации:


from
 sklearn
.
ensemble 
import
 RandomForestClassifier
from
 sklearn
.
metrics 
import
 accuracy_score
from
 sklearn
.
metrics 
import
 brier_score_loss
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_classification_data
(
)
  
# инициализация модели:
model 
=
 RandomForestClassifier
(
n_estimators
=
100
,
  
# число базовых моделей 
                               bootstrap
=
True
,
    
# обучать на подвыборках или всей выборке 
                               max_features
=
0.5
,
  
# доля случайных признаков для обучения 
                               n_jobs
=
-
1
)
         
# использовать все ядра процессора  
model
.
fit
(
X_train
,
 Y_train
)
    
# обучение модели   
Y_hat 
=
 model
.
predict
(
X_test
)
  
# построение прогнозов
print
(
f'Точность прогнозов: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
P_hat 
=
 model
.
predict_proba
(
X_test
)
  
# можно предсказывать вероятности классов
loss 
=
 brier_score_loss
(
Y_test
,
 P_hat
[
:
,
1
]
)
  
# мера Бриера на вероятности положительного класса
print
(
f'Мера Бриера ошибки прогноза вероятностей: 
{
loss
:
.2f
}
'
)






Случайный лес для регрессии:


from
 sklearn
.
ensemble 
import
 RandomForestRegressor
from
 sklearn
.
metrics 
import
 mean_absolute_error
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_regression_data
(
)
# инициализация модели:
model 
=
 RandomForestRegressor
(
n_estimators
=
100
,
  
# число базовых моделей
                              bootstrap
=
True
,
    
# обучать на подвыборках или всей выборке
                              max_features
=
0.5
,
  
# доля случайных признаков для обучения
                              n_jobs
=
-
1
)
         
# использовать все ядра процессора
model
.
fit
(
X_train
,
 Y_train
)
      
# обучение модели   
Y_hat 
=
 model
.
predict
(
X_test
)
    
# построение прогнозов
print
(
f'Средний модуль ошибки (MAE): 
{
mean_absolute_error
(
Y_test
,
 Y_hat
)
:
.2f
}
'
)
  




Больше информации
. 
Полный код
.


Особо случайные деревья для классификации:


from
 sklearn
.
ensemble 
import
 ExtraTreesClassifier
from
 sklearn
.
metrics 
import
 accuracy_score
from
 sklearn
.
metrics 
import
 brier_score_loss
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_classification_data
(
)
  
# инициализация модели:
model 
=
 ExtraTreesClassifier
(
n_estimators
=
100
,
  
# число базовых моделей 
                             bootstrap
=
True
,
    
# обучать на подвыборках или всей выборке 
                             max_features
=
1.0
,
  
# доля случайных признаков для обучения 
                             n_jobs
=
-
1
)
         
# использовать все ядра процессора 
model
.
fit
(
X_train
,
 Y_train
)
       
# обучение модели   
Y_hat 
=
 model
.
predict
(
X_test
)
     
# построение прогнозов
print
(
f'Точность прогнозов: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
P_hat 
=
 model
.
predict_proba
(
X_test
)
  
# можно предсказывать вероятности классов
loss 
=
 brier_score_loss
(
Y_test
,
 P_hat
[
:
,
1
]
)
  
# мера Бриера на вероятности положительного класса
print
(
f'Мера Бриера ошибки прогноза вероятностей: 
{
loss
:
.2f
}
'
)






Особо случайные деревья для регрессии:


from
 sklearn
.
ensemble 
import
 ExtraTreesRegressor
from
 sklearn
.
metrics 
import
 mean_absolute_error
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_regression_data
(
)
 
# инициализация модели:
model 
=
 ExtraTreesRegressor
(
n_estimators
=
100
,
  
# число базовых моделей  
                            bootstrap
=
True
,
    
# обучать на подвыборках или всей выборке  
                            max_features
=
0.5
,
  
# доля случайных признаков для обучения
                            n_jobs
=
-
1
)
         
# использовать все ядра процессора
model
.
fit
(
X_train
,
 Y_train
)
       
# обучение модели   
Y_hat 
=
 model
.
predict
(
X_test
)
     
# построение прогнозов
print
(
f'Средний модуль ошибки (MAE): 
{
mean_absolute_error
(
Y_test
,
 Y_hat
)
:
.2f
}
'
)
  




Больше информации
. 
Полный код
.


Литература
​






Breiman L. Random forests //Machine learning. – 2001. – Т. 45. – С. 5-32.






Geurts P., Ernst D., Wehenkel L. Extremely randomized trees //Machine learning. – 2006. – Т. 63. – С. 3-42.




Предыдущая страница
Настройка на разных фрагментах обучающей выборки
Следующая страница
Стэкинг
Настройка решающих правил в деревьях
Обычное дерево
Настройка правил в случайном лесе
Настройка правил в особо случайных деревьях
Пример запуска на Python
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Стэкинг | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Ансамбли моделей
Математическое обоснование ансамблей
Простая агрегация в ансамблях
Методы построения базовых моделей
Настройка на разных фрагментах обучающей выборки
Ансамбли рандомизированных деревьев
Стэкинг
Дополнительная литература
Вопросы
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Ансамбли моделей
Стэкинг
Содержание этой страницы
Стэкинг


Алгоритм стэкинга
 (stacking 
[1]
) решает задачу настройки ансамбля моделей





для общей ситуации, когда агрегирующая функция 

 имеет 
свои собственные настраиваемые параметры
.


Использование исходного вектора признаков
Агрегирующей функции, помимо прогнозов базовых моделей, можно передавать и исходный вектор признаков 

. В результате получим следующую функцию предсказания:

В этом случае агрегирующая модель получит возможность по-разному использовать прогнозы базовых моделей 
в разных частях признакового пространства
.




Базовые модели в стэкинге можно настраивать неточно, поскольку агрегирующая функция будет подправлять итоговый прогноз, учитывая ответы других моделей.




Линейный стэкинг
​


Простейшим примером 

 выступает линейная комбинация базовых моделей с настраиваемыми весами 

.







Смещение 

 включают, если агрегируются недообученные модели с систематическими смещениями. Если в базовых алгоритмах присутствуют переобученные модели, то они будут давать несмещенные прогнозы, и смещение 

 можно не включать.




Настройка весов производится методом 
линейной регрессии
, в которой признаками выступают не исходные признаковые описания объектов, а 
прогнозы базовых моделей
.


Переобучение
При настройке базовых моделей 

 и агрегирующей 

 
нельзя использовать одну и ту же обучающую выборку
, иначе будет происходить переобучение!


Рассмотрим пример. Пусть среди базовых моделей присутствует алгоритм одного ближайшего соседа. Очевидно, на обучающей выборке он будет обеспечивать 100% точность, поскольку ближайшим соседом для прогнозируемых объектов обучающей выборки будут выступать они сами. Тогда, при обучении параметров базовой модели на той же обучающей выборке, всё внимание агрегирующей модели будет направлено на самую переобученную модель!


Правильная настройка стэкинга будет рассмотрена ниже.


Специальные виды регуляризации
​


Веса 

 будут находиться неустойчиво из-за сильной корреляции признаков, которыми выступают прогнозы одной и той же целевой величины 

 разными базовыми моделями. Чтобы повысить устойчивость оценки весов и качество всего ансамбля, необходимо использовать регуляризацию на веса. Это может быть стандартная L1- или L2-регуляризация, но в контексте решаемой задачи целесообразно использование специального регуляризатора:





который будет прижимать веса не к нулевым значениям, а к равномерному усреднению базовых моделей, что представляет естественный вид 
равномерного усреднения
.


Дополнительно можно настраивать веса при условии их неотрицательности:





поскольку прогнозы базовых моделей должны получаться положительно скоррелированными с целевой величиной 

.


Стэкинг общего вида
​


В качестве агрегирующей модели 

 может выступать не только линейная регрессия, но вообще любая модель: логистическая регрессия, решающее дерево или даже другой ансамбль, например, решающий лес. Теоретически можно рассмотреть даже стэкинг над стэкингом, хотя это редко используется в связи со сложной процедурой настройки.


Настройка стэкинга
​


Если настраивать базовые модели и агрегирующую на одной и той же обучающей выборке, то будет происходить переобучение, вызванное тем, что базовые модели настраиваются на известные отклики, а агрегирующая повторно использует те же самые отклики. Чтобы так не происходило, можно использовать две стратегии: блендинг и стэкинг с кросс-валидацией.


Блендинг
​


В блендинге настройка базовых моделей и агрегирующей производится на двух разных выборках объектов, как показано на схеме:


[IMAGE]


Формально последовательность действий записывается следующим образом:






Разбить обучающую выборку 

 на две случайные подвыборки 

 и 

 размера 

 и 

.






Обучить базовые модели на 

.






Предсказать объекты выборки 

 каждой базовой моделью, в результате чего получить матрицу прогнозов базовыми моделями 

.






На обучающей выборке 

 обучить агрегирующую модель 

.






Донастроить базовые модели на всей обучающей выборке 

.






Последний шаг не приводит к переобучению и опционален. Без него агрегирующая модель максимально согласуется с базовыми, поскольку именно на них она настраивалась. Если же использовать последний шаг, то базовые модели получаются лучше настроенными (используя все наблюдения, а не часть), но будут хуже сочетаться с агрегирующей функцией, которая использовала их настройку на подвыборке 

, а не на всей выборке.


Пропорции разбиения на подвыборки
Обучающая выборка разбивается на первую и вторую выборку в пропорции примерно 80/20%, поскольку в стэкинге основная тяжесть прогнозирования ложится на базовые модели, а агрегирующей модели остаётся лишь оптимальным образом скомбинировать уже имеющиеся прогнозы.


Стэкинг с кросс-валидацией
​


Недостаток блэндинга заключается в том, что при настройке агрегирующей модели используются не все объекты, а лишь их подмножество, оказавшееся во второй выборке, что приводит к недостаточно точной настройке 

.


Повысить точность позволяет стэкинг с кросс-валидацией - это и есть алгоритм стэкинга по умолчанию.


Последовательность действий при настройке с кросс-валидацией будет следующей:






Разбить обучающую выборку 

 на 

 случайных подвыборок 

 одинакового размера (состоящие из 

 объектов).






Для 

:






настроить базовые модели на всех подвыборках кроме 

-ой, получив их настроенные версии 

;






спрогнозировать с помощью 

 объекты исключённой 

-й выборки, получив матрицу прогнозов 

.










Объединить все подвыборки прогнозов 

 в одну 

.






Добавить к 

 небольшой случайный шум.






На выборке 

 настроить агрегирующую модель 

.






Обучить базовые модели 

 на всей выборке 

.






Последний шаг нужен для замены 

 версий каждой базовой модели одной финальной.


Настройка агрегирующей модели корректна, поскольку основывается на честных вневыборочных прогнозах базовыми моделями на тех объектах, которые они не использовали при обучении. Настройка производится весьма точно, поскольку задействуются все 

 объектов исходной выборки.


Поскольку на втором шаге для каждой подвыборки настраивается своя версия каждой базовой модели, объединять напрямую их прогнозы не совсем правильно - это будут прогнозы, сделанные немного отличающимися моделями. Для их выравнивания используется шаг 4, на котором к прогнозам базовых моделей  добавляется случайный шум с небольшой дисперсией (гиперпараметр метода).


Вариант стэкинга
Вместо шага 6, на котором происходит перенастройка базовых моделей на всей обучающей выборке, для нового объекта 

 можно строить прогноз каждой версией всех базовых моделей, полученных на шаге 2. То есть построить 

 прогнозов моделями 

 для 

 

. Затем нужно для каждой версии базовых моделей провести агрегирование их прогнозов и усреднить по версиям:

Это в 

 раз замедляет построение прогноза, но может обеспечивать более высокую точность на некоторых типах данных.


Пример запуска в Python
​


Стэкинг для классификации:


from
 sklearn
.
neighbors 
import
 KNeighborsClassifier
from
 sklearn
.
tree 
import
 DecisionTreeClassifier
from
 sklearn
.
linear_model 
import
 LogisticRegression
from
 sklearn
.
ensemble 
import
 StackingClassifier
from
 sklearn
.
metrics 
import
 accuracy_score
from
 sklearn
.
metrics 
import
 brier_score_loss
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_classification_data
(
)
# Инициализируем базовые модели и проверим их качество
knn 
=
 KNeighborsClassifier
(
n_neighbors
=
100
)
    
# инициализация модели
knn
.
fit
(
X_train
,
 Y_train
)
     
# обучение модели   
Y_hat 
=
 knn
.
predict
(
X_test
)
   
# построение прогнозов
print
(
f'Точность прогнозов: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
  
tree_model 
=
 DecisionTreeClassifier
(
)
  
# инициализация дерева
tree_model
.
fit
(
X_train
,
 Y_train
)
       
# обучение модели   
Y_hat 
=
 tree_model
.
predict
(
X_test
)
     
# построение прогнозов
print
(
f'Точность прогнозов: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
  
# Инициализируем стэкинг
ensemble 
=
 StackingClassifier
(
estimators
=
[
(
'K nearest neighbors'
,
 knn
)
,
   
# базовые модели
                                          
(
'decision tree'
,
 tree_model
)
]
,
 
                              final_estimator
=
LogisticRegression
(
)
,
  
# агрегирующая модель
                              cv
=
3
,
        
# количество блоков кросс-валидации при настройке стэкинга
                              n_jobs
=
-
1
)
   
# используем все ядра процессора для настройки
ensemble
.
fit
(
X_train
,
 Y_train
)
     
# обучение базовых моделей` ансамбля
Y_hat 
=
 ensemble
.
predict
(
X_test
)
   
# построение прогнозов
print
(
f'Точность прогнозов: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
  
P_hat 
=
 ensemble
.
predict_proba
(
X_test
)
  
# можно предсказывать вероятности классов
loss 
=
 brier_score_loss
(
Y_test
,
 P_hat
[
:
,
1
]
)
  
# мера Бриера на вероятности положительного класса
print
(
f'Мера Бриера ошибки прогноза вероятностей: 
{
loss
:
.2f
}
'
)




Больше информации
. 
Полный код
.


Стэкинг для регрессии:


from
 sklearn
.
neighbors 
import
 KNeighborsRegressor
from
 sklearn
.
tree 
import
 DecisionTreeRegressor
from
 sklearn
.
linear_model 
import
 Ridge
from
 sklearn
.
ensemble 
import
 StackingRegressor
from
 sklearn
.
metrics 
import
 accuracy_score
from
 sklearn
.
metrics 
import
 brier_score_loss
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_classification_data
(
)
# Инициализируем базовые модели и проверим их качество
knn 
=
 KNeighborsRegressor
(
n_neighbors
=
100
)
  
# инициализация модели
knn
.
fit
(
X_train
,
 Y_train
)
                   
# обучение модели   
Y_hat 
=
 log_model
.
predict
(
X_test
)
           
# построение прогнозов
print
(
f'Средний модуль ошибки (MAE): 
{
mean_absolute_error
(
Y_test
,
 Y_hat
)
:
.2f
}
'
)
   
tree_model 
=
 DecisionTreeRegressor
(
)
  
# инициализация дерева
tree_model
.
fit
(
X_train
,
 Y_train
)
      
# обучение модели   
Y_hat 
=
 tree_model
.
predict
(
X_test
)
    
# построение прогнозов
print
(
f'Средний модуль ошибки (MAE): 
{
mean_absolute_error
(
Y_test
,
 Y_hat
)
:
.2f
}
'
)
   
# Инициализируем стэкинг
ensemble 
=
 StackingRegressor
(
estimators
=
[
(
'K nearest neighbors'
,
 knn
)
,
   
# базовые модели
                                         
(
'decision tree'
,
 tree_model
)
]
,
 
                              final_estimator
=
Ridge
(
)
,
  
# агрегирующая модель
                              cv
=
3
,
        
# количество блоков кросс-валидации при настройке стэкинга
                              n_jobs
=
-
1
)
   
# используем все ядра процессора для настройки
ensemble
.
fit
(
X_train
,
 Y_train
)
     
# обучение базовых моделей ансамбля
Y_hat 
=
 ensemble
.
predict
(
X_test
)
   
# построение прогнозов
print
(
f'Средний модуль ошибки (MAE): 
{
mean_absolute_error
(
Y_test
,
 Y_hat
)
:
.2f
}
'
)
      




Больше информации
. 
Полный код
.


Литература
​




Wolpert D. H. Stacked generalization //Neural networks. – 1992. – Т. 5. – №. 2. – С. 241-259.


Предыдущая страница
Ансамбли рандомизированных деревьев
Следующая страница
Дополнительная литература
Линейный стэкинг
Специальные виды регуляризации
Стэкинг общего вида
Настройка стэкинга
Блендинг
Стэкинг с кросс-валидацией
Пример запуска в Python
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Дополнительная литература | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Ансамбли моделей
Математическое обоснование ансамблей
Простая агрегация в ансамблях
Методы построения базовых моделей
Настройка на разных фрагментах обучающей выборки
Ансамбли рандомизированных деревьев
Стэкинг
Дополнительная литература
Вопросы
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Ансамбли моделей
Дополнительная литература
Содержание этой страницы
Дополнительная литература


В 
следующей главе учебника
 мы детально рассмотрим один из самых популярных и успешных алгоритмов построения ансамблей - алгоритм бустинга.


Дополнительно о методах построения ансамблей можно прочитать в 
[1]
 и 
[2]
, а также в 
[3]
, где также описаны байесовские методы построения ансамблей.


В 
[4]
 описана реализация представленных алгоритмов в библиотеке sklearn.


Литература
​




Дьяконов А.Г. Машинное обучение и анализ данных: ансамбли алгоритмов.


Учебник ШАД: ансамбли в машинном обучении.


Webb A. R., Copsey K.D. Statistical pattern recognition. – John Wiley & Sons, 2011.


Документация sklearn: ensembles, gradient boosting, random forests, bagging, voting, stacking.


Предыдущая страница
Стэкинг
Следующая страница
Вопросы
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Вопросы для самопроверки | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Ансамбли моделей
Математическое обоснование ансамблей
Простая агрегация в ансамблях
Методы построения базовых моделей
Настройка на разных фрагментах обучающей выборки
Ансамбли рандомизированных деревьев
Стэкинг
Дополнительная литература
Вопросы
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Ансамбли моделей
Вопросы
Вопросы для самопроверки




Возможно ли теоретически построить сколь угодно точный ансамбль моделей, использующий только неточные базовые модели?


Почему в общем случае нельзя усреднять дискриминантные функции разных базовых моделей в ансамбле? В чём смысл рангового преобразования перед усреднением рейтингов?


Может ли качество бэггинга устойчиво снижаться при выборе слишком большого числа базовых моделей?


Чем метод случайных подпространств отличается от алгоритма случайного леса?


Чем алгоритм случайного леса отличается от алгоритма особо случайных деревьев? В каком случае базовые модели получаются более недообученные?


Может ли качество прогнозов начать систематически ухудшаться с ростом числа базовых моделей в алгоритмах бэггинга, методе случайных подпространств, алгоритме случайного леса и особо случайных деревьев? Почему?


Оценка out-of-bag в среднем переоценивает или недооценивает качество прогнозов на тестовой выборке?


Почему в стэкинге нельзя настраивать агрегирующую модель на прогнозах тех же объектов, по которым настраивались базовые модели? Почему базовые модели можно донастроить на всех наблюдениях после того, как агрегирующая модель уже зафиксирована?


Предыдущая страница
Дополнительная литература
Следующая страница
Бустинг
© 2023-25 
Виктор Китов.
 
Новости проекта.









Бустинг | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Бустинг
Сравнение бустинга с другими ансамблями моделей
Алгоритм AdaBoost
Градиентный бустинг
Алгоритм градиентного бустинга
Улучшения градиентного бустинга
Иллюстрация работы
Градиентный бустинг второго порядка
Популярные реализации
Точность градиентного бустинга
Дополнительная литература
Вопросы
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Бустинг
Бустинг
Содержание этой страницы
Бустинг


Алгоритм бустинга
 (boosting 
[1]
) строит прогноз в виде ансамбля (композиции) базовых моделей:





Агрегирующая модель, на базе которой строится итоговый прогноз, представляет собой линейную комбинацию базовых моделей с настраиваемыми весами:





Все базовые модели, кроме начального приближения 

, берутся из одного семейства.




Как правило, начальное приближение выбирается тождественным нулём или настраиваемой константой, а остальные модели - решающими деревьями небольшой глубины.




Типы решаемых задач
​


Смысл 

 меняется в зависимости от решаемой задачи:






для 
регрессии
 

 предсказывает регрессионный прогноз:









для 
бинарной классификации
 

 представляет собой рейтинг положительного класса по сравнению с отрицательным. Итоговый прогноз 

 строится как функция взятия знака 

 (+1 для положительных и -1 для отрицательных аргументов):









в 
многоклассовой классификации
 на 

 классов 

 представляет собой вектор рейтингов для каждого класса, а прогноз строится по принципу назначения класса, обладающего максимальным рейтингом:









Принцип построения ансамбля
​


Базовые модели, кроме начального приближения 

, выбираются из одного класса, но неравнозначны между собой, поскольку 
настраиваются последовательно одна за другой
:







 настраивается приближать целевую величину 

;







 учится исправлять ошибки 

;







 учится исправлять ошибки 

;














 учится исправлять ошибки 

.






Более формально, решаются следующие задачи:






Настраиваем начальное приближение









Для 

:


находим коррекцию:





обновляем ансамбль:









Возвращаем 

.






Описанная процедура также известна как forward stagewise additive modeling 
[2]
.




На шаге 2 часто коэффициент 

 не настраивается, а берётся малой константой, называемой 
шаг обучения
 (learning rate).




Особенности реализации
​


Для эффективности применения ансамбля усреднение должно происходить по многим базовым моделям, поэтому в бустинге их число измеряется сотнями и даже тысячами.


Для того, чтобы строить ансамбль из большого числа моделей, базовые модели 
не должны быть слишком точными
, чтобы оставлять пространство для дальнейших уточнений последующими уточняющими моделями. Для этого, в частности, используются следующие принципы:






Начальное приближение полагается тождественному нулю 

 либо находится как наилучший константный прогноз 

.






Последующие базовые модели 

 берутся простыми и неточными. Чаще всего это 
решающие деревья
 небольшой глубины (~1-5) или с ограничением на максимальное число листьев (~2-32).


Какую модель получим, если будем строить бустинг над линейными моделями?
Комбинируя с весами линейные модели, мы снова получим линейную модель!
Поэтому бустинг над линейными моделями не используется.
Хотя можно взять линейную модель в качестве начального приближения,
а последующие базовые модели брать уже из другого семейства.






На каждой итерации настраивать модель 

 и коэффициент 

 при ней можно неточно. Часто 

 просто берут малой константой, так как настройка 

 уже настраивает общий масштаб изменения.






Литература
​






Wikipedia: boosting (machine learning).






Hastie T., Tibshirani R., Friedman J. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. – Springer Science & Business Media, 2009.




Предыдущая страница
Бустинг
Следующая страница
Сравнение бустинга с другими ансамблями моделей
Типы решаемых задач
Принцип построения ансамбля
Особенности реализации
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Сравнение бустинга с другими ансамблями моделей | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Бустинг
Сравнение бустинга с другими ансамблями моделей
Алгоритм AdaBoost
Градиентный бустинг
Алгоритм градиентного бустинга
Улучшения градиентного бустинга
Иллюстрация работы
Градиентный бустинг второго порядка
Популярные реализации
Точность градиентного бустинга
Дополнительная литература
Вопросы
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Бустинг
Сравнение бустинга с другими ансамблями моделей
Содержание этой страницы
Сравнение бустинга с другими ансамблями моделей


Бустинг и бэггинг
​


Ранее изученные 
алгоритмы построения ансамбля
, такие как 
бэггинг, метод случайных подпространств
 и 
случайный лес
, настраивают модели независимо друг от друга, что  снижает 
переобученность
 базовых моделей (снижает дисперсию их ошибок в 
разложении на смещение и разброс
). Это позволяет эффективно распределить настройку каждой модели по разным вычислительным устройствам. Также нельзя переобучиться по числу базовых моделей - при увеличении их числа среднее качество ансамбля будет только расти. Однако независимость построения каждой базовой модели 
не позволяет моделям исправлять систематические ошибки ансамбля
.


В бустинге же модели 
настраиваются последовательно, исправляя ошибки уже настроенного ансамбля
. В результате этого происходит борьба с недообученностью базовых моделей (снижение систематического смещения базовых моделей в 
разложении на смещение и разброс
). Поэтому алгоритм бустинга, как правило, работает точнее бэггинга, но требует более тщательной настройки по числу базовых моделей, поскольку может переобучаться, если их выбрать слишком много, как показано на графике:


[IMAGE]


Для подбора оптимального количества базовых моделей нужно 
отслеживать качество ансамбля на отдельной валидационной выборке
.


Также итеративная процедура настройки базовых моделей в бустинге 
не допускает параллелизацию
 в их обучении: настроить следующую модель возможно, лишь когда настроены все предыдущие!


Бустинг и стэкинг
​


Итеративная процедура настройки модели и коэффициента при ней в бустинге позволяет быстро строить линейную агрегирующую модель (как в 
линейном стэкинге
), однако коэффициент при текущей модели 
учитывают ошибки только предшествующих моделей
, но не будущих. Также базовые модели в стэкинге настраиваются предсказывать конечную целевую переменную, а в бустинге - 
ошибку прогнозирования текущим ансамблем
.
Предыдущая страница
Бустинг
Следующая страница
Алгоритм AdaBoost
Бустинг и бэггинг
Бустинг и стэкинг
© 2023-25 
Виктор Китов.
 
Новости проекта.









Алгоритм AdaBoost | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Бустинг
Сравнение бустинга с другими ансамблями моделей
Алгоритм AdaBoost
Градиентный бустинг
Алгоритм градиентного бустинга
Улучшения градиентного бустинга
Иллюстрация работы
Градиентный бустинг второго порядка
Популярные реализации
Точность градиентного бустинга
Дополнительная литература
Вопросы
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Бустинг
Алгоритм AdaBoost
Содержание этой страницы
Алгоритм AdaBoost


Алгоритм AdaBoost
 (
[1]
, впервые предложен в 
[2]
) исторически был первым алгоритмом бустинга. Он работает в следующей постановке:






Рассматривается задача бинарной классификации 

, решаемая с помощью экспоненциальной функции потерь 

.






Начальное приближение полагается равным нулю: 

.






В качестве базовых алгоритмов 

 можно брать любые алгоритмы, способные обучаться на 
взвешенной обучающей выборке
 (где каждое наблюдение учитывается со своим весом).






Обучение на взвешенной выборке
Большинство алгоритмов машинного обучения допускает минимизацию средних потерь на взвешенной выборке. Например, в решающих деревьях необходимо каждый объект 

 учитывать 

 раз при расчете функции неопределённости и минимизации потерь в листе.
Если алгоритм настройки не позволяет учитывать веса, можно сгенерировать обучающую выборку, в которой каждый объект будет повторяться пропорционально его весу (например, если вес равен 3, то объект в выборке нужно повторить 3 раза). Но этот способ работает только для целочисленных весов (таких как 1,2,3,...) и может приводить к большому разрастанию выборки.
Альтернативно (хоть это и не то же самое, а лишь приближение) можно обучать модель на случайной подвыборке объектов, в которую каждый объект попадает из обучающей выборки с вероятностью, пропорциональной весу наблюдения 

.


Результатом работы AdaBoost является относительный рейтинг положительного класса





а прогноз осуществляется знаком величины 

:





Алгоритм AdaBoost




Инициализируем веса объектов 

.






Для каждого 

:






Настраиваем 

 по выборке 

 с весами 

.






Вычисляем 
взвешенную
 частоту ошибок:









Если 

 или 

, то останавливаем построение ансамбля.






Вычисляем 

.






Пересчитываем веса:









Нормируем веса:













Возвращаем классификатор, действующий по правилу:









Анализ алгоритма
​


Проверка 

 на шаге 3 производится, поскольку если 

, то 

 безошибочно классифицирует все объекты выборки, и можно использовать только эту модель для классификации. На практике такое реализуется редко, поскольку в качестве базовых моделей используются очень простые алгоритмы, такие как деревья решений небольшой глубины.


Как видно по шагу алгоритма 2.i, каждая базовая модель 

 настраивается на одну и ту же исходную обучающую выборку 

, 
меняются лишь веса
, с которыми учитывается каждый объект.


Нормировка на шаге 2.vi производится для численной устойчивости, иначе веса могут снижаться до машинного нуля либо возрастать слишком сильно.


Из шага 2.v, видно, что веса зависят от промежуточного ансамбля 

 следующим образом:







Знак 

 означает "равен с точностью до константы", которая возникает в силу того, что веса перенормируются на шаге 2.vi, чтобы суммироваться в единицу.




Этот вид весов очень интуитивен, поскольку 

 представляет собой 
отступ
 при классификации объекта 

 ансамблем 

 и по смыслу представляет собой качество классификации этого объекта. Чем качество классификации объекта выше, тем соответствующий вес ниже, и следующая базовая модель будет слабее его учитывать. А чем качество ниже, тем вес проблемного объекта выше, что вынуждает следующую базовую модель сильнее его учитывать, чтобы исправить неточную классификацию.


Обобщение подхода
По аналогии с AdaBoost можно разработать собственную версию итеративного построения ансамбля, где на каждом шаге настраивается одна и та же модель по одной и той же обучающей выборке, но вес проблемных объектов повышается, а хорошо предсказанных - снижается по пользовательскому правилу.


На шаге 2.4 рассчитывается коэффициент при следующей базовой модели. Его зависимость от взвешенной частоты ошибок имеет вид:


[IMAGE]


Отсюда видно, что вес, с которым добавляется следующая базовая модель 

, тем выше, чем точнее она работает (

 ниже). Если 

, то 

 и новая базовая модель добавится с нулевым весом, не изменив ансамбль. Веса на шаге 2.v также не изменятся, поэтому последующие запуски алгоритма ничего изменять не будут. В связи с этим, при 

 на шаге 2.iii целесообразно досрочно останавливать алгоритм. При очень плохом классификаторе с частотой ошибок 

 процесс также останавливается, хотя остаётся вариант инвертировать его прогнозы (сделав 

) и продолжить процесс обучения.


Условие 

 гарантирует, что всегда выполнено условие 

.


Вывод AdaBoost
​


Выведем аналитически алгоритм AdaBoost.


Задаём начальное приближение 

. Настройка 

 будет производится, используя экспоненциальную функцию ошибки на отступ классификации:





Применяя правило последовательной настройки с этой функцией потерь, получим:





где веса для объекта 

 на итерации 

  определяем по правилу





Вывод множителя при базовой модели
​


Функция потерь, как сумма выпуклых функций (экспонент с неотрицательными коэффициентами), является выпуклой по 

. Поэтому не только необходимым, но и достаточным условием минимума является равенство нулю производной потерь в формуле (2):














где 

 - взвешенная частота ошибок:





Вывод критерия для настройки базовой модели
​


Распишем потери в формуле (2) в эквивалентном виде:





Первое слагаемое от 

 не зависит. Во втором слагаемом, поскольку 

, то 

, следовательно, для минимизации потерь по 

 необходимо, чтобы 

 решала задачу минимизации взвешенного числа ошибок:





Вывод формулы для пересчёта весов
​


Мы определили веса по формуле (1):





Следовательно,





Пример запуска на Python
​


AdaBoost для классификации:


from
 sklearn
.
ensemble 
import
 AdaBoostClassifier
from
 sklearn
.
metrics 
import
 accuracy_score
from
 sklearn
.
metrics 
import
 brier_score_loss
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_classification_data
(
)
  
# инициализация AdaBoost (по умолчанию-над деревьями)
model 
=
 AdaBoostClassifier
(
n_estimators
=
50
)
   
model
.
fit
(
X_train
,
 Y_train
)
     
# обучение модели   
Y_hat 
=
 model
.
predict
(
X_test
)
   
# построение прогнозов
print
(
f'Точность прогнозов: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
P_hat 
=
 model
.
predict_proba
(
X_test
)
  
# можно предсказывать вероятности классов
loss 
=
 brier_score_loss
(
Y_test
,
 P_hat
[
:
,
1
]
)
  
# мера Бриера на вер-ти положительного класса
print
(
f'Мера Бриера ошибки прогноза вероятностей: 
{
loss
:
.2f
}
'
)
 




Больше информации
. 
Полный код
.


Также в библиотеке sklearn существует алгоритм 
AdaBoost.R2
 для решения задачи регрессии.


Литература
​






Wikipedia: AdaBoost.






Freund Y., Schapire R. E. A desicion-theoretic generalization of on-line learning and an application to boosting //European conference on computational learning theory. – Berlin, Heidelberg : Springer Berlin Heidelberg, 1995. – С. 23-37.




Предыдущая страница
Сравнение бустинга с другими ансамблями моделей
Следующая страница
Градиентный бустинг
Анализ алгоритма
Вывод AdaBoost
Вывод множителя при базовой модели
Вывод критерия для настройки базовой модели
Вывод формулы для пересчёта весов
Пример запуска на Python
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Градиентный бустинг | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Бустинг
Сравнение бустинга с другими ансамблями моделей
Алгоритм AdaBoost
Градиентный бустинг
Алгоритм градиентного бустинга
Улучшения градиентного бустинга
Иллюстрация работы
Градиентный бустинг второго порядка
Популярные реализации
Точность градиентного бустинга
Дополнительная литература
Вопросы
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Бустинг
Градиентный бустинг
Содержание этой страницы
Градиентный бустинг


Градиентный бустинг
 (gradient boosting 
[1]
, предложен в 
[2]
) представляет собой приближение бустинга с использованием 
градиента функции потерь
. В отличие от 
AdaBoost
, он работает с произвольной дифференцируемой функцией потерь, а не только с экспоненциальной. В частности это позволяет решать не только задачу классификации, но и регрессии.


В качестве базовых моделей чаще всего используются 
решающие деревья
 небольшой глубины (gradient boosting over decision trees, GBDT).


Когда говорят о бустинге, то чаще всего имеют ввиду именно градиентный бустинг.


Идея метода
​


Если отвлечься от множителя при базовой функции, то в бустинге решается задача подбора оптимальной 

 такой, что





Если вектор прогнозов функции 

 заменить на вектор вещественных чисел 

, то задача переформулируется в виде классической минимизации функции по аргументам:





Используя идеологию 
градиентного спуска
, эту задачу в линейном приближении можно решить, положив





Следовательно, в исходной постановке следует выбирать 

 так, чтобы обеспечить





Реализация
На практике это означает обучение 

 на обучающей выборке:



Алгоритм градиентного бустинга основан на итеративной оценке 

 для 

 и добавлении этих функций к ансамблю 

.




Заметим, что в обучающей выборке для каждой базовой модели 

 вектора признаков будут одинаковыми, а целевые значения - разными, поскольку разными будут ошибки  

, уточняемой на каждой итерации.




Настройка 

 происходит по правилу:







Заставить 

 приближать антиградиент ансамбля можно, используя 
любую
 регрессионную функцию потерь. Квадратичные потери выше - просто наиболее типичный случай.




Тогда шагу градиентного спуска при минимизации 






будет приближённо соответствовать обновление ансамбля:





где шаг обучения (learning rate) 

 выбирается пользователем (гиперпараметр).


Случай функции выигрыша
Если настройка ансамбля производится не 
минимизацией
 функции потерь, а  
максимизацией
 функции выигрыша, то 

 нужно настраивать приближать не антиградиент потерь (градиент 
со знаком минус
), а градиент функции (
со знаком плюс
).


Примеры
​


Случай регресии
​


Рассмотрим задачу регрессии 

 с функцией потерь:





Тогда следующая базовая модель будет настраиваться приближать





Обновление базовой модели пройдёт по правилу





То есть в каждой точке 

 ансамбль будет корректироваться на величину недопрогноза 

.


[IMAGE]


Случай бинарной классификации
​


Для бинарной классификации 

 зададим функцию потерь персептрона:





Тогда следующая базовая модель будет настраиваться приближать








В результате такого обновления ансамбль не изменяется для объектов, которые уже классифицируются корректно (

 и 

 одного знака), и изменится на 

 в сторону 

 на неверно классифицированных объектах.


Это улучшает качество классификации неверно предсказанных объектов (повышает отступ), поскольку конечные прогнозы ансамбль выдаёт по правилу:





Это изменение проиллюстрировано ниже:


[IMAGE]


Как видим, при использовании функции потерь персептрона корректировка на 

 осуществляется только для ошибочно классифицированных объектов, у которых 

 и 

 разных знаков.


Случай многоклассовой классификации
​


Для многоклассовой классификации можно использовать методы 
один-против-одного
, 
один-против-всех
 и 
коды, исправляющие ошибки,
 которые решают многоклассовую классификацию с помощью набора бинарных классификаторов.


Альтернативно можно решать многоклассовую классификацию напрямую. В этом случае 

 будет представлять собой уже 
вектор из рейтингов
 для каждого из 

 классов, а в качестве прогноза будет назначаться класс, обладающий максимальным рейтингом:





В случае минимизации потерь 

:





то есть базовая базовая модель и целевая величина будут представлять собой 

-мерные векторы, сближаемые через 
векторную
 функцию потерь.




Далее мы рассмотрим 
алгоритм бустинга в общем виде
.


С частным случаем многоклассового бустинга при логистической функции потерь можно ознакомиться, например, в 
[3]
.


Литература
​






Wikipedia: gradient boosting.






Friedman J. H. Greedy function approximation: a gradient boosting machine //Annals of statistics. – 2001. – С. 1189-1232.






Мерков А. Б. Распознавание образов: введение в методы статистического обучения. // Москва: Едиториал УРСС. – 2019.




Предыдущая страница
Алгоритм AdaBoost
Следующая страница
Алгоритм градиентного бустинга
Идея метода
Примеры
Случай регресии
Случай бинарной классификации
Случай многоклассовой классификации
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Алгоритм градиентного бустинга | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Бустинг
Сравнение бустинга с другими ансамблями моделей
Алгоритм AdaBoost
Градиентный бустинг
Алгоритм градиентного бустинга
Улучшения градиентного бустинга
Иллюстрация работы
Градиентный бустинг второго порядка
Популярные реализации
Точность градиентного бустинга
Дополнительная литература
Вопросы
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Бустинг
Алгоритм градиентного бустинга
Содержание этой страницы
Алгоритм градиентного бустинга


Базовый алгоритм
​


Разобравшись 
в идее построения каждой следующей базовой модели в градиентном бустинге
, приходим к следующему алгоритму построения итогового ансамбля:


Алгоритм градиентного бустинга
Вход
:




обучающая выборка 

 ;






функция потерь 

 и число базовых моделей 

.








Настраиваем начальное приближение 

 по 

.






Для каждого 

:






вычисляем градиенты: 







настраиваем 

 на выборке 

;






обновляем 

.








Выход
: композиция 

.


Алгоритм с переменным шагом
​


Шаг обучения 

 можно варьировать, подбирая его наилучшее значение на каждой итерации, решая задачу одномерной оптимизации (например, простым перебором по сетке):


Алгоритм градиентного бустинга с адаптацией шага обучения
Вход
:




обучающая выборка 

 ;






функция потерь 

 и число базовых моделей 

.








Настраиваем начальное приближение 

 по 

.






Для каждого 

:






вычисляем градиенты: 







настраиваем 

 на выборке 

;






настраиваем шаг
 







обновляем 









Выход
: композиция 

.


Модификация для решающих деревьев
​


Когда базовыми алгоритмами 

 выступают решающие деревья (что и применяется почти всегда на практике), то алгоритм немного изменяется. Как известно, решающее дерево разбивает пространство признаков на систему непересекающихся прямоугольников 

, соответствующих листьям дерева. Каждому листу 

 (и соответствующему прямоугольнику) назначается константный прогноз 

, как показано на иллюстрации:


[IMAGE]


Прогноз решающего дерева имеет вид:





После настройки решающего дерева на шаге 2.ii, предлагается 
индивидуально
 подобрать прогнозы 

 для каждой соответствующей области признакового пространства, чтобы они лучше всего улучшили качество работы ансамбля:


Алгоритм градиентного бустинга для решающих деревьев
Вход
:




обучающая выборка 

;






функция потерь 

 и число базовых моделей 

.








Настраиваем начальное приближение 

 по 

.






Для каждого 

:






вычисляем градиенты: 

;






настраиваем 
решающее дерево
 

 на выборке 

,

получаем разбиение пространства признаков
 

;






для каждого прямоугольника 

 

 
пересчитываем прогнозы
:









обновляем 

.








Выход
: композиция 

.


Обратим внимание, что в этой схеме 
отсутствует
 подбор коэффициента 

 при базовой модели. Учёт коэффициента мог бы синхронно изменять все прогнозы добавляемого решающего дерева в каждом прямоугольнике. Но необходимости в этом нет, поскольку мы 
уже подобрали индивидуальные прогнозы в каждом прямоугольнике на шаге 2.iii
.


Также с реализацией градиентного бустинга и особенностью реализации для решающих деревьев можно ознакомиться в 
[1]
.


Пример запуска на Python
​


Градиентный бустинг для классификации:


from
 sklearn
.
ensemble 
import
 GradientBoostingClassifier
from
 sklearn
.
metrics 
import
 accuracy_score
from
 sklearn
.
metrics 
import
 brier_score_loss
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_classification_data
(
)
  
# инициализация модели (базовые модели-по умолчанию деревья, но могут быть другие):
model 
=
 GradientBoostingClassifier
(
n_estimators
=
1000
,
  
# число базовых моделей   
                                   learning_rate
=
0.1
,
  
# шаг обучения 
                                   subsample
=
1.0
,
      
# доля случайных объектов для обучения
                                   max_features
=
1.0
)
   
# доля случайных признаков для обучения
model
.
fit
(
X_train
,
 Y_train
)
       
# обучение модели   
Y_hat 
=
 model
.
predict
(
X_test
)
     
# построение прогнозов
print
(
f'Точность прогнозов: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
P_hat 
=
 model
.
predict_proba
(
X_test
)
  
# можно предсказывать вероятности классов
loss 
=
 brier_score_loss
(
Y_test
,
 P_hat
[
:
,
1
]
)
  
# мера Бриера на вер-ти положительного класса
print
(
f'Мера Бриера ошибки прогноза вероятностей: 
{
loss
:
.2f
}
'
)






Градиентный бустинг для регрессии:


from
 sklearn
.
ensemble 
import
 GradientBoostingRegressor
from
 sklearn
.
metrics 
import
 mean_absolute_error
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_regression_data
(
)
  
# инициализация модели (базовые модели-по умолчанию деревья, но могут быть другие):
model 
=
 GradientBoostingRegressor
(
n_estimators
=
1000
,
  
# число базовых моделей   
                                  learning_rate
=
0.1
,
  
# шаг обучения  
                                  subsample
=
1.0
,
      
# доля случайных объектов для обучения
                                  max_features
=
1.0
)
   
# доля случайных признаков для обучения     
model
.
fit
(
X_train
,
 Y_train
)
       
# обучение модели   
Y_hat 
=
 model
.
predict
(
X_test
)
     
# построение прогнозов
print
(
f'Средний модуль ошибки 
(
MAE
)
:
 \
    
{
mean_absolute_error
(
Y_test
,
 Y_hat
)
:
.
2f
}
'
)
       




Больше информации
. 
Полный код
.


Литература
​




Hastie T., Tibshirani R., Friedman J. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. – Springer Science & Business Media, 2009.


Предыдущая страница
Градиентный бустинг
Следующая страница
Улучшения градиентного бустинга
Базовый алгоритм
Алгоритм с переменным шагом
Модификация для решающих деревьев
Пример запуска на Python
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Улучшения градиентного бустинга | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Бустинг
Сравнение бустинга с другими ансамблями моделей
Алгоритм AdaBoost
Градиентный бустинг
Алгоритм градиентного бустинга
Улучшения градиентного бустинга
Иллюстрация работы
Градиентный бустинг второго порядка
Популярные реализации
Точность градиентного бустинга
Дополнительная литература
Вопросы
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Бустинг
Улучшения градиентного бустинга
Содержание этой страницы
Улучшения градиентного бустинга


Есть две популярные техники, призванные улучшить качество итоговой модели градиентного бустинга - сжатие и сэмплирование.


Сжатие
​


В традиционном градиентном бустинге обновление ансамбля происходит добавлением новой базовой модели с коэффициентом (если модель - решающее дерево, то без коэффициента):





Идея 
сжатия
 (shrinkage) основана на том, чтобы добавлять 

 не полностью, а с некоторым малым коэффициентом  

:





Константный шаг
В случае обновления ансамбля с фиксированным шагом

домножать отдельно на 

 смысла нет, так как достаточно просто уменьшить множитель 

.


Чем базовых моделей в ансамбле больше, тем весь ансамбль в среднем получается точнее, поскольку модели отчасти компенсируют ошибки друг друга. Сжатие позволяет 
искусственно увеличить число базовых моделей в ансамбле
, снижая вклад каждой базовой модели в отдельности. Чем гиперпараметр 

 меньше, тем больше шагов 

 потребуется произвести, чтобы дойти до оптимального решения, поскольку двигаться мы будем более малыми шагами. Вместе они связаны следующим соотношением:







Например, если двигаться с уменьшенным шагом в десять раз, то потребуется в 10 раз больше итераций.




Такая модификация улучшает качество прогнозов за счёт того, что алгоритм точнее сойдётся к оптимуму. Обычно выбирают 

.


Цена повышения точности - 
увеличение вычислительных ресурсов
, поскольку придётся дольше обучать ансамбль, а также производить больше вычислений, чтобы строить каждый прогноз увеличенным числом базовых моделей.


Рассмотрим задачу классификации. Пример зависимости точности градиентного бустинга от числа базовых моделей для различных значений 

 приведён ниже:


[IMAGE]


Как видим, уменьшение 

 приводит к более высокому числу базовых моделей в оптимальной конфигурации. Зато точность ансамбля повышается!


Ускоренный поиск лучшей конфигурации
Чтобы найти наилучшую конфигурацию бустинга быстрее, поступают следующим образом:




С большим 

 по сетке значений настраивают параметры градиентного бустинга. Это включает оптимальное число базовых моделей 

, глубину решающих деревьев, критерий неопределённости при их настройке и прочие гиперпараметры.






Уменьшают 

 в 

 раз:









Увеличивают оптимальное число базовых моделей в 

 раз:







В итоге получаем готовую модель, настройка гиперпараметров которой производилась быстрее по её вычислительно эффективной аппроксимации!


Сэмплирование
​


В обычной реализации бустинга каждая базовая модель 

 настраивается, используя все объекты и признаки обучающей выборки.


Идея 
сэмплирования
 (subsampling) заключается в том, чтобы настраивать каждую базовую модель, используя случайную подвыборку из объектов и признаков, сэмплируемых 
без возвращения
. В результате:






настройка бустинга производится быстрее;






базовые модели становятся более разнообразными, что повышает итоговую точность ансамбля исходя из 
разложения неоднозначности
.








Поскольку для каждой базовой модели подмножество используемых объектов и признаков 
своё
, а ансамбль состоит из большого числа таких моделей, то итоговая модель будет зависеть почти от всех объектов и признаков.




Настройка базовых моделей бустинга по подмножеству объектов также позволяет использовать 
out-of-bag оценку
 для оценки качества ансамбля, не прибегая к дополнительной валидационной выборке.


Гиперпараметры сэмплирования
При использовании сэмплирования возникают гиперпараметры:




доля сэмплируемых объектов;






доля сэмплируемых признаков.




Для оптимальной точности метода их необходимо настроить, используя 
отдельную валидационную выборку или кросс-валидацию
.


Рассмотрим задачу регрессии. Пример зависимости средней ошибки 
MAE
 на тестовой выборке от доли использованных объектов приведён ниже:


[IMAGE]


Далее приведён пример зависимости от числа сэмплируемых признаков:


[IMAGE]


В приведённых примерах настройка базовых моделей не на всех, а на случайной части объектов и признаков привела к улучшению точности ансамбля.


Выбор гиперпараметров
В отличие от 

, которое чем меньше, тем лучше при достаточном числе базовых моделей, зависимость от доли используемых объектов и признаков сложна и неоднозначна и требует тщательного подбора по 
валидационной выборке или кросс-валидации
.


Идея использования не всех объектов, а случайной подвыборки при настройке базовых моделей была предложена в 
[1]
. Механизмы shrinkage и subsampling также описаны в 
[2]
.


Поиск разбиений по сетке
​


При использовании решающих деревьев в качестве базовых моделей бустинга вместо того, чтобы перебирать все допустимые пороги, можно перебирать пороги только по грубой сетке значений. Для этого рекомендуется использовать 10,20,30, ... 90% квантильные значения признака для объектов, 
попадающих в соответствующий узел дерева
. Можно использовать и другую сетку квантизации. Это ускоряет выбор правил при настройке решающих деревьев, снижая точность подгонки под данные. Но высокая точность в бустинге нам и не нужна, поскольку неточности в настройке текущей базовой модели исправят последующие модели ансамбля.


Подобная квантизация порогов используется, например, в алгоритме xgBoost 
[3]
.


Литература
​






Friedman J. H. Stochastic gradient boosting //Computational statistics & data analysis. – 2002. – Т. 38. – №. 4. – С. 367-378.






Hastie T., Tibshirani R., Friedman J. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. – Springer Science & Business Media, 2009.






Chen T., Guestrin C. Xgboost: A scalable tree boosting system //Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. – 2016. – С. 785-794.




Предыдущая страница
Алгоритм градиентного бустинга
Следующая страница
Иллюстрация работы
Сжатие
Сэмплирование
Поиск разбиений по сетке
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Иллюстрация работы градиентного бустинга по шагам | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Бустинг
Сравнение бустинга с другими ансамблями моделей
Алгоритм AdaBoost
Градиентный бустинг
Алгоритм градиентного бустинга
Улучшения градиентного бустинга
Иллюстрация работы
Градиентный бустинг второго порядка
Популярные реализации
Точность градиентного бустинга
Дополнительная литература
Вопросы
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Бустинг
Иллюстрация работы
Содержание этой страницы
Иллюстрация работы градиентного бустинга по шагам


Рассмотрим визуализацию работы градиентного бустинга:








где







;







 - решающие деревья глубины 3;







.






Для простоты визуализации рассмотрим двумерное признаковое пространство





Будем строить целевую зависимость 

 и текущее приближение 

 на левом графике, а ошибку 

 и следующую базовую модель 

 - на правом.





[IMAGE]





[IMAGE]





[IMAGE]





[IMAGE]





[IMAGE]





[IMAGE]





[IMAGE]





[IMAGE]





[IMAGE]





[IMAGE]





[IMAGE]


Как видим, с ростом 

 отклонение прогноза от истинного значения уменьшается и становится более шумным. Скачки в ошибке возникают на местах разбиения признакового пространства узлами деревьев.


Результаты работы были получены, используя интерактивный визуализатор Алексея Рогожникова 
[1]
, в котором можно отобразить работу бустинга и при других пользовательских настройках.


Литература
​




Brilliantly wrong: Gradient Boosting explained.


Предыдущая страница
Улучшения градиентного бустинга
Следующая страница
Градиентный бустинг второго порядка
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Градиентный бустинг второго порядка | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Бустинг
Сравнение бустинга с другими ансамблями моделей
Алгоритм AdaBoost
Градиентный бустинг
Алгоритм градиентного бустинга
Улучшения градиентного бустинга
Иллюстрация работы
Градиентный бустинг второго порядка
Популярные реализации
Точность градиентного бустинга
Дополнительная литература
Вопросы
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Бустинг
Градиентный бустинг второго порядка
Содержание этой страницы
Градиентный бустинг второго порядка


Мы вывели 
алгоритм градиентного бустинга
 из 
линейного приближения
 функции потерь. Но можно было бы применить ту же самую идею, используя более точное квадратичное приближение!


Рассмотрим для объекта 

 функцию потерь 

 и введём обозначения для её первой и второй производной по значению прогноза:





Тогда из разложения Тейлора второго порядка 
[1]
 получим следующую квадратичную аппроксимацию для функции потерь:





где 

 обозначает некоторое выражение, не зависящее от базовой модели 

, по которой нам необходимо производить минимизацию.


Отсюда следует, что для минимизации функции потерь для объекта 

 базовая модель 

 должна приближать 

 с 
весом
 

. То есть должна настраиваться на следующей обучающей выборке:





с соответствующими весами 

, которые будут неотрицательны в окрестности локального минимума.


На приближении второго порядка основан алгоритм LogitBoost, подробно описанный в 
[2]
, а также алгоритм xgBoost 
[3]
.


Литература
​






Викиконспекты ИТМО: формула Тейлора для произвольной функции.






Мерков А. Б. Распознавание образов: введение в методы статистического обучения. // Москва: Едиториал УРСС. – 2019.






Chen T., Guestrin C. Xgboost: A scalable tree boosting system //Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. – 2016. – С. 785-794.




Предыдущая страница
Иллюстрация работы
Следующая страница
Популярные реализации
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Популярные реализации | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Бустинг
Сравнение бустинга с другими ансамблями моделей
Алгоритм AdaBoost
Градиентный бустинг
Алгоритм градиентного бустинга
Улучшения градиентного бустинга
Иллюстрация работы
Градиентный бустинг второго порядка
Популярные реализации
Точность градиентного бустинга
Дополнительная литература
Вопросы
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Бустинг
Популярные реализации
Содержание этой страницы
Популярные реализации


На языке python алгоритм градиентного бустинга над решающими деревьями реализован в библиотеке 
sklearn
 классами 
GradientBoostingClassifier
 и 
GradientBoostingRegressor
 для решения задач классификации и регрессии соответственно.


Там также реализованы ускоренные версии алгоритма 
HistGradientBoostingClassifier
 и 
HistGradientBoostingRegressor
, производящие настройку правил во внутренних узлах решающих деревьев за счёт перебора не по всем допустимым порогам, а по более грубой сетке значений. Также эти реализации допускают автоматическую обработку пропущенных значений  признаков, отправляя все объекты с пропущенным признаком либо в левое, либо в правое поддерево, в зависимости от того, что приводит к большему снижению функции неопределённости.


Тремя самыми продвинутыми реализациями бустинга являются:


Название
Документация
Разработчики
xgBoost
сайт
XGBoost Contributors
LightGBM
сайт
Microsoft
CatBoost
сайт
Яндекс


Все реализации допускают параллелизацию настройки базовых моделей, которые поддерживаются как на процессоре, так и на видеокарте.


Реализации используют расширенный набор гиперпараметров, влияющих на точность ансамбля. При настройке правил в узлах деревьев допускается оптимизация не по всем порогам, а по более грубой сетке значений для ускорения обучения модели на больших данных. При этом






xgBoost 
[1]
 использует 
оптимизацию второго порядка
 за счёт квадратичной аппроксимации функции потерь. Добавлены возможности регуляризации каждого решающего дерева.






LightGBM 
[2]
 настраивает каждую базовую модель не на всех данных, а на подмножестве объектов, сильнее всего влияющих на прогнозы ансамбля, что существенно ускоряет настройку модели. Также метод использует специальную технику для эффективной работы с разреженными данными (содержащими много нулевых значений).






CatBoost 
[3]
 строится не над традиционными, а над небрежными решающими деревьями (oblivious decision trees), в которых на каждом уровне дерева во всех узлах проверяется условие над одним и тем же признаком. Это позволяет настраивать деревья быстрее без потери качества всего ансамбля. Также CatBoost использует специальную обработку категориальных признаков.






Литература
​




Chen T., Guestrin C. Xgboost: A scalable tree boosting system //Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. – 2016. – С. 785-794.


Ke G. et al. Lightgbm: A highly efficient gradient boosting decision tree //Advances in neural information processing systems. – 2017. – Т. 30.


Prokhorenkova L. et al. CatBoost: unbiased boosting with categorical features //Advances in neural information processing systems. – 2018. – Т. 31.


Предыдущая страница
Градиентный бустинг второго порядка
Следующая страница
Точность градиентного бустинга
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Точность градиентного бустинга | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Бустинг
Сравнение бустинга с другими ансамблями моделей
Алгоритм AdaBoost
Градиентный бустинг
Алгоритм градиентного бустинга
Улучшения градиентного бустинга
Иллюстрация работы
Градиентный бустинг второго порядка
Популярные реализации
Точность градиентного бустинга
Дополнительная литература
Вопросы
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Бустинг
Точность градиентного бустинга
Содержание этой страницы
Точность градиентного бустинга


Градиентный бустинг над решающими деревьями - 
один из самых точных алгоритмов классического машинного обучения
 для большинства задач, если не брать в расчёт нейросетевые методы. Но даже по сравнению с нейросетями градиентный бустинг показывает сопоставимое, а часто даже более высокое качество на табличных данных, в которых признаки представлены в виде небольшого вектора признаков. Этот алгоритм особенно хорошо работает, когда признаки имеют разные типы - вещественные, бинарные, категориальные и порядковые, поскольку, в отличие от нейросетей, решающие деревья особенно хорошо справляются с разнородными типами данных.




Делаются попытки догнать качество бустинга на табличных данных с помощью нейросетей, см. Tabular Deep Learning, например, 
[1]
 и 
[2]
.




Точность градиентного бустинга не снижает важности других методов. Для каждого прогнозирующего алгоритма существует ситуация, когда именно он будет оказываться лучшим из всех возможных (например, генерируя сами данные согласно предложенному алгоритму).




Это явно иллюстрируется в no free lunch теоремах 
[3]
, 
[4]
, доказывающих невозможность доминирования одного алгоритма оптимизации над всеми остальными в общем случае.




Изученные методы могут улучшать точность прогнозов, работая в 
ансамбле
 с градиентным бустингом.


Также для всех изученных алгоритмов существуют ситуации, когда именно они будут оказываться наилучшими, например:






Когда классов много, а представителей каждого класса мало, то метод K ближайших соседей часто оказывается лучшим решением, поскольку начинает распознавать класс всего по нескольким примерам.






Когда признаков много по сравнению с числом наблюдений, то линейная модель с регуляризацией может показывать наилучший результат как модель, учитывающая одновременное влияние сразу всех признаков. Поскольку влияние моделируется самой простой (линейной) зависимостью, эта модель наименее склонна переобучаться на малых выборках.






Также базовые модели классического машинного обучения, будучи простыми в настройке, часто используются в качестве референса (бейзлайна) относительно которого уже улучшается качество более продвинутыми моделями, такими как градиентный бустинг и нейросети. Если же сложные модели дают минимальный прирост в точности, но работают существенно медленнее, то из соображений эффективности целесообразен возврат к базовым моделям.


Литература
​






Arik S. Ö., Pfister T. Tabnet: Attentive interpretable tabular learning //Proceedings of the AAAI conference on artificial intelligence. – 2021. – Т. 35. – №. 8. – С. 6679-6687.






Gorishniy Y., Kotelnikov A., Babenko A. Tabm: Advancing tabular deep learning with parameter-efficient ensembling //arXiv preprint arXiv:2410.24210. – 2024.






Wikipedia: no free lunch theorem.






Wolpert D. H., Macready W. G. No free lunch theorems for optimization //IEEE transactions on evolutionary computation. – 1997. – Т. 1. – №. 1. – С. 67-82.




Предыдущая страница
Популярные реализации
Следующая страница
Дополнительная литература
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Дополнительная литература | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Бустинг
Сравнение бустинга с другими ансамблями моделей
Алгоритм AdaBoost
Градиентный бустинг
Алгоритм градиентного бустинга
Улучшения градиентного бустинга
Иллюстрация работы
Градиентный бустинг второго порядка
Популярные реализации
Точность градиентного бустинга
Дополнительная литература
Вопросы
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Бустинг
Дополнительная литература
Содержание этой страницы
Дополнительная литература


Алгоритм бустинга подробно изложен в 
[1]
. Также ознакомиться с методом можно в 
[2]
.


В 
[3]
 описана реализация и примеры запуска классического бустинга в библиотеке sklearn. Примеры запуска и основные параметры продвинутых реализаций бустинга XGBoost и CatBoost со ссылками для более полного погружения есть в 
[4]
 и 
[5]
.


Литература
​




Hastie T., Tibshirani R., Friedman J. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. – Springer Science & Business Media, 2009.


Учебник ШАД: градиентный бустинг.


Документация sklearn: ensembles, gradient boosting, random forests, bagging, voting, stacking.


Викиконспекты ИТМО: XGBoost.


Викиконспекты ИТМО: CatBoost.


Предыдущая страница
Точность градиентного бустинга
Следующая страница
Вопросы
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Вопросы для самопроверки | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Бустинг
Сравнение бустинга с другими ансамблями моделей
Алгоритм AdaBoost
Градиентный бустинг
Алгоритм градиентного бустинга
Улучшения градиентного бустинга
Иллюстрация работы
Градиентный бустинг второго порядка
Популярные реализации
Точность градиентного бустинга
Дополнительная литература
Вопросы
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Бустинг
Вопросы
Вопросы для самопроверки




Может ли качество бустинга устойчиво снижаться при выборе слишком большого числа базовых моделей?


Имеет ли смысл в качестве базовых моделей бустинга использовать только модели линейной регрессии? Почему?


В качестве базовых моделей бустинга следует использовать простые или сложные модели (в терминах их гибкости подстройки под данные)? Почему?


Насколько устойчивым к наличию выбросов будет получаться решение, найденное алгоритмом AdaBoost?


Следует выбирать модели градиентного бустинга так, чтобы их прогнозы оказывались как можно более похожими или непохожими? Какой приём позволяет этого добиться?


Объясните, почему приём shrinkage приводит к повышению точности прогнозов? Какой у него есть недостаток?


На какую обучающую выборку будет настраиваться базовая модель градиентного бустинга при решении задачи классификации с логистическими потерями?


Предыдущая страница
Дополнительная литература
Следующая страница
Интерпретация простых моделей
© 2023-25 
Виктор Китов.
 
Новости проекта.









Интерпретируемое машинное обучение | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретируемое машинное обучение
Интерпретация метрических методов
Метод наивного Байеса
Интерпретация линейной регрессии
Интерпретация логистической регрессии
Интерпретация решающего дерева
Вопросы
Интерпретация сложных моделей
Заключение
Интерпретация простых моделей
Интерпретируемое машинное обучение
Содержание этой страницы
Интерпретируемое машинное обучение


Интерпретируемость моделей и её приложения
​


Прогностическая модель называется 
интерпретируемой
 (interpretable) или 
объяснимой
 (explainable), если 
человек может проинтерпретировать её решения
.




Как правило, более сложные модели, учитывающие большее число факторов нелинейным образом, являются менее интерпретируемыми, но обеспечивают более высокую точность, поэтому существует противоречие между объяснимостью и качеством прогнозов.




Преимущества, которые даёт интерпретируемость:






В приложениях, где цена ошибки высока (например, в задаче медицинской диагностики, определяющей, нужно ли пациенту делать операцию), важна не только точность, но и способность модели обосновать своё решение (для врача). Поэтому в таких приложениях лучше использовать несколько интерпретируемых моделей, а не одну сложную. Модель, способная объяснить свои прогнозы, вызывает больше доверия и проще внедряется на практике.






Интерпретируемость позволяет оценить адекватность принятого решения: было ли оно принято, основываясь на сильных и значимых факторах (causal factors), или модель переобучилась и приняла пусть даже верное решение, но отталкиваясь от ложных взаимосвязей (false correlations).




Например, в задаче классификации кошек и собак на изображении можно проанализировать факторы, которые повлияли на тот или иной прогноз. Это могут быть характеристические факторы, такие как размер и расположение (кошки могут забираться на деревья, а собаки - нет). Или это могут быть ошибочные факторы (например, наличие снега на заднем плане), которые в силу ограниченности обучающей выборки присутствовали в комбинации только с одним из классов, но не с другим (например, со снегом попадались только фото с собаками).




Оценка адекватности модели позволяет производить отладку (debugging) модели, делая её прогнозы более логичными и корректными.






В процессе интерпретации прогнозов модели иногда можно отследить, что модель использует какие-либо запрещённые факторы (такие как национальность и цвет кожи в задаче кредитного скоринга), что может делать процесс принятия решений несправедливым к тем или иным социальным группам. Либо модель может опираться на какие-то приватные признаки о пользователях, использование которых не разрешено законом.






Виды интерпретируемости
​


Методы интерпретации делятся на






привязанные к конкретной модели
, такой как решающее дерево, линейная регрессия и т.д. (model based);






не зависящие от модели
 (model agnostic).






Также различают 
глобальную
 и 
локальную
 интерпретируемость, как схематично показано ниже 
[1]
:


[IMAGE]


Модель является 
глобально интерпретируемой
, если человек понимает весь  процесс принятия решений целиком 
для любых объектов
.


Локальная интерпретируемость
 означает, что человек может понять, почему 
для конкретного объекта
 было принято то или иное решение.


Подходом к интерпретации сложных многоуровневых моделей может быть разделение процесса принятия решения на отдельные интерпретируемые блоки.




Пример: для 
многослойной нейросети
 можно пытаться интерпретировать работу отдельных нейронов. Систему автоматического управления транспортным средством можно декомпозировать на отдельные блоки, такие как детекция пешеходов и транспортных средств на дороге, определение расстояния до них, распознавание дорожных знаков, прогноз расположения транспортного средства в следующий момент времени и т.д.




Интерпретируемые и неинтерпретируемые модели
​


Модели в машинном обучении по своей конструкции бывают простыми и сложными. 
Простые модели
 (white-box models), как правило, не могут обеспечить наилучшую точность, зато обладают глобальной интерпретируемостью. Примерами таких моделей являются:






метрические методы
 (при использовании небольшого числа локальных объектов);






линейные модели 
регрессии
 и 
классификации
 (от небольшого числа признаков);






решающие деревья
 небольшой глубины;






метод наивного Байеса
 (naive Bayes).






При решении ответственных задач с высокой ценой ошибки (например, при предсказании, нужно ли делать пациенту операцию или нет) именно таким моделям отдаётся предпочтение, в силу их интерпретируемости.


Сложные модели
 (black-box models) способны моделировать более широкий класс зависимостей, поэтому, при достаточном объёме обучающих данных, обеспечивают более точные прогнозы. Но из-за сложности внутренней логики их непосредственная интерпретация затруднена. Однако существуют опосредованные способы анализа прогнозов и для сложных моделей.


Далее мы изучим интерпретацию простых моделей, а интерпретацией сложных займёмся в 
следующем разделе книги
.




О важности интерпретируемости моделей машинного обучения, а также о классификации подходов к интерпретируемости коротко можно прочитать в блог-посте 
[2]
. Также интерпретирумости моделей целиком посвящён отдельный учебник 
[3]
.


Литература
​






comet.com: model interpretability part 3: local model agnostic methods.






Heartbeat blog: model interpretability part 1: the importance and approaches.






Molnar C. Interpretable machine learning. – Lulu. com, 2020.




Предыдущая страница
Интерпретация простых моделей
Следующая страница
Интерпретация метрических методов
Интерпретируемость моделей и её приложения
Виды интерпретируемости
Интерпретируемые и неинтерпретируемые модели
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Интерпретация метрических методов | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретируемое машинное обучение
Интерпретация метрических методов
Метод наивного Байеса
Интерпретация линейной регрессии
Интерпретация логистической регрессии
Интерпретация решающего дерева
Вопросы
Интерпретация сложных моделей
Заключение
Интерпретация простых моделей
Интерпретация метрических методов
Содержание этой страницы
Интерпретация метрических методов


Метод K ближайших соседей
​


В 
методе K ближайших соседей
 для нового объекта 

 ищется 

 ближайших объектов в обучающей выборке, а в качестве прогноза выдаётся среднее значение откликов для этих объектов.


Этот метод 
является интерпретируемым
, поскольку для обоснования того или иного прогноза достаточно просто посмотреть на отклики ближайших объектов.




Например, при классификации можно ли пациенту с заданным диагнозом и другими характеристиками проводить операцию или нет, метод может обосновать своё решение. К примеру, операцию пациенту проводить можно, поскольку этот пациент очень похож на Иванова, Петрова и Сидорова из обучающей выборки, которым операцию провели, и они благополучно пошли на поправку.




Метод ближайших центроидов
​


Метод ближайших центроидов
 идейно похож на метод ближайших соседей, но применим только к задаче классификации. Вначале для каждого класса вычисляется характерный представитель этого класса (центроид) простым усреднением по объектам заданного класса. Затем для нового объекта 

 сопоставляется тот класс, расстояние до центроида которого меньше всего.


Идея построения прогноза легка для восприятия. Сложности с интерпретацией могут возникнуть лишь в том, что при усреднении объектов может возникнуть нереалистичный объект (например, если объект - пациент больницы, то можем усреднить людей разного пола, возраста и с разными несочетаемыми симптомами). В этом случае центроиды можно заменить на ближайшие к ним реальные объекты обучающей выборки (примеры реальных людей), а если множество объектов одного класса имеет невыпуклую форму, то можно доработать метод таким образом, чтобы каждый класс представлялся не одним, а сразу несколькими репрезентативными объектами.
Предыдущая страница
Интерпретируемое машинное обучение
Следующая страница
Метод наивного Байеса
Метод K ближайших соседей
Метод ближайших центроидов
© 2023-25 
Виктор Китов.
 
Новости проекта.









Метод наивного Байеса | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретируемое машинное обучение
Интерпретация метрических методов
Метод наивного Байеса
Интерпретация линейной регрессии
Интерпретация логистической регрессии
Интерпретация решающего дерева
Вопросы
Интерпретация сложных моделей
Заключение
Интерпретация простых моделей
Метод наивного Байеса
Содержание этой страницы
Метод наивного Байеса


Генеративные и дискриминативные модели
​


Прогностические модели машинного обучения бывают генеративные и дискриминативные.


Дискриминативные модели
 (discriminative models) моделируют только 
условное распределение отклика при условии вектора признаков
 

.


Генеративные модели
 (generative models) моделируют 
совместное распределение признаков и откликов
 

. Из генеративной модели можно легко получить дискриминативную по правилу условных вероятностей:





где 

 означает пропорционально с точностью до константы, которой выступает деление на 

, не зависящей от класса, а потому не влияющей на прогноз его метки.


Идея метода наивного Байеса
​


Метод наивного Байеса
 (naive Bayes) представляет собой генеративную модель классификации, в которой дополнительно используется 
предположение наивного Байеса
 (naive Bayes assumption), состоящее в том, что 
признаки предполагаются распределёнными независимо при условии отклика
:







Например, в задаче классификации писем на полезные и спам по встречаемости разных слов в письме это предположение означает, что 
при условии класса письма
 (полезное или спам) встречаемости слов независимы друг от друга.




Предположение наивного Байеса на практике не выполняется, зато оно позволяет существенно упростить оценку многомерного распределения 

, сведя его к оценке набора одномерных распределений! В результате снижается дисперсия оценки сложной модели за счёт её аппроксимации более простой моделью, имеющей более высокое смещение в терминах 
разложения на смещение и разброс
.


Условная и безусловная независимость
Условная независимость 
не эквивалентна
 безусловной независимости, записываемой как:



Например, в задаче классификации писем на полезные и спам безусловная независимость означает, что P("скидка" и "купи") = P("скидка") × P("купи"). Однако эти два слова однозначно зависимы: при появлении слова "купи" с большой вероятностью встретится и слово "скидка"!


Предположение же условной независимости признаёт, что вероятности слов могут синхронно меняться с классом письма (спам или полезное), однако 
при условии выбранного класса
 присутствие одного из слов уже не влияет на вероятность встречи другого.




Сделав предположение наивного Байеса, получим итоговый вид 
дискриминантных функций классификатора
:





Прогноз осуществляется назначением класса, обладающего максимальным значением дискриминантной функции.


Интерпретация
​


Если общее число признаков 

 невелико, то метод наивного Байеса интерпретируем, поскольку вклад каждого признака вносится мультипликативно, и для аномально высокой и низкой вероятности можно отследить, из-за каких признаков и соответствующих слагаемых 

 мы получили именно такой прогноз. Отсортировав признаки по этой величине, можно выделить признаки, сильнее всего сдвигающие прогноз в пользу принятия или отказа от заданного класса.
Предыдущая страница
Интерпретация метрических методов
Следующая страница
Интерпретация линейной регрессии
Генеративные и дискриминативные модели
Идея метода наивного Байеса
Интерпретация
© 2023-25 
Виктор Китов.
 
Новости проекта.









Интерпретация линейной регрессии | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретируемое машинное обучение
Интерпретация метрических методов
Метод наивного Байеса
Интерпретация линейной регрессии
Интерпретация логистической регрессии
Интерпретация решающего дерева
Вопросы
Интерпретация сложных моделей
Заключение
Интерпретация простых моделей
Интерпретация линейной регрессии
Содержание этой страницы
Интерпретация линейной регрессии


Предположения метода
​


Линейная регрессия
 строит прогноз по формуле:





Модель использует достаточно сильные предположения о данных:






каждый признак 

 влияет на отклик линейно со своим фиксированным весом 

;






характер этого влияния не зависит от значений остальных признаков.






На практике эти предположения, скорее всего, не выполнены, зато настроенная модель проста и легко поддаётся интерпретации.


Интерпретация весов
​


Веса линейной регрессии можно интерпретировать следующим образом:






Знак веса 

 определяет 
направленность влияния
 

-го признака на отклик. Признак с положительным весом положительно влияет на отклик, а с отрицательным - отрицательно.






Величина веса 

 определяет 
силу влияния
: увеличение 

 на единицу приводит к увеличению 

 на 

. В случае, если 

 - бинарный признак (присутствие определённой характеристики), то 

 показывает, насколько увеличился бы прогноз, если бы признак был активен.




Например, если прогнозируем, за какое время спортсмен пробежит марафон, а 

, то 

 покажет, насколько изменится время забега при наличии травмы у спортсмена. Если 

 является категориальным признаком (например, у какого тренера занимался спортсмен) и кодируется 
one-hot кодированием
, то полезно одну из категорий назначить референсной и закодировать вектором из нулей [0,0,...,0] (например, категорию, что спортсмен учился без тренера). Тогда вес при каждом бинарном признаке one-hot кодирования показывает вклад методики обучения соответствующего тренера в результат забега.








Модуль веса при признаке 

 оценивает степень влияния признака на прогноз. Однако перед применением этой методики все признаки необходимо привести к единой шкале (
нормализовать
).




Иначе уменьшение признака в K раз и перенастройка модели приведут к увеличению веса при нём в K раз, но это не будет означать, что признак стал в K раз более важным!








В статистике существует 
асимптотическая оценка стандартного отклонения
 

 для оценки веса 

. Это позволяет визуализировать для каждого признака не только 

, но и его стандартное отклонение.




Если интервал 

 покрывает ноль, то можно говорить о статистически незначимом влиянии 

-го признака на отклик.




Для проверки значимости влияния признака этого же можно использовать и t-тест Стьюдента 
[1]
, основанный на t-статистике, равной 

. Можно на графике откладывать 

 и соответствующий 95% интервал для этого теста, как показано на рисунке ниже 
[2]
 для задачи BikeSharing 
[3]
:


[IMAGE]


Если интервал на графике покрывает ноль, то влияние признака на целевое значение статистически незначимо, иначе влияние считается значимым.




Значимость влияния признака на отклик важна в таких задачах, как определение оптимального лечения заболевания. Если признак представляет собой объём выпитого лекарства, а выяснится, что влияние статистически незначимое, то нужно подбирать другие методы лечения!








Анализ аддитивных эффектов
​


Величина 

 характеризует 
аддитивный эффект
, который i-й признак оказывает на прогноз для вещественного и бинарного признака. Перед использованием 
необходимо центрировать каждый признак
, вычтя из него его среднее по всей выборке.


Визуализировать распределение аддитивных эффектов удобно, используя 
ящики с усами
 (boxplots 
[4]
).


Построение ящика с усами




Краями прямоугольника ("ящика") выступают 25% и 75% 
персентили
 

 и 

.






Черта внутри прямоугольника соответствует 50% персентили (
медиане
).






"Усы" строятся слева и справа от "ящика" строятся как линия, покрывающая интервал 

, при этом границы интервала должны лежать на ближайших реальных наблюдениях в данных, поэтому могут выглядеть несимметрично относительно "ящика".






Наблюдения, выпадающие за границы интервала "усов" визуализируются отдельными точками.






"Ящик" и "усы" могут строиться по другим правилам, если об этом явно говорится в тексте.




Рассмотрим визуализацию распределения аддитивных эффектов для задачи BikeSharing 
[3]
, в которой оценивается число сданных напрокат велосипедов в разные дни. Для каждого дня известны его дата, день недели, погода, температура и другие параметры.


На этом же графике можно отложить частные аддитивные эффекты для отдельного прогноза (выделено красным), как показано на рисунке ниже 
[2]
:


[IMAGE]


По графику видно, что в целом на аренду велосипедов сильнее всего в плюс влияло время с начала наблюдений (days_since_2011), так как популярность сервиса росла со временем, а также температура дня (temp). А сильнее всего в минус влияла влажность воздуха (hum).


Для аномально низкого прогноза в интересующий день аддитивные эффекты обозначены красными крестиками. Из графика видно, что малый прогноз для выбранного наблюдения основывается на малой температуре, а также на том, что рассматривается аренда в начале наблюдений, когда аренда велосипедов еще не была так популярна.


Снижение числа признаков
​


Интерпретация даже такой простой модели, как линейная регрессия, может будет затруднена, если число признаков велико, как происходит, например, при работе с текстовыми данными. В этом случае мы можем понять, как 
каждый отдельно взятый признак влияет на прогноз
, но 
не можем мысленно предсказать прогноз
 из-за одновременного влияния большого числа других признаков.


Для упрощения интерпретации можно настраивать линейную регрессию с сильной 
L1-регуляризацией
, которая способна отбирать в модель только те признаки, которые сильнее всего влияют на отклик.


Варьируя силу регуляризации (множитель при регуляризаторе), можно заставить модель использовать требуемое небольшое число признаков.




Альтернативно можно использовать 
OMP-регрессию
, отбирающей самые значимые признаки либо использовать другие методы отбора признаков.




Литература
​




Wikipedia: Student's t-test.


Molnar C. Interpretable machine learning. – Lulu. com, 2020: linear regression.


UC Irvine Machine Learning Repository: Bike Sharing dataset.


Wikipedia: box plot.


Предыдущая страница
Метод наивного Байеса
Следующая страница
Интерпретация логистической регрессии
Предположения метода
Интерпретация весов
Анализ аддитивных эффектов
Снижение числа признаков
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Интерпретация логистической регрессии | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретируемое машинное обучение
Интерпретация метрических методов
Метод наивного Байеса
Интерпретация линейной регрессии
Интерпретация логистической регрессии
Интерпретация решающего дерева
Вопросы
Интерпретация сложных моделей
Заключение
Интерпретация простых моделей
Интерпретация логистической регрессии
Интерпретация логистической регрессии


Рассмотрим модель 
логистической регрессии
 для решения задачи бинарной классификации, когда 

. В модели предполагается, что





Здесь так же, как и для линейной регрессии, по знаку коэффициента можно судить о направлении влияния признака на прогноз:






признак с положительным коэффициентом увеличивает вероятность положительного класса,






признак с отрицательным коэффициентом - уменьшает.






Величину коэффициента можно проинтерпретировать следующим образом:





Последняя величина (отношение вероятностей классов) называется 
odds ratio
, и увеличение i-го признака на 1 приводит к увеличению её значения в 

 раз.
Предыдущая страница
Интерпретация линейной регрессии
Следующая страница
Интерпретация решающего дерева
© 2023-25 
Виктор Китов.
 
Новости проекта.









Интерпретация решающего дерева | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретируемое машинное обучение
Интерпретация метрических методов
Метод наивного Байеса
Интерпретация линейной регрессии
Интерпретация логистической регрессии
Интерпретация решающего дерева
Вопросы
Интерпретация сложных моделей
Заключение
Интерпретация простых моделей
Интерпретация решающего дерева
Содержание этой страницы
Интерпретация решающего дерева


Решающее дерево является интерпретируемым алгоритмом машинного обучения. Интерпретация возможна:






визуализацией решающего дерева;






оценкой степени влияния каждого признака на прогнозы в среднем по выборке;






оценкой степени влияния каждого признака на прогноз интересующего объекта.






Ниже мы рассмотрим каждый из подходов детально.


Визуализация деревьев
​


Решающее дерево небольшой глубины можно визуализировать и анализировать напрямую. В этом смысле это метод, обладающий 
глобальной интерпретируемостью
.


Ниже приведён простой пример решающего дерева для задачи кредитного скоринга в банке, работу которого может понять даже не-специалист:


[IMAGE]


Глобальная важность признаков
​


Можно оценивать значимость каждого признака для прогнозов решающего дерева в целом по выборке, используя ранее уже изученное 
среднее изменение неопределённости
 (mean decrease in impurity, MDI).


Рассмотрим задачу wine 
[1]
, в которой по характеристикам вина требуется предсказать его класс. Значимости каждого признака приведены ниже 
[2]
:


[IMAGE]


Из графика сразу видно, что уровень пролина оказывается самым важным признаком.


Эту же методику можно применять для ансамбля над решающими деревьями (бэггинг, случайный лес, бустинг и др.) - нужно лишь усреднить важности признаков каждого дерева с теми коэффициентами, с которыми оно учитываются в ансамбле.




Поскольку ансамбли дают более точные прогнозы, расчёт важности по ансамблю деревьев даст более надёжную оценку влияния признаков на отклик!




Первичный анализ данных
Анализ самых значимых признаков по ансамблю решающих деревьев - важный этап 
первичного анализа данных
, который стоит применять, даже если вы не собираетесь впоследствии использовать сами решающие деревья!


Вклад признака в отдельный прогноз
​


Нас может интересовать вклад каждого признака не для всех объектов выборки, а для одного интересующего объекта 

. Рассмотрим, как это можно рассчитать.


Как известно в решающих деревьях прогноз приписывается каждому листу дерева 
простым усреднением откликов объектов, попавших в лист
. В случае классификации усредняются one-hot закодированные метки классов, что на выходе даёт вектор предсказанных вероятностей классов. Но аналогично можно сопоставить прогноз и каждому промежуточному узлу, усредняя отклики объектов, прошедших через соответствующий узел.


Введём обозначения:







 - узел дерева,







 - соответствующий родительский узел,







 - корень дерева,







 - путь от корня до листа, по которому объект 

 спустился вниз по дереву.






Посчитаем для объекта 

 прогноз 

 в каждом промежуточном узле дерева 

 вдоль пути 

. Итоговый прогноз можно декомпозировать по вкладу в него каждого узла:





Но нам нужен не вклад каждого узла, а 
вклад каждого признака
 в прогноз для интересующего объекта. Для этого для каждого признака 

 найдём множество тех узлов 

, где этот признак использовался в решающем правиле дерева.


Тогда вклад 

-го признака в прогноз 

 считается как суммарный вклад по узлам, учитывающим 

-й признак:





Так мы рассчитаем вклад каждого признака в прогноз определённого объекта 

. Метод был предложен в 
[3]
.


Обратим внимание, что





причём часть признаков будут оказывать положительное, а часть - отрицательное влияние на величину прогноза.




Метод обобщается на ансамбль решающих деревьев (бэггинг, бустинг, решающий лес и др.): для этого нужно усреднить вклады признаков по деревьям ансамбля.




Глобальная важность признака
Усредняя оценку важности по всем объектам выборки, получим 
глобальную важность признака
, похожую по смыслу на меру 
среднего изменения неопределённости
. Первая мера оценивает среднее изменение прогноза при учёте признака, а вторая - среднее влияние признака на снижение 
неопределённости прогнозов
.




Вы также можете прочитать про интерпретацию решающих деревьев в 
[4]
. А в 
следующем разделе учебника
 мы изучим подходы интерпретации прогнозов сложных моделей (balck-box models), таких как ансамбли алгоритмов и нейронные сети.


Литература
​






UC Irvine Machine Learning Repository: wine dataset.






Kanoki.org: decision tree in sklearn.






Blog.datadive.net: interpreting random forests.






Molnar C. Interpretable machine learning. – Lulu. com, 2020: Decision Tree.




Предыдущая страница
Интерпретация логистической регрессии
Следующая страница
Вопросы
Визуализация деревьев
Глобальная важность признаков
Вклад признака в отдельный прогноз
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Вопросы для самопроверки | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретируемое машинное обучение
Интерпретация метрических методов
Метод наивного Байеса
Интерпретация линейной регрессии
Интерпретация логистической регрессии
Интерпретация решающего дерева
Вопросы
Интерпретация сложных моделей
Заключение
Интерпретация простых моделей
Вопросы
Вопросы для самопроверки




В чём разница между локальной и глобальной интерпретируемостью моделей машинного обучения?


В чём заключается предположение наивного Байеса? Приведите пример, когда это предположение не выполнено.


Почему нельзя судить о важности признака в линейной регрессии по модулю коэффициента при этом признаке без предварительной нормализации признаков?


Сравните оценку важности признаков по коэффициентам линейной регрессии и методом среднего изменения неопределённости в решающем дереве. Какой из двух методов более предпочтителен в общем случае и почему?


Зависят ли значения аддитивных эффектов в линейной регрессии от перемасштабирования признаков и последующей перенастройки модели?


Приведите два способа расчёта глобальной важности признаков для всей выборки по решающему дереву. В чём их интуитивное различие?


Почему важность признака лучше оценивать не по отдельному решающему дереву, а по ансамблю из деревьев?


Предыдущая страница
Интерпретация решающего дерева
Следующая страница
Интерпретация сложных моделей
© 2023-25 
Виктор Китов.
 
Новости проекта.









Интерпретация сложных моделей | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Интерпретация сложных моделей
Анализ ошибок модели
Прогнозы на типичных и нетипичных объектах
Влияние признаков на качество прогнозов
Значения Шепли
Локальное объяснение интерпретируемой моделью
Влияние фрагментов
Зависимость прогноза от признаков
Контрфактические объяснения
Влияние обучающих объектов
Вопросы
Заключение
Интерпретация сложных моделей
Интерпретация сложных моделей
Содержание этой страницы
Интерпретация сложных моделей


Если целью прогнозирования является построение максимально точных прогнозов, а не объяснение зависимости в простых терминах, то для этого используют 
сложные модели
 (black-box models), производящие большое число нелинейных операций над вектором признаков. Такие модели не обладают интерпретируемостью напрямую, но можно применить разнообразные опосредованные приёмы для их анализа и объяснения их прогнозов, которые мы рассмотрим в этом разделе.


Способы интерпретации
​


Анализировать сложную модель и её прогнозы можно, изучая:






изменение прогноза в зависимости от реального отклика
;






влияние признаков на прогнозы модели
;






поведение модели на типичных и нетипичных объектах выборки
;






вклад значений отдельных признаков в прогноз
;






изменение прогноза в зависимости от изменения отдельных признаков
;






максимально похожие объекты на заданный, для которых модель выдаёт другой прогноз
;






влияние отдельных объектов обучающей выборки на модель, которую мы в итоге обучим
;






влияние отдельных частей/характеристик объекта на прогноз модели
.






В последующих главах мы разберём эти подходы детальнее. Будут изучены подходы, применимые к самому широкому классу моделей. Во второй части учебника, посвящённой нейросетям, будет 
отдельная глава
 по интерпретации свёрточных нейросетей.


Корреляция, а не причинно-следственная связь
Важно помнить, что интерпретация методов машинного обучения 
показывает корреляцию, а не причинно-следственную связь
 (correlation does not imply causation).


Например, рассмотрим задачу прогнозирования количества атак акул на отдыхающих на морском курорте. Количество купленного мороженного может оказаться одним из самых важных признаков. Разумеется, это не значит, что эти величины связаны напрямую. Скорее, из-за благоприятной погоды больше людей начинают отдыхать на море, покупать мороженное и, как следствие, подвергаться эпизодическим атакам акул.


С другими примерами можно ознакомиться, например, в 
[1]
.


Литература
​




statology.org: correlation does not imply causation: 5 real-world examples.


Предыдущая страница
Интерпретация сложных моделей
Следующая страница
Анализ ошибок модели
Способы интерпретации
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Анализ ошибок модели | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Интерпретация сложных моделей
Анализ ошибок модели
Прогнозы на типичных и нетипичных объектах
Влияние признаков на качество прогнозов
Значения Шепли
Локальное объяснение интерпретируемой моделью
Влияние фрагментов
Зависимость прогноза от признаков
Контрфактические объяснения
Влияние обучающих объектов
Вопросы
Заключение
Интерпретация сложных моделей
Анализ ошибок модели
Содержание этой страницы
Анализ ошибок модели


Для отладки моделей и улучшения их качества полезно анализировать не агрегированную меру качества по всей выборке, такую как точность классификации или средний модуль ошибки, а смотреть на ошибки 
в разбивке по различным истинным значениям целевой переменной
. Это позволяет понять характер зависимости ошибок от реального значения отклика.


Регрессия
​


В случае регрессии для этого строят график зависимости прогноза 

 от истинного значения 

, как показано ниже:


[IMAGE]




По представленному графику видно, что модель хорошо предсказывает объекты со средним откликом, но плохо - с низким или высоким, недооценивая его величину. Таким образом, качество прогнозов можно улучшить, повысив прогноз, когда он оказался ниже или выше среднего значения.




В библиотеке sklearn есть специальный класс PredictionErrorDisplay, позволяющий легко строить подобные визуализации 
[1]
.


Классификация
​


В случае классификации можно анализировать 
матрицу ошибок
 (confusion matrix), строкам которой соответствуют реальные отклики, а столбцам - их прогнозы. Таким образом, 

-й элемент матрицы содержит число случаев, когда истинный класс 

 был предсказан 

-м классом.


Ниже приведён пример этой матрицы для трёх классов:






10
3
0

0
20
12

2
5
30




По матрице видно, что классификатор в целом справляется с задачей (высокие значения на диагонали), а самая типичная ошибка классификатора - назначить объекту 2-го класса 3-й класс. Таким образом, если модель предсказывает 3-й класс, можно для этого объекта проводить дополнительную классификацию отдельной моделью, специально обученной точно различать 2-й и 3-й классы.




В библиотеке sklearn матрица ошибок вычисляется функцией confusion_matrix 
[2]
.


Анализ проблемных объектов
​


Полезно смотреть на те объекты, на которых модель была уверена в одном прогнозе, а верным оказался другой прогноз. Такие ошибки считаются наиболее существенными.


В случае классификации уверенность модели можно оценить по:






рейтингам классов;






вероятностям классов;






величине 
отступа
.






Если прогноз строится ансамблем, то об уверенности прогноза можно судить по числу базовых моделей, голосующих за тот или иной класс.


Анализ таких объектов может дать подсказку, какие дополнительные свойства объектов необходимо учесть в модели, чтобы она реже ошибалась.


Литература
​






Документация sklearn: plotting cross-validated predictions.






Документация sklearn: confusion_matrix.




Предыдущая страница
Интерпретация сложных моделей
Следующая страница
Прогнозы на типичных и нетипичных объектах
Регрессия
Классификация
Анализ проблемных объектов
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Прогнозы на типичных и нетипичных объектах | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Интерпретация сложных моделей
Анализ ошибок модели
Прогнозы на типичных и нетипичных объектах
Влияние признаков на качество прогнозов
Значения Шепли
Локальное объяснение интерпретируемой моделью
Влияние фрагментов
Зависимость прогноза от признаков
Контрфактические объяснения
Влияние обучающих объектов
Вопросы
Заключение
Интерпретация сложных моделей
Прогнозы на типичных и нетипичных объектах
Содержание этой страницы
Прогнозы на типичных и нетипичных объектах


Для отладки обученной модели полезно рассмотреть её обработку:






типичных объектов
 (прототипов, prototypes);






нетипичных объектов
 (критиков, criticisms).






Объекты-прототипы лежат в центрах плотно заполненных областей признакового пространства. Объекты-критики находятся, наоборот, в слабо заполненных областях пространства признаков.




Для простоты последующего анализа множество прототипов и критиков нужно выбирать минимально достаточным, т.е. с использованием минимального числа характерных примеров.




Пример выделения прототипов и критиков для двумерных данных показан ниже 
[1]
:


[IMAGE]




Как видим, прототипы лежат в областях сгущения характерных объектов, а критики - в сгущениях нетипичных объектов, что позволяет описать типичные и нетипичные случаи минимальным числом примеров!




Примеры объектов-прототипов и критиков для задачи определения породы собаки и распознавания рукописных цифр по фото показаны ниже 
[1]
:


[IMAGE]




Видно, что прототипы первой задачи представляют собой классические фото собак крупным планом. Критики же представляют нетипичные случаи, где собак на фото может быть много, на собаку что-то одето и т.д.


Аналогично и во второй задаче - прототипы представляют собой классические и разборчивые написания цифр. На изображениях-критиках цифры написаны неразборчиво, слишком жирно или вообще не соответствуют никакой цифре!




Поскольку прототипы и критики ёмко описывают множество типичных и нетипичных случаев, они позволяют легко получить комплексное представление о работе модели в разных сценариях перед её внедрением.


Прототипы можно найти как центры кластеров при кластеризации методом К-медоид 
[2]
. Этот метод кластеризации аналогичен методу К-средних 
[3]
, только центрами могут выступать лишь объекты обучающей выборки. В качестве критиков можно выбирать объекты выборки, далёкие от центров кластеров, а также друг от друга.


Существует и более продвинутая процедура выделения прототипов и критиков - MMD-critic, описанная в 
[1]
 и имеющая реализацию на python 
[4]
.


Литература
​






Molnar C. Interpretable machine learning. – Lulu. com, 2020: prototypes and criticisms.






Wikipedia: k-medoids.






Wikipedia: k-means clustering.






pypi.org: mmd-critic library.




Предыдущая страница
Анализ ошибок модели
Следующая страница
Влияние признаков на качество прогнозов
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Влияние признаков на качество прогнозов | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Интерпретация сложных моделей
Анализ ошибок модели
Прогнозы на типичных и нетипичных объектах
Влияние признаков на качество прогнозов
Значения Шепли
Локальное объяснение интерпретируемой моделью
Влияние фрагментов
Зависимость прогноза от признаков
Контрфактические объяснения
Влияние обучающих объектов
Вопросы
Заключение
Интерпретация сложных моделей
Влияние признаков на качество прогнозов
Содержание этой страницы
Влияние признаков на качество прогнозов


Перестановочная важность признаков
​


Метод перестановочной важности признаков
 (permutation feature importance) представляет собой способ расчёта степени влияния каждого признака на прогнозы модели.


Достоинством метода является то, что он применим:






для любой модели (white-box, black-box models);






для любой задачи (классификация, регрессия и др.);






для любой функции потерь.






Пусть 

 - матрица объекты-признаки (вектора признаков для каждого объекта составляют строки этой матрицы), а 

 - вектор откликов для объектов в матрице 

. Пара 

 может соответствовать 
как обучающей, так и внешней валидационной выборке
.


Пусть 

 - потери модели на выборке 

, например, средний модуль ошибки для регрессии или частота ошибок для классификации. Чтобы оценить важность 

-го признака, перемешаем (с возвращением) случайным образом значения этого признака (значения 

-го столбца матрицы 

),
получим новую матрицу 

, отличную от 

 только в 

-м столбце.


При таком случайном перемешивании общее распределение 

-го признака сохранится, но связь с 

 потеряется. Пусть 

 - потери модели на выборке 

. Тогда перестановочная важность признака 

 (permutation feature importance, PMI, 
[1]
, 
[2]
) считается по одной из следующих формул:








Таким образом, перестановочная важность признака показывает, во сколько/на сколько средние потери прогнозов изменятся, если модель не сможет эффективно использовать информацию, хранящуюся в том или ином признаке.


Устойчивость к случайности
Обратим внимание, что результат зависит от случайной перестановки признака. При различных перестановках будем получать различный результат. Поэтому на практике статистика пересчитывается много раз для случайных перестановок, а в качестве итогового ответа выдаётся её 
среднее значение
.


Пример расчёта важности признаков по формуле (1) для задачи bike sharing 
[3]
 приведён ниже 
[4]
, где точками обозначены средние значения важности при перезапусках метода, а интервал показывает нижнюю и верхнюю квантиль по значениям в различных запусках:


[IMAGE]




Как видим, все признаки оказывают значимое влияние на прогноз, кроме признака holiday, поскольку его доверительный интервал покрывает единицу.




Рекомендуется использовать отношение (1), а не разность потерь (2), поскольку тогда можно сопоставлять важность признаков на разных моделях 
с разными диапазонами потерь
: относительное изменение потерь более инвариантно к изменению диапазона, чем разность.


Перестановочную важность признаков можно считать:






по обучающей выборке
: тогда узнаем, на каких признаках модель сильнее всего переобучилась;






по валидационной тестовой выборке
: тогда узнаем, какой признак важнее для прогнозирования новых объектов.






Достоинства
​


Метод даёт глобальную интерпретируемость для всей выборки в привязке к конкретной функции потерь. В этом её достоинство по сравнению с внешними эвристическими методами расчёта важности признаков, такими как корреляция 
[5]
 с откликом или нормализованная взаимная информация (normalized mutual information, NMI 
[6]
), которые зависят от прогнозов и верных ответов, но 
никак не зависят от рассматриваемой функции потерь
.


Недостатки
​


К недостаткам метода стоит отнести то, что расчёт важности будет во многом основываться на нереалистичных объектах.




Рассмотрим в качестве объектов пациентов больницы, у которых признаки включают рост и вес. Оценивая важность роста, мы переставляем значения роста случайным образом, оставляя вес таким, каким он был, что может приводить к малореальным пациентам с большим весом, но малого роста, и наоборот.




Также в случае связанных признаков (как тот же рост и вес пациента), если мы переставим случайно значения одного признака, то у модели останется возможность извлекать информацию об "испорченном" признаке из оставшихся связанных признаков. Это приведёт к занижению важности каждого признака в группе зависимых признаков.


Поэтому рекомендуется вначале разбивать признаки на группы связанных друг с другом признаков, а потом переставлять элементы сразу для всех признаков группы. Так мы оценим важность каждой зависимой группы признаков как целого без смещений.




Также с перестановочной важностью признаков можно ознакомиться в 
[4]
. А в 
[7]
 представлен обзор и сравнение различных методов оценки важности признаков.


Литература
​






Breiman L. Random forests //Machine learning. – 2001. – Т. 45. – С. 5-32.






Fisher A., Rudin C., Dominici F. All models are wrong, but many are useful: Learning a variable's importance by studying an entire class of prediction models simultaneously //Journal of Machine Learning Research. – 2019. – Т. 20. – №. 177. – С. 1-81.






UC Irvine Machine Learning Repository: bike sharing dataset.






Molnar C. Interpretable machine learning. – Lulu. com, 2020: permutation feature importance.






Wikipedia: correlation.






Wikipedia: mutual information.






Wei P., Lu Z., Song J. Variable importance analysis: A comprehensive review //Reliability Engineering & System Safety. – 2015. – Т. 142. – С. 399-432.




Предыдущая страница
Прогнозы на типичных и нетипичных объектах
Следующая страница
Значения Шепли
Перестановочная важность признаков
Достоинства
Недостатки
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Значения Шепли | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Интерпретация сложных моделей
Анализ ошибок модели
Прогнозы на типичных и нетипичных объектах
Влияние признаков на качество прогнозов
Значения Шепли
Локальное объяснение интерпретируемой моделью
Влияние фрагментов
Зависимость прогноза от признаков
Контрфактические объяснения
Влияние обучающих объектов
Вопросы
Заключение
Интерпретация сложных моделей
Значения Шепли
Содержание этой страницы
Значения Шепли


Значения Шепли
 (Shapley values 
[1]
) позволяют объяснить для выбранного объекта 

 вклад значения каждого признака в прогноз модели 

. Оценка производится для конкретного объекта и конкретного значения выбранного признака. Вклад значений всех признаков и обеспечивает результирующий прогноз.


Рассмотрим в качестве примера задачу Titanic 
[2]
, в которой по описанию каждого  пассажира (включающему класс билета, пол, возраст и т.д.) нужно предсказать, выжил он в результате кораблекрушения или нет. На рисунке ниже 
[3]
 показано объяснение прогнозируемой вероятности выживания для одного из пассажиров:


[IMAGE]




Видно, что высокая вероятность прогнозируемого выживания 0.93 обеспечивается тем, что пассажир - женщина, которая не путешествовала третьим классом. Однако то, что она не путешествовала первым классом (в one-hot кодировании индикаторы класса - разные признаки) несколько снизило оцениваемую вероятность выжить.




Псевдокод для приближённого расчёта значения Шепли, измеряющего вклад 

-го признака в прогноз приведён ниже.


Результат:
 значение Шепли для значения 

-го признака


Параметры:
 количество итераций 

, исследуемый объект 

, индекс признака 

, матрица данных 

, модель машинного обучения 

.






Для всех 

:






Выбрать случайный объект 

 из матрицы данных 







Случайным образом выбрать перестановку 

 признаков






Упорядочить объект 

:  







Упорядочить объект 

:  







Построить два новых объекта:




С признаком 

:  



Без признака 

:    









Вычислить маржинальный вклад:













Вычислить значение Шепли как среднее маржинальных вкладов:









Число повторов 

 определяет точность полученной оценки: чем выше - тем она получится точнее.


По сути, происходит оценка, насколько в среднем вырастает прогноз, если оставить и заменить интересующее значение признака случайным значением из выборки при одновременной замене случайного подмножества других признаков. В итоге получим 
среднее изменение прогноза за счёт того, что интересующий признак принимает заданное значение
.


Таким образом, значения Шепли оценивают важность признаков в контексте заданного объекта 

, а сумма их значений равна отклонению прогноза 

 от среднего прогноза по всем объектам.


Недостатком метода, как для 
перестановочной важности признаков
, является 
усреднение по малореальным объектам
, поскольку в процедуре оценки генерируются синтетические объекты, для которых часть значений признаков взята из одного объекта, а другая часть - из другого, что может приводить к маловероятным комбинациям признаков, особенно когда признаки сильно скоррелированы.


Глобальная важность признака
С помощью значений Шепли можно вычислить и 
глобальную важность признака
. Для этого абсолютные значения Шепли для этого признака усредняются по всем объектам выборки:





Детальнее о значениях Шепли, их теоретическом обосновании и свойствах можно прочитать в 
[4]
 и 
[5]
. Пример практического расчёта этих значений в python, используя библиотеку shap, доступен в 
[6]
.


Литература
​






Wikipedia: Shapley value.






openml.org: Titanic dataset.






Gosiewska A., Biecek P. IBreakDown: Uncertainty of model explanations for non-additive predictive models //arXiv preprint arXiv:1903.11420. – 2019.






Molnar C. Interpretable machine learning. – Lulu. com, 2020: Shapley values.






Molnar C. Interpretable machine learning. – Lulu. com, 2020: SHAP.






Документация shap: an introduction to explainable AI with Shapley values.




Предыдущая страница
Влияние признаков на качество прогнозов
Следующая страница
Локальное объяснение интерпретируемой моделью
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Локальное объяснение интерпретируемой моделью | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Интерпретация сложных моделей
Анализ ошибок модели
Прогнозы на типичных и нетипичных объектах
Влияние признаков на качество прогнозов
Значения Шепли
Локальное объяснение интерпретируемой моделью
Влияние фрагментов
Зависимость прогноза от признаков
Контрфактические объяснения
Влияние обучающих объектов
Вопросы
Заключение
Интерпретация сложных моделей
Локальное объяснение интерпретируемой моделью
Содержание этой страницы
Локальное объяснение интерпретируемой моделью


Алгоритм LIME
​


Метод 
LIME
 (local interpretable model-agnostic explanations 
[1]
) позволяет объяснить прогноз сложной модели 

 для интересуемого объекта 

 за счёт 
аппроксимации прогнозов этой модели другой простой и интерпретируемой моделью
 в окрестности точки 

.




Например, в задаче кредитного скоринга нас может интересовать, почему для определённого клиента кредит не был одобрен. Пусть прогноз возврата кредита осуществляется многослойной нейросетью или сложным ансамблем моделей, поэтому напрямую неинтерпретируем. Но мы можем сгенерировать много синтетических клиентов, похожих на интересующего, посмотреть на прогнозы сложной модели для этих похожих клиентов и настроить 
простую интерпретируемую модель, аппроксимирующую прогнозы сложной модели в окрестности интересуемого клиента
. Простыми и интерпретируемыми моделями могут выступать решающее дерево, линейная модель, метод ближайших центроидов и т.д.




Простая модель поддаётся непосредственной интерпретации, поэтому можно напрямую изучить логику её работы, чтобы делать выводы о работе сложной модели в окрестности интересующего объекта.


Метод LIME работает следующим образом:






Выбрать объект 

, для которого нужно объяснить прогноз сложной модели 

.






Сгенерировать выборку, состоящую из локальных вариаций 

 объекта 

.






Построить для вариаций прогнозы сложной моделью 

, получив выборку:









Взвесить объекты по близости к 

 (чем вариация ближе, тем её вес больше):









Настроить интерпретируемую модель 

 по взвешенной выборке (чем вес выше, тем объект учитывается 
сильнее
).






Исследовать интерпретируемую модель, аппроксимирующую прогноз сложной модели для точки 

.






Этапы работы алгоритма визуализированы ниже на графиках A,B,C,D 
[2]
:


[IMAGE]


Процесс сэмплирования объектов, похожих на заданный, зависит от характера объектов:






Для вектора вещественных чисел можно добавлять шум с небольшой дисперсией.






Для текста можно включать/исключать отдельные слова.






Для изображения - включать/исключать отдельные суперпиксели (области соседних пикселей, примерно похожих по цвету 
[3]
).






В качестве простой интерпретируемой модели, аппроксимирующей сложную, обычно используется:






Решающее дерево небольшой глубины.






Линейная модель с сильной 
L1-регуляризацией
.






L1-регуляризация используется для сокращения числа признаков. Альтернативно для этого можно использовать 
OMP-регрессию
 или другой метод 
отбора признаков
, такой как forward-selection (последовательный выбор самых важных признаков) или backward-selection (последовательное исключение самых незначимых).


Контроль ошибки аппроксимации
​


Cтоит помнить, что простая интерпретируемая модель является лишь 
аппроксимацией
 сложной модели, поэтому важно контролировать качество её аппроксимации. Например, для задачи регрессии это может быть ошибка аппроксимации относительно ошибки аппроксимации константой:





Если ошибка аппроксимации высока, нужно либо усложнять аппроксимирующую модель (увеличивая глубину дерева или увеличивая число признаков, ослабляя  L1-регуляризацию), либо уменьшить окрестность сэмплируемых вокруг интересующего объекта 

 точек (которую при прочих равных лучше брать побольше, чтобы описать поведение исходной модели в более широкой области).


Примеры использования
​


Классификация текста
​


В 
[1]
 представлена интерпретация бинарного классификатора документа из подмножества документов датасета 20-news-groups 
[4]
, относящихся к классам christianity и atheism:


[IMAGE]


Самые значимые слова показаны слева, а начало документа - справа. Хотя классификация корректна, модель использовала нерелевантные слова Posting, Host и Re, не имеющие никакого отношения к темам христианства и атеизма! Подобный анализ позволяет 
выявить переобученные модели
, даже если они показывают хорошее качество прогнозов.


Классификация изображений
​


Метод LIME можно использовать и для интерпретации моделей, классифицирующих изображения по объектам, которые на них показаны. Для этого можно сложную модель, такую как 
Google inception network
, аппроксимировать линейным классификатором, использующим небольшое число суперпикселей. Пример подобной интерпретации для наиболее вероятных классов приведён ниже 
[1]
:


[IMAGE]


Как видим, наиболее сильно влияющие суперпиксели согласуются с классами, и модель не переобучилась.




Метод LIME на python реализован в 
одноимённой библиотеке
. Детальнее о методе можно почитать в 
[2]
, а также в оригинальной статье 
[1]
.


Литература
​






Ribeiro M. T., Singh S., Guestrin C. " Why should i trust you?" Explaining the predictions of any classifier //Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. – 2016. – С. 1135-1144.






Molnar C. Interpretable machine learning. – Lulu. com, 2020: LIME.






Medium.com: superpixels and SLIC.






UC Irvine Machine Learning Repository: twenty newsgroups dataset.




Предыдущая страница
Значения Шепли
Следующая страница
Влияние фрагментов
Алгоритм LIME
Контроль ошибки аппроксимации
Примеры использования
Классификация текста
Классификация изображений
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Влияние фрагментов на прогноз | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Интерпретация сложных моделей
Анализ ошибок модели
Прогнозы на типичных и нетипичных объектах
Влияние признаков на качество прогнозов
Значения Шепли
Локальное объяснение интерпретируемой моделью
Влияние фрагментов
Зависимость прогноза от признаков
Контрфактические объяснения
Влияние обучающих объектов
Вопросы
Заключение
Интерпретация сложных моделей
Влияние фрагментов
Содержание этой страницы
Влияние фрагментов на прогноз


В задаче классификации фотографий можно очень легко оценивать влияние каждого фрагмента изображения на прогноз. Для этого изображение нужно разбить на суперпиксели (superpixels 
[1]
), то есть группы соседних пикселей, примерно похожих по цвету и размеру, а затем поочерёдно затирать каждый суперпиксель (заполняя равномерно некоторым цветом) и смотреть, 
насколько изменится прогноз модели
.


Ниже показаны примеры разбиения изображения на суперпиксели 
[2]
:


[IMAGE]


На изображениях ниже подсвечены суперпиксели, заполнение которых равномерным цветом приводит к максимальному изменению прогноза 
[3]
:


[IMAGE]


По самым значимым суперпикселям видно, что модель обучилась корректно - при классификации объекта она анализирует именно его, а не фон.




Вместо суперпикселей изображение можно разбить на квадратные участки и затирать поочерёдно каждый участок, чтобы оценить его влияние. Однако в этом случае полученная карта влияния будет получаться более грубой, чем используя суперпиксели.




Анализ текстов
Аналогичный подход можно применить и при классификации текстов - нужно 
поочерёдно удалять слова, фразы или целые предложения
 и смотреть, насколько изменится прогноз модели, чтобы определить самые значимые части текста, голосующие за выбранный класс.


Выделение суперпикселей
​


Для выделения суперпикселей существуют различные алгоритмы. Опишем один из самых известных - алгоритм SLIC (simple linear iterative clustering) 
[2]
:






Изображение переводится в цветовое пространство 
CIELAB
. Тогда цвет каждой точки будет кодироваться не тройкой 

, а тройкой 

.






Инициализируются центры K кластеров по равномерной сетке координат 

. Если у нас 

 пикселей, то вначале каждый кластер будет содержать 

 пикселей, а сторона каждого кластера будет примерно равна 

.






Центры немного смещаются, чтобы обеспечить минимум перепада цветов вдоль вертикальной и горизонтальной оси в окрестности 3x3:











В цикле до сходимости, используя алгоритм K-средних 
[4]
:




для каждого центра производится распределение окружающих его пикселей между кластерами по принципу близости до его центра в пространстве 

 и пространственной окрестности 

.


обновляются расположения центров кластеров как средние значения 5-мерных векторов, описывающих каждый пиксель.






Постобработка: если обнаружены несвязные области, отнесенные к одному центроиду, они присоединяются к ближайшему соседнему кластеру.






В работе 
[5]
 можно прочитать про другие методы извлечения суперпикселей и их сравнение с методом SLIC. Алгоритмы извлечения суперпикселей реализованы в библиотеке scikit-image 
[6]
.


Литература
​






Paperswithcode.com: superpixels.






Achanta R. et al. Slic superpixels. – 2010.






Wei Y. et al. Explain black-box image classifications using superpixel-based interpretation //2018 24th International Conference on Pattern Recognition (ICPR). – IEEE, 2018. – С. 1640-1645.






Wikipedia: K-means clustering.






Wu C., Yan H. A survey of superpixel methods and their applications //Authorea Preprints. – 2024.






Документация scikit-image: сomparison of segmentation and superpixel algorithms.




Предыдущая страница
Локальное объяснение интерпретируемой моделью
Следующая страница
Зависимость прогноза от признаков
Выделение суперпикселей
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Зависимость прогноза от признаков | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Интерпретация сложных моделей
Анализ ошибок модели
Прогнозы на типичных и нетипичных объектах
Влияние признаков на качество прогнозов
Значения Шепли
Локальное объяснение интерпретируемой моделью
Влияние фрагментов
Зависимость прогноза от признаков
Контрфактические объяснения
Влияние обучающих объектов
Вопросы
Заключение
Интерпретация сложных моделей
Зависимость прогноза от признаков
Содержание этой страницы
Зависимость прогноза от признаков


Сложные неинтерпретируемые модели (black-box models) можно анализировать, визуализируя 
зависимость их прогнозов от изменения отдельных входных признаков
. Тем самым можно выделить признаки, оказывающие наибольшее влияние на модель, а также оценить характер этого влияния и проверить, насколько это влияние согласуется с априорными знаниями.


График частичной зависимости
​


Определение
​


График частичной зависимости
 (partial dependence plot, PDP 
[1]
) показывает влияние выбранного признака 

 (например, первого) на прогноз модели 

, где вектором 

 обозначены все признаки, кроме выбранного (например, второй, третий и т.д.). Определим ожидаемое значение прогноза 

, зафиксировав интересующий признак и усредняя по всем оставшимся:





На практике распределение признаков неизвестно, поэтому используется численная оценка среднего по объектам выборки при фиксированном признаке 

:








 представляет собой объект 

, у которого интересующий признак положен равным 

.




Примеры
​


Рассмотрим задачу BikeSharing 
[2]
, в которой прогнозируется число арендованных велосипедов по характеристикам дня (дата, температура, влажность и т.д.). График частичной зависимости для этой задачи показан на рисунке ниже для вещественных признаков слева, а для категориального признака (season) справа 
[3]
:


[IMAGE]


По графикам видно, что велосипедов арендуется меньше при низкой и высокой температуре. Снижает число аренд высокая влажность и скорость ветра. Это согласуется с общей логикой и свидетельствует в пользу того, что модель построена верно. Хотя зависимость от сезона оказалась не настолько ярко выражена.


Зависимость от двух признаков
​


Можно строить PDP-график зависимости 
сразу для пары признаков
. В этом случае он будет представлять собой тепловую карту (heatmap) изменений целевого значения от двух признаков, на которой будет видно их совместное воздействие на прогноз, как показано ниже на графике справа 
[4]
:


[IMAGE]


Зависимость такого рода позволит выявить более сложные виды 
совместного воздействия двух признаков
 на прогнозы модели.


Преимущества и недостатки метода
​


График частичной зависимости PDP интуитивен и его легко реализовать. Также эту зависимость можно строить не для одного, а сразу для двух признаков.


PDP - это метод глобальной интерпретации модели (без привязки к определённому объекту), показывающий общую зависимость прогнозов модели от признака. С другой стороны, вычисление PDP вычислительно трудоёмко - приходится проводить усреднение 
по всем объектам выборки
 для каждого значения признака (для больших выборок лучше считать приближённо по подвыборке). Также из-за усреднения по всем объектам мы можем потерять часть зависимостей.




Например, если для половины объектов признак положительно влияет на прогноз, а для другой половины - отрицательно, то при усреднении получим отсутствие связи!




В PDP предполагается, что интересующий признак 

 и остальные признаки 

 
независимы
, поскольку при построении графика значение интересующего признака фиксируется, а остальные признаки берутся из выборки независимо. Если в действительности признаки сильно зависимы, это будет приводить к появлению малореалистичных объектов.




Например, при анализе данных пациентов больницы можно строить PDP для признака "рост". При этом скоррелированный признак "вес" будет браться независимо от роста, что будет приводить к появлению нереалистичных пациентов с детским ростом и взрослым весом.




График индивидуальных условных ожиданий
​


График индивидуальных условных ожиданий
 (Individual Conditional Expectation, ICE 
[5]
) показывает зависимость отклика от интересующего признака, не усредняя по остальным объектам, а для каждого объекта в отдельности. Разобьём, как и раньше, вектор признаков 

 на интересующий признак 

 и все остальные признаки 

. ICE график представляет 
собой совокупность графиков
 зависимостей прогноза от признака 
для каждого объекта валидационной выборки
 

:





и показан для задачи BikeSharing на рисунке ниже 
[6]
:


[IMAGE]


График ICE даёт более детальную картину: он показывает влияние интересующего признака на прогноз 
по каждому объекту в отдельности
, что позволяет увидеть, например, ситуацию, когда для половины объектов признак имеет положительное влияние, а для половины - отрицательное.


Недостатком подхода является перегруженная графиками иллюстрация, на которой сложно выделить основные тенденции, поэтому часто строят графики сдвинутых индивидуальных условных ожиданий (Centered ICE plot, c-ICE) по объектам, центрируя, чтобы все графики выходили из одной точки:





после чего отдельным цветом можно отобразить усреднённую по объектам зависимость для простоты визуализации, как показано ниже 
[6]
:


[IMAGE]




Усреднённая зависимость на графике (жёлтая), с точностью до сдвига, будет PDP-графиком.




Стоит отметить, что как графики ICE и c-ICE, точно так же, как PDP, опираются на предположение о 
независимости
 признака 

 от всех остальных, поскольку используют  сгенерированные объекты, где признаки меняются независимо от друга. Это может приводить использованию в вычислениях малореалистичных объектов.


Условный график
​


Условный график
 (marginal plot, M-plot 
[7]
) лишён недостатка PDP и ICE графиков, состоящего в усреднении по несуществующим малореальным объектам за счёт того, что там при каждом значении признака 

 происходит усреднение не по безусловному распределению оставшихся признаков 

, а 
по условному
 

.


Приведём иллюстрацию, на которой слева показано безусловное распределение 

, а справа - условное распределение 

 
[7]
:


[IMAGE]


Формулой условный график запишется следующим образом:





где анализируемый признак 

 разбивается на полуинтервалы 

, а 

 - множество объектов, для которых значение признака 

 попало в 

-й интервал,  

 обозначает мощность (число элементов) этого множества.


На условном графике, в отличие от графиков PDP и ICE, усреднение производится только по реалистичным объектам, однако при анализе признака, сильно связанного с другим признаком, график покажет 
совокупное влияние обоих скореллированных признаков, а не чистый эффект одного из них
.




В примере с пациентами больницы это будет совокупное влияние и роста, и веса пациента, а не только роста (или только веса) в чистом виде.






График аккумулированных локальных эффектов
​


График аккумулированных локальных эффектов
 (Accumulated Local Effects, ALE 
[8]
) повторяет методологию условного M-графика, но лишён недостатка, состоящего в том, что если два признака сильно скоррелированы, то будет показан совокупный эффект этих признаков, а не чистый эффект одного из них. ALE-график покажет именно 
чистый эффект интересующего признака
. При этом усреднение будет производиться только по реалистичным объектам.


Формула для расчёта графика аккумулированных локальных эффектов следующая:





где обозначения такие же, как для условного графика M-plot.


Динамика зависимости от значения признака складывается из малых локальных изменений в областях полуинтервала значений признака 

. Формула показывает изменения прогноза 
только за счёт интересующего признака
 

, когда прочие признаки не влияют, поскольку по ним происходит локальное усреднение вокруг значений признака, который мы анализируем.


Итоговый ALE-график - это аккумулированная сумма таких малых изменений по аналогии того как разность значений функции в двух точках - это интеграл от её производной между этими точками. Пример ALE-графика для задачи BikeSharing показан ниже 
[7]
:


[IMAGE]


Зависимость от двух признаков
Как и для PDP-графика, ALE-график можно строить сразу для пары признаков. В этом случае он будет представлять собой тепловую карту (heatmap) изменений целевого значения от двух признаков, на которой будет видно их 
совместное воздействие
 на прогноз.




Детальнее о PDP-графике можно прочитать в 
[3]
, о ICE-графике - в 
[4]
, а об условном и ALE-графике - в 
[7]
.


С кодом, реализующим построение PDP- и ICE-графиков с использованием библиотеки sklearn, можно ознакомиться в 
[4]
. Построение PDP- и ALE-графиков реализовано в библиотеках PiML 
[9]
 и effector 
[10]
.


Литература
​




Hastie T., Tibshirani R., Friedman J. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. – Springer Science & Business Media, 2009.


UC Irvine Machine Learning Repository: Bike Sharing dataset.


Molnar C. Interpretable machine learning. – Lulu. com, 2020: Partial Dependence Plot (PDP).


Документация sklearn: Partial Dependence and Individual Conditional Expectation plots.


Goldstein A. et al. Peeking inside the black box: Visualizing statistical learning with plots of individual conditional expectation //journal of Computational and Graphical Statistics. – 2015. – Т. 24. – №. 1. – С. 44-65.


Molnar C. Interpretable machine learning. – Lulu. com, 2020: Individual Conditional Expectation (ICE).


Molnar C. Interpretable machine learning. – Lulu. com, 2020: Accumulated Local Effects (ALE).


Apley D. W., Zhu J. Visualizing the effects of predictor variables in black box supervised learning models //Journal of the Royal Statistical Society Series B: Statistical Methodology. – 2020. – Т. 82. – №. 4. – С. 1059-1086.


Документация PiML.


Документация effector.


Предыдущая страница
Влияние фрагментов
Следующая страница
Контрфактические объяснения
График частичной зависимости
Определение
Примеры
Зависимость от двух признаков
Преимущества и недостатки метода
График индивидуальных условных ожиданий
Условный график
График аккумулированных локальных эффектов
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Контрфактические объяснения | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Интерпретация сложных моделей
Анализ ошибок модели
Прогнозы на типичных и нетипичных объектах
Влияние признаков на качество прогнозов
Значения Шепли
Локальное объяснение интерпретируемой моделью
Влияние фрагментов
Зависимость прогноза от признаков
Контрфактические объяснения
Влияние обучающих объектов
Вопросы
Заключение
Интерпретация сложных моделей
Контрфактические объяснения
Содержание этой страницы
Контрфактические объяснения


Один из способов проинтерпретировать тот или иной прогноз - это задаться вопросом: а какие минимальные изменения нужно произвести в прогнозируемом объекте, чтобы получить другой (нужный нам) прогноз?






Пример 1
. Рассмотрим модель, прогнозирующую, за сколько можно сдать квартиру на рынке по её характеристикам. Предположим, мы оценили эту модель по обучающей выборке, и для нашей квартиры модель выдаёт 50000 руб./мес. Можно задаться вопросом - какие минимальные изменения в квартире нужно произвести, чтобы сдавать её за 70000 руб./мес? Нас, конечно, будет интересовать поиск в пространстве только тех параметров, которые можно изменить - характер ремонта, наличие бытовой техники и мебели, условия сдачи и т.д.






Пример 2
. Рассмотрим модель, прогнозирующую, можно ли клиенту выдать кредит или нельзя. Допустим, она выдаёт прогноз, что нельзя. Тогда можно задаться вопросом: а какие минимальные изменения в характеристиках клиента должны случиться, чтобы кредит ему всё-таки одобрили? Например, иметь стаж работы на год больше или получать зарплату на 10 процентов выше.






Ответы на подобные вопросы даёт 
метод контрфактических объяснений
 (counterfactual explanations). Контрфактическое объяснение для 

 - это такой объект 

, который






максимально похож на 

 (отличается в минимальном числе признаков на минимальную величину),






но в то же время обладает требуемым откликом 

.






Находить контрфактические объяснения можно, решая следующую оптимизационную задачу 
[1]
:





Из условий Каруша-Куна-Таккера 
[2]
 можно показать, что она эквивалентна следующей задаче:





где 

 - расстояние между объектами, а 

 и 

 связаны между собой некоторым убывающим преобразованием 

.


Таким образом, контрфактическое объяснение 

 получается в результате балансирования двух требований:






прогноз 

 должен минимально отличаться от требуемого прогноза 

;






само объяснение 

 должно быть максимально похоже на исходный объект 

.








Какое именно свойство для нас важнее контролируется гиперпараметрами 

 и 

.




В качестве 

 в 
[1]
 предлагается брать





поскольку модули отклонений признаков (а не квадраты отклонений) будут поощрять нахождение таких 

, которые бы отличались от 

 в минимальном числе признаков, оставляя при этом оставшиеся признаки такими, какими они были, что упрощает интерпретируемость. Нормировка на 

 (mean absolute deviation) приводит признаки к одинаковому масштабу, делая их равнозначными при сравнении. Хотя можно использовать и 
другие методы нормализации признаков
.


В 
[3]
 контрфактические объяснения предлагается находить, накладывая дополнительные штрафы:






за число отличающихся признаков в 

 и 

 (чтобы упростить интерпретацию);






за несогласованность 

 с обучающей выборкой (по расстоянию от 

 до ближайшего соседа из обучающей выборки).








Более детально ознакомиться с контрафактическими объяснениями вы можете в 
[4]
.


Литература
​






Wachter S., Mittelstadt B., Russell C. Counterfactual explanations without opening the black box: Automated decisions and the GDPR //Harv. JL & Tech. – 2017. – Т. 31. – С. 841.






Wikipedia: Karush–Kuhn–Tucker conditions.






Dandl S. et al. Multi-objective counterfactual explanations //International conference on parallel problem solving from nature. – Cham : Springer International Publishing, 2020. – С. 448-469.






Molnar C. Interpretable machine learning. – Lulu. com, 2020: Counterfactual Explanations.




Предыдущая страница
Зависимость прогноза от признаков
Следующая страница
Влияние обучающих объектов
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Влияние обучающих объектов | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Интерпретация сложных моделей
Анализ ошибок модели
Прогнозы на типичных и нетипичных объектах
Влияние признаков на качество прогнозов
Значения Шепли
Локальное объяснение интерпретируемой моделью
Влияние фрагментов
Зависимость прогноза от признаков
Контрфактические объяснения
Влияние обучающих объектов
Вопросы
Заключение
Интерпретация сложных моделей
Влияние обучающих объектов
Содержание этой страницы
Влияние обучающих объектов


Значимые объекты (influential instances)
​


Прогнозы модели зависят от её параметров, которые настраиваются по обучающей выборке. Разумно поставить следующий вопрос: какие объекты обучающей выборки сильнее всего влияют на






параметры модели,






прогноз модели для частного объекта 

,






качество прогнозов модели для всей выборки?






Обучающие примеры, оказывающие наиболее сильное влияние, называются 
значимыми объектами
 (influential instances).


На рисунке ниже 
[1]
 хорошо виден один объект справа внизу, который оказывает наиболее сильное влияние на прогнозы модели, смещая их:


[IMAGE]


Очевидно, это неправильная ситуация, когда лишь один объект способен сильно смещать все прогнозы модели!


Использование информации о значимых объектах
​


Выявление значимых объектов и силы их влияния позволяет решать следующие задачи:






Выявление вредных объектов
, которые приводят к смещённым прогнозам и должны быть исключены из выборки. Этими объектами могут быть:






объекты-выбросы, полученные, например, в результате ошибки измерения или описания нестандартных случаев, которые модель не должна обрабатывать;






целенаправленно занесённые ошибочные наблюдения для искажения прогнозов модели в нужную злоумышленнику сторону (data poisoning attack 
[2]
)










Верификация корректности обучающей выборки и выявление переобучения
: прогноз модели не должен определяться отдельными наблюдениями, а должен интегрировать опыт от многих обучающих примеров!






Приоретизация измерений для перепроверки
: вместо перепроверки корректности занесения данных от всех наблюдений перепроверим в первую очередь значимые наблюдения.






Обнаружение наиболее информативных объектов
 чтобы понять, какими новыми объектами дополнять обучающую выборку, чтобы расширенная обучающая выборка дала максимальное улучшение качества прогнозов (active learning 
[3]
).






Последнее особенно важно, когда мы обучили модель на одной выборке, а применяем к другой (с немного отличающимся распределением объектов). Используя значимые наблюдения  можно анализировать несоответствие выборок и понимать, объектов какого типа не хватает при обучении модели.




Например, модель обучена предсказывать вероятность невозврата кредита на клиентах банка из одного региона, а затем применяется в другом. Если для прогнозов значимыми объектами окажутся клиенты с нестабильным источником доходов, привязанном к сезонности, то следует больше собрать данных именно по таким клиентам!




Расчёт значимости объектов
​


Определим влияние объектов более формально. Пусть предиктивная модель 

 обучена на всех наблюдениях, а 

 обучена на всех, кроме 

-го объекта 

. Тогда влияние 

-го наблюдения на прогноз объекта 

 можно оценить как





а глобальное влияние на все прогнозы выборки будет получаться усреднением по объектам:







Впервые подобный анализ был предложен в 
[4]
 для выявления значимых наблюдений для линейной регрессии, а в качестве меры отклонений использовался квадрат ошибки.




В случае векторного прогноза (например, вектор вероятностей классов) модуль в формулах нужно заменить на векторную норму от изменений.


Можно исключать объекты не по одному, а группами по определённому критерию. Например, по времени наблюдений. И анализировать, насколько модель зависит от более старых и более новых наблюдений. Или анализировать наблюдения, полученные из разных источников.


Оценив влияние 

 для каждого объекта 

 обучающей выборки, можно построить простую интерпретируемую модель, которая будет предсказывать это влияние. Проще всего использовать дерево небольшой глубины. Анализируя структуру этого дерева, мы получим общее представление о тех характеристиках, которыми обладают значимые объекты.


Если исключать объекты по одному, а не группами, то расчёты важности будут вычислительно трудоёмкими, поскольку предполагают, что для каждого объекта выборки нужно перенастраивать модель, когда этот объект в выборку включён и исключён. Эти расчёты упрощаются при использовании 
метода опорных векторов
 и 
регрессии опорных векторов
, поскольку прогнозы для этих методов зависят только от опорных объектов (которых мало) и не зависят от неинформативных объектов (большинство).


Для моделей, оцениваемых градиентными методами оптимизации (линейные методы, нейросети) существует эффективный алгоритм приближённого расчёта важности объектов без многократной перенастройки модели с включением/исключением каждого объекта выборки 
[5]
. В этой работе, в частности, рассматривается задача классификации изображений на собак и рыб, и для тестового изображения рыбы приводятся два самых значимых обучающих объекта для её классификации двумя моделями - методом опорных векторов с Гауссовым ядром (SVM-RBF) и нейросетевой моделью Inception V3:


[IMAGE]


Из иллюстрации видно, что метод SVM-RBF больше зависит от попиксельного сходства между изображениями, игнорируя семантику, поскольку самые важные обучающие изображения оказались той же цветовой гаммы, но содержат рыб другой разновидности. А модель Inception концентрируется именно на семантической близости: самые важные обучающие объекты для неё отличаются по цветам, зато содержат фотографии рыбы того же самого вида, которую необходимо классифицировать.




Подробный разбор темы значимых объектов доступен в 
[1]
. Обзор различных методов вычисления значимости объектов (помимо перенастройки модели с объектом/без объекта), а также их сравнение предоставлено в 
[6]
.


Литература
​






Molnar C. Interpretable machine learning. – Lulu. com, 2020: Influential Instances.






crowdstrike.com: data-poisoning.






Wikipedia: Active learning.






Cook R. D. Detection of influential observation in linear regression //Technometrics. – 1977. – Т. 19. – №. 1. – С. 15-18.






Koh P. W., Liang P. Understanding black-box predictions via influence functions //International conference on machine learning. – PMLR, 2017. – С. 1885-1894.






Søgaard A. et al. Revisiting methods for finding influential examples //arXiv preprint arXiv:2111.04683. – 2021.




Предыдущая страница
Контрфактические объяснения
Следующая страница
Вопросы
Значимые объекты (influential instances)
Использование информации о значимых объектах
Расчёт значимости объектов
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.









Вопросы для самопроверки | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Интерпретация сложных моделей
Анализ ошибок модели
Прогнозы на типичных и нетипичных объектах
Влияние признаков на качество прогнозов
Значения Шепли
Локальное объяснение интерпретируемой моделью
Влияние фрагментов
Зависимость прогноза от признаков
Контрфактические объяснения
Влияние обучающих объектов
Вопросы
Заключение
Интерпретация сложных моделей
Вопросы
Вопросы для самопроверки




Как по матрице ошибок посчитать долю ошибочных классификаций?


Почему в методе перестановочной важности признаков нужно выдавать усреднённую оценку по разным запускам, а по однократному запуску?


Метод перестановочной важности признаков завышает или занижает важность сильно скоррелированных признаков? Почему?


Почему для анализа областей, сильнее всего влияющих на классификацию изображений эффективнее разбивать изображение на суперпиксели, а не на квадратные области равномерной сетки? В чём состоит идея алгоритма разбиения изображения на суперпиксели?


Какие объясняющие модели используются для интерпретации прогноза методом LIME?


В чём преимущество условного графика (marginal plot) по сравнению с графиком частичной зависимости (partial dependence plot)? Какой есть недостаток у условного графика и как его можно исправить?


Какие методы интерпретации моделей объясняют прогнозы модели для всей выборки в целом, а какие - только прогноз для конкретного объекта?


Предыдущая страница
Влияние обучающих объектов
Следующая страница
Заключение
© 2023-25 
Виктор Китов.
 
Новости проекта.

