





Вопросы для самопроверки | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Линейная регрессия
Аналитическое решение для линейной регрессии
Регуляризация в линейной регрессии
Аналитическое решение для гребневой регрессии
Линейный ансамбль моделей
Регрессия опорных векторов
Orthogonal matching pursuit
Локально-линейная регрессия
Дополнительная литература
Вопросы
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Линейная регрессия и её обобщения
Вопросы
Вопросы для самопроверки




В каких случаях лучше использовать линейную регрессию, а в каких - метод K ближайших соседей для построения прогнозов?


Зачем используется регуляризация? В каких случаях лучше использовать L1-регуляризацию, а в каких - L2-регуляризацию?


В каких ситуациях по сути оценка весов линейной регрессии не будет определена? Почему?


Какой гиперпараметр в гребневой и LASSO-регрессии отвечает за выразительную сложность (гибкость) модели? Его увеличение увеличивает или уменьшает  сложность модели?


От объектов, удовлетворяющих какому свойству, будет зависеть решение регрессии опорных векторов? А от каких не будет? Почему?


Почему при линейной комбинации прогнозов различных базовых моделей, веса при моделях необходимо настраивать не на той же самой выборке, на которой настраивались базовые модели? Приведите иллюстративный пример.


Почему важно всегда включать константный признак в список признаков метода Orthogonal Matching Pursuit регрессии?


Приведите примеры задач, в которых оправдано использование 
$\epsilon$
ϵ
-нечувствительных потерь.


Предыдущая страница
Дополнительная литература
Следующая страница
Оценка качества регрессии
© 2023-25 
Виктор Китов.
 
Новости проекта.

