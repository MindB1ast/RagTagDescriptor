





Контрфактические объяснения | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Интерпретация сложных моделей
Анализ ошибок модели
Прогнозы на типичных и нетипичных объектах
Влияние признаков на качество прогнозов
Значения Шепли
Локальное объяснение интерпретируемой моделью
Влияние фрагментов
Зависимость прогноза от признаков
Контрфактические объяснения
Влияние обучающих объектов
Вопросы
Заключение
Интерпретация сложных моделей
Контрфактические объяснения
Содержание этой страницы
Контрфактические объяснения


Один из способов проинтерпретировать тот или иной прогноз - это задаться вопросом: а какие минимальные изменения нужно произвести в прогнозируемом объекте, чтобы получить другой (нужный нам) прогноз?






Пример 1
. Рассмотрим модель, прогнозирующую, за сколько можно сдать квартиру на рынке по её характеристикам. Предположим, мы оценили эту модель по обучающей выборке, и для нашей квартиры модель выдаёт 50000 руб./мес. Можно задаться вопросом - какие минимальные изменения в квартире нужно произвести, чтобы сдавать её за 70000 руб./мес? Нас, конечно, будет интересовать поиск в пространстве только тех параметров, которые можно изменить - характер ремонта, наличие бытовой техники и мебели, условия сдачи и т.д.






Пример 2
. Рассмотрим модель, прогнозирующую, можно ли клиенту выдать кредит или нельзя. Допустим, она выдаёт прогноз, что нельзя. Тогда можно задаться вопросом: а какие минимальные изменения в характеристиках клиента должны случиться, чтобы кредит ему всё-таки одобрили? Например, иметь стаж работы на год больше или получать зарплату на 10 процентов выше.






Ответы на подобные вопросы даёт 
метод контрфактических объяснений
 (counterfactual explanations). Контрфактическое объяснение для 
$\left(\mathbf{x},f\left(\mathbf{x}\right)\right)$
(
x
,
f
(
x
)
)
 - это такой объект 
$\mathbf{x}'$
x
′
, который






максимально похож на 
$\mathbf{x}$
x
 (отличается в минимальном числе признаков на минимальную величину),






но в то же время обладает требуемым откликом 
$y'$
y
′
.






Находить контрфактические объяснения можно, решая следующую оптимизационную задачу 
[1]
:


$\left(f\left(\mathbf{x}'\right)-y'\right)^{2}+\lambda\rho\left(\mathbf{x},\mathbf{x}'\right)\to\min_{\mathbf{x}'}$
(
f
(
x
′
)
−
y
′
)
2
+
λ
ρ
(
x
,
x
′
)
→
x
′
min
​


Из условий Каруша-Куна-Таккера 
[2]
 можно показать, что она эквивалентна следующей задаче:


$\begin{cases}
\left(f\left(\mathbf{x}'\right)-y'\right)^{2}\to\min_{\mathbf{x}'}\\
\rho\left(\mathbf{x},\mathbf{x}'\right)\le\varepsilon,
\end{cases}$
{
(
f
(
x
′
)
−
y
′
)
2
→
min
x
′
​
ρ
(
x
,
x
′
)
≤
ε
,
​


где 
$\rho\left(\mathbf{x},\mathbf{x}'\right)$
ρ
(
x
,
x
′
)
 - расстояние между объектами, а 
$\lambda$
λ
 и 
$\varepsilon$
ε
 связаны между собой некоторым убывающим преобразованием 
$\varepsilon=F\left(\lambda\right)$
ε
=
F
(
λ
)
.


Таким образом, контрфактическое объяснение 
$\mathbf{x}'$
x
′
 получается в результате балансирования двух требований:






прогноз 
$f\left(\mathbf{x}'\right)$
f
(
x
′
)
 должен минимально отличаться от требуемого прогноза 
$y'$
y
′
;






само объяснение 
$\mathbf{x}'$
x
′
 должно быть максимально похоже на исходный объект 
$\mathbf{x}$
x
.








Какое именно свойство для нас важнее контролируется гиперпараметрами 
$\lambda$
λ
 и 
$\varepsilon$
ε
.




В качестве 
$\rho\left(\mathbf{x},\mathbf{x}'\right)$
ρ
(
x
,
x
′
)
 в 
[1]
 предлагается брать


$\begin{gathered}
\rho\left(\mathbf{x},\mathbf{x}'\right)=\sum_{d=1}^{D}\frac{\left|x^{d}-x'^{d}\right|}{MAD\left(x^{d}\right)},\\
MAD\left(x^{d}\right)=\text{median}_{n\in\left\{ 1,...N\right\} }\left|x_{n}^{d}-\text{median}_{n\in\left\{ 1,...N\right\} }\left(x_{n}^{d}\right)\right|,
\end{gathered}$
ρ
(
x
,
x
′
)
=
d
=
1
∑
D
​
M
A
D
(
x
d
)
​
x
d
−
x
′
d
​
​
,
M
A
D
(
x
d
)
=
median
n
∈
{
1
,
...
N
}
​
​
x
n
d
​
−
median
n
∈
{
1
,
...
N
}
​
(
x
n
d
​
)
​
,
​


поскольку модули отклонений признаков (а не квадраты отклонений) будут поощрять нахождение таких 
$\mathbf{x}'$
x
′
, которые бы отличались от 
$\mathbf{x}$
x
 в минимальном числе признаков, оставляя при этом оставшиеся признаки такими, какими они были, что упрощает интерпретируемость. Нормировка на 
$MAD\left(x^{d}\right)$
M
A
D
(
x
d
)
 (mean absolute deviation) приводит признаки к одинаковому масштабу, делая их равнозначными при сравнении. Хотя можно использовать и 
другие методы нормализации признаков
.


В 
[3]
 контрфактические объяснения предлагается находить, накладывая дополнительные штрафы:






за число отличающихся признаков в 
$\mathbf{x}$
x
 и 
$\mathbf{x}'$
x
′
 (чтобы упростить интерпретацию);






за несогласованность 
$\mathbf{x}'$
x
′
 с обучающей выборкой (по расстоянию от 
$\mathbf{x}'$
x
′
 до ближайшего соседа из обучающей выборки).








Более детально ознакомиться с контрафактическими объяснениями вы можете в 
[4]
.


Литература
​






Wachter S., Mittelstadt B., Russell C. Counterfactual explanations without opening the black box: Automated decisions and the GDPR //Harv. JL & Tech. – 2017. – Т. 31. – С. 841.






Wikipedia: Karush–Kuhn–Tucker conditions.






Dandl S. et al. Multi-objective counterfactual explanations //International conference on parallel problem solving from nature. – Cham : Springer International Publishing, 2020. – С. 448-469.






Molnar C. Interpretable machine learning. – Lulu. com, 2020: Counterfactual Explanations.




Предыдущая страница
Зависимость прогноза от признаков
Следующая страница
Влияние обучающих объектов
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.

