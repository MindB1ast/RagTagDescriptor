





Ансамбли моделей | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Ансамбли моделей
Математическое обоснование ансамблей
Простая агрегация в ансамблях
Методы построения базовых моделей
Настройка на разных фрагментах обучающей выборки
Ансамбли рандомизированных деревьев
Стэкинг
Дополнительная литература
Вопросы
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Ансамбли моделей
Ансамбли моделей
Содержание этой страницы
Ансамбли моделей


Идея
​


Ансамбли моделей
 (model ensembles), называемые также 
композициями алгоритмов
, строят прогноз, используя не одну модель 
$f(\mathbf{x})$
f
(
x
)
, а совокупность 
базовых моделей
 (base learners) 
$f_1(\mathbf{x}),...f_M(\mathbf{x})$
f
1
​
(
x
)
,
...
f
M
​
(
x
)
 и 
агрегирующую мета-модель
 (meta-model) 
$G(\cdot)$
G
(
⋅
)
, которая агрегирует прогнозы базовых моделей:


$\widehat{y}(\mathbf{x})=G(f_{1}(\mathbf{x}),...f_{M}(\mathbf{x}))$
y
​
(
x
)
=
G
(
f
1
​
(
x
)
,
...
f
M
​
(
x
))


Далее рассмотрим проблемы, которые могут успешно решаться с помощью ансамблей моделей.


Борьба с переобучением
​


Ансамбли позволяют бороться с  
переобучением
 (overfitting) базовых моделей под обучающую выборку.




Используя ансамбль, мы надеемся, что одни модели будут недооценивать целевую переменную, другие - переоценивать, в результате чего ошибки разных моделей взаимно скомпенсируются, и мы получим более точный итоговый прогноз.




Агрегирующей моделью 
$G(\cdot)$
G
(
⋅
)
 в этом случае выступает простая функция, такая как усреднение прогнозов базовых моделей.




[IMAGE]


Борьба с недообучением
​


Также ансамбли позволяют бороться с 
недообучением
 (undefitting) базовых моделей, поскольку использование сложной агрегирующей модели 
$G(\cdot)$
G
(
⋅
)
 позволяет внести дополнительную гибкость в процесс построения прогнозов.


Рассмотрим пример классификации, представленный на рисунке ниже. Как видим, данные линейно неразделимы, поэтому первый линейный классификатор размечает лишь часть объектов корректно, аналогично и второй классификатор. Если же объединить прогнозы двух классификаторов по правилу логического AND, то есть назначать красный класс лишь в случаях, когда оба классификатора предсказывают красный класс, то получим безошибочную классификацию, выделенную тёмно-синим на рисунке:


[IMAGE]


Повышение устойчивости
​


Также ансамбли позволяют уменьшить риски, связанные с той или иной стратегией моделирования. У каждой модели есть свои предположения о данных, которые в реальности будут лишь ограниченно выполняться и приводить к систематическому смещению. Использование не одной, а сразу нескольких моделей, использующих разные предположения о распределении данных, позволяет уменьшить несоответствие итоговой модели реальному распределению. 
Поэтому рекомендуется использовать в ансамбле модели разных классов
 - решающие деревья, линейные модели и метрические методы.


Аналогия с инвестициями
Один из основных принципов инвестирования заключается в диверсификации рисков ("не складывать все яйца в одну корзину"), состоящий в том, что инвестиционный портфель должен состоять из разнородных активов. Даже если один из активов упадёт в цене, совокупный портфель подешевеет не сильно, поскольку будет включать в себя различные активы.


Разные типы данных


Необходимость использования ансамблей может вытекать из свойств самой задачи. Например, при многоклассовой классификации, когда используется 
набор бинарных классификаторов
. Или когда уже построены отдельные базовые модели (например, идентификаторы человека по голосу, по лицу, по отпечатку пальцев), и мы хотим уточнить итоговый прогноз, учитывая мнения всех моделей.
Предыдущая страница
Ансамбли моделей
Следующая страница
Математическое обоснование ансамблей
Идея
Борьба с переобучением
Борьба с недообучением
Повышение устойчивости
© 2023-25 
Виктор Китов.
 
Новости проекта.

