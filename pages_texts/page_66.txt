





Вопросы для самопроверки | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Численные методы оптимизации
Метод градиентного спуска
Метод стохастического градиентного спуска
Мониторинг сходимости
Стохастический градиентный спуск с инерцией
Метод Ньютона
Вопросы
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Численная оптимизация
Вопросы
Вопросы для самопроверки




Почему веса в градиентных методах оптимизации смещают на антиградиент функции потерь?


В чём заключено преимущество метода стохастического градиентного спуска по сравнению с обычным методом градиентного спуска?


В чем мотивация использования стохастического градиентного спуска с инерцией? При каких условиях он может сходиться медленнее, чем метод градиентного спуска?


Как гиперпараметр 
$\alpha$
α
 влияет на степень экспоненциального сглаживания?


Перечислите преимущества и недостатки метода Ньютона по сравнению с методом градиентного спуска. Обоснуйте, почему он найдёт минимум квадратичной функции всего за одну итерацию.


Предыдущая страница
Метод Ньютона
Следующая страница
Оценка качества классификации
© 2023-25 
Виктор Китов.
 
Новости проекта.

