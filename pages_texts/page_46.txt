





Меры оценки качества регрессионных прогнозов | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Меры оценки качества регрессионных прогнозов
Конечные меры эффективности
Поточечный график
Вопросы
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Оценка качества регрессии
Меры оценки качества регрессионных прогнозов
Содержание этой страницы
Меры оценки качества регрессионных прогнозов


В задаче регрессии строится прогноз 
$\hat{y}(\mathbf{x})$
y
^
​
(
x
)
 вещественной целевой переменной 
$y$
y
.


О качестве регрессионных прогнозов судят по ошибкам модели на объектах отдельной 
валидационной выборки
.


$\varepsilon_n=\hat{y}(\mathbf{x}_n)-y_n,\quad n=1,2,...N$
ε
n
​
=
y
^
​
(
x
n
​
)
−
y
n
​
,
n
=
1
,
2
,
...
N


Несмещённая оценка качества
Напомним, что оценивать качество работы модели необходимо на данных, которые 
модель увидела впервые
, а не на тех данных, на которых настраивались параметры модели. Иначе мы получим слишком оптимистичные ошибки.
Причём данные для оценки не могут быть в валидационной выборке, если она  использовалась для подбора гиперпараметров, поскольку в этом случае модель уже использовала эти данные! Для несмещённой оценки качества в этом случае необходима третья 
независимая выборка
.


Ниже будут приведены популярные функции оценки качества регрессионных прогнозов. Но важно помнить, что итоговый выбор меры качества должен как можно точнее оценивать 
реальные потери заказчика от ошибок прогнозирования
 (например, в рублях), поскольку именно ради минимизации этих потерь модель машинного обучения и внедряется!


Mean squared error (MSE)
​


Среднеквадратичная ошибка
 (mean squared error, MSE) используется как для настройки параметров модели, так и для оценки её качества на новых данных, и считается по формуле:


$\text{MSE}=\frac{1}{N}\sum_{n=1}^N (\hat{y}(\mathbf{x}_n)-y_n)^2$
MSE
=
N
1
​
n
=
1
∑
N
​
(
y
^
​
(
x
n
​
)
−
y
n
​
)
2


Коэффициент детерминации
​


Коэффициент детерминации 
$R^2$
R
2
 по сути определяется также среднеквадратичной ошибкой и вычисляется по формуле:


$R^2 = 1 - \frac{\frac{1}{N}\sum_{n=1}^N (\hat{y}(\mathbf{x}_n)-y_n)^2}{\frac{1}{N}\sum_{n=1}^N (y_n-\overline{y})^2}$
R
2
=
1
−
N
1
​
∑
n
=
1
N
​
(
y
n
​
−
y
​
)
2
N
1
​
∑
n
=
1
N
​
(
y
^
​
(
x
n
​
)
−
y
n
​
)
2
​


Он принимает значения от 
$-\infty$
−
∞
 до 1. Чем он выше, тем прогноз в среднем лучше по сравнению с прогнозированием константой, в качестве которой берется средний отклик. Значение 1 соответствует идеально точным прогнозам, а значение 0 - прогнозам, по качеству неотличимым от прогнозирования средним значением.


Root mean squared error (RMSE)
​


Корень из среднеквадратичной ошибки
 (root mean squared error (RMSE)) вычисляется по формуле:


$\text{RMSE}=\sqrt{\text{MSE}}=\sqrt{\frac{1}{N}\sum_{n=1}^N (\hat{y}(\mathbf{x}_n)-y_n)^2}$
RMSE
=
MSE
​
=
N
1
​
n
=
1
∑
N
​
(
y
^
​
(
x
n
​
)
−
y
n
​
)
2
​


и её рекомендуется использовать вместо MSE, поскольку она будет измерять ошибку в той же размерности, в которой строится прогноз. Например, если предсказывается сколько клиент потратит на сервис в рублях, то RMSE будет измерять погрешность также в рублях, в то время как MSE будет измерять погрешность в рублях в квадрате (руб
2
) и будет несравнимой напрямую со значением прогноза.


Mean absolute error (MAE)
​


Средний модуль ошибки
 (mean absolute error, MAE) вычисляется по формуле:


$\text{MAE} = \frac{1}{N}\sum_{n=1}^N \vert \hat{y}(\mathbf{x}_n)-y_n \vert$
MAE
=
N
1
​
n
=
1
∑
N
​
∣
y
^
​
(
x
n
​
)
−
y
n
​
∣


MAE измеряется в той же размерности, что и прогнозируемая величина. По сравнению с RMSE, MAE обладает преимуществом, что её значение меньше подвержено влиянию отдельных нетипичных объектов, на которых мы получили очень большую ошибку прогноза.


MSE и RMSE будут учитывать 
не саму величину ошибки, а её квадрат
, что приведёт к завышенному влиянию на них наблюдений-выбросов.


Доля плохо предсказанных объектов
​


Чтобы 
сосредоточить внимание на плохо спрогнозированных объектах
, можно вычислять долю объектов, на которых ошибка оказалась выше определённого порога 
$h>0$
h
>
0
:


$\text{BadFreq} = \frac{1}{N}\sum_{n=1}^N \mathbb{I} \{ \vert \hat{y}(\mathbf{x}_n)-y_n \vert > h \}$
BadFreq
=
N
1
​
n
=
1
∑
N
​
I
{
∣
y
^
​
(
x
n
​
)
−
y
n
​
∣
>
h
}


Эта мера полезна для контроля доли ситуаций, в которых модель дала совсем неудовлетворительный прогноз.


Средняя относительная ошибка
​


Часто важно не абсолютное значение ошибки, а относительное. Например, при прогнозировании спроса на редко покупаемые товары, такие как автомобили, ошибка на 1,2,3 может оказаться существенной. Но эта же величина ошибки будет несущественной, если речь идёт о часто покупаемых товарах, таких как молоко и хлеб, поскольку оцениваемая величина для магазина измеряется в тысячах. Для этого усредняют не абсолютные, а относительные значения ошибки, как показано ниже.


Макроусреднённая относительная ошибка
​


MAPE
 (mean absolute percentage error) вычисляет 
макроусреднённую
 (macro averaged) относительную ошибку по формуле:


$\text{MAPE} = \frac{1}{N}\sum_{n=1}^N \frac{ \vert \hat{y}(\mathbf{x}_n)-y_n \vert } {|y_n|}$
MAPE
=
N
1
​
n
=
1
∑
N
​
∣
y
n
​
∣
∣
y
^
​
(
x
n
​
)
−
y
n
​
∣
​


Если в качестве откликов возможны нулевые значения 
$y_n$
y
n
​
, то, чтобы не делить на ноль, можно штрафовать прогнозы нуля большой, но фиксированной константой, либо нормировать в этих случаях на небольшую положительную константу 
$a \sim 0.1$
a
∼
0.1
:


$\text{MAPE'} = \frac{1}{N}\sum_{n=1}^N \frac{ \vert \hat{y}(\mathbf{x}_n)-y_n \vert } {\max\{|y_n|,a\}}$
MAPE’
=
N
1
​
n
=
1
∑
N
​
max
{
∣
y
n
​
∣
,
a
}
∣
y
^
​
(
x
n
​
)
−
y
n
​
∣
​


Микроусреднённая относительная ошибка
​


Мера 
WAPE
 (weighted average percentage error) вычисляется как 
микроусреднение
 относительных ошибок (micro averaging) по формуле:


$\text{WAPE} = \frac{1}{N} \frac{\sum_{n=1}^N \vert \hat{y}(\mathbf{x}_n)-y_n \vert } {\sum_{n=1}^N|y_n|}$
WAPE
=
N
1
​
∑
n
=
1
N
​
∣
y
n
​
∣
∑
n
=
1
N
​
∣
y
^
​
(
x
n
​
)
−
y
n
​
∣
​


Такая мера ошибки полезна при прогнозировании спроса на товары, которые покупаются редко (т.е. часто 
$y_n=0$
y
n
​
=
0
).


Задача
Минимизация MSE будет эквивалентна оптимизации каких из вышеприведённых критериев? Почему?


Мы привели самые популярные способы оценки качества регрессии. Оценке качества классификации будет посвящён 
отдельный раздел учебника
. Вы также можете ознакомиться с методами оценки качества регрессии и классификации в учебнике ШАД 
[1]
 и учебнике А. Г. Дьяконова 
[2]
.


Чтобы понять, насколько высокий результат обеспечивает наша модель необходимо сравнить значение критерия для выбранной модели и 
общепринятых моделей, используемых в данной предметной области
, называемых бейзлайнами (baselines).


Оптимизация по целевым мерам качества


Оптимизация параметров модели
​


Меры MAE и WAPE также можно оптимизировать напрямую, но для этого придётся в качестве потерь задавать модули, а не квадраты ошибок, и использовать для этого уже 
численную оптимизацию
, реализованную в большинстве пакетов машинного обучения.


Для минимизации MAPE и MAPE' можно минимизировать модули ошибок, где каждый объект учитывается взвешенным образом с весом 
$\frac{1}{|y_n|}$
∣
y
n
​
∣
1
​
 и 
$\frac{1}{\max\{|y_n|, a\}}$
m
a
x
{
∣
y
n
​
∣
,
a
}
1
​
 соответственно.


подсказка
Регрессионные прогнозы лучше оценивать не по стандартной мере качества, а по 
целевой мере потерь
, которая максимально близко соответствует реальным потерям (например, в рублях) при тех или иных ошибках прогнозирования.


Оптимизация гиперпараметров модели
​


Гиперпараметры модели
 также рекомендуется подбирать, оптимизируя 
целевую меру потерь
. Это легко сделать, поскольку чаще всего гиперпараметры подбираются перебором по сетке или другим безградиентным методом оптимизации. Поэтому целевая мера не обязательно должна быть дифференцируемой.


Литература
​




Учебник ШАД: метрики классификации и регрессии.


Дьяконов А.Г. Машинное обучение и анализ данных: функции ошибки в задачах регрессии.


Предыдущая страница
Оценка качества регрессии
Следующая страница
Конечные меры эффективности
Mean squared error (MSE)
Коэффициент детерминации
Root mean squared error (RMSE)
Mean absolute error (MAE)
Доля плохо предсказанных объектов
Средняя относительная ошибка
Макроусреднённая относительная ошибка
Микроусреднённая относительная ошибка
Оптимизация параметров модели
Оптимизация гиперпараметров модели
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.

