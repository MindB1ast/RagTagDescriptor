





Бустинг | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Бустинг
Сравнение бустинга с другими ансамблями моделей
Алгоритм AdaBoost
Градиентный бустинг
Алгоритм градиентного бустинга
Улучшения градиентного бустинга
Иллюстрация работы
Градиентный бустинг второго порядка
Популярные реализации
Точность градиентного бустинга
Дополнительная литература
Вопросы
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Бустинг
Бустинг
Содержание этой страницы
Бустинг


Алгоритм бустинга
 (boosting 
[1]
) строит прогноз в виде ансамбля (композиции) базовых моделей:


$f_0(\mathbf{x}),f_1(\mathbf{x}),f_2(\mathbf{x}),...f_M(\mathbf{x})$
f
0
​
(
x
)
,
f
1
​
(
x
)
,
f
2
​
(
x
)
,
...
f
M
​
(
x
)


Агрегирующая модель, на базе которой строится итоговый прогноз, представляет собой линейную комбинацию базовых моделей с настраиваемыми весами:


$G_M(\mathbf{x})=f_0(\mathbf{x})+c_1 f_1(\mathbf{x})+c_2 f_2(\mathbf{x})+...+c_M f_M(\mathbf{x})$
G
M
​
(
x
)
=
f
0
​
(
x
)
+
c
1
​
f
1
​
(
x
)
+
c
2
​
f
2
​
(
x
)
+
...
+
c
M
​
f
M
​
(
x
)


Все базовые модели, кроме начального приближения 
$f_0(\mathbf{x})$
f
0
​
(
x
)
, берутся из одного семейства.




Как правило, начальное приближение выбирается тождественным нулём или настраиваемой константой, а остальные модели - решающими деревьями небольшой глубины.




Типы решаемых задач
​


Смысл 
$G_M(\mathbf{x})$
G
M
​
(
x
)
 меняется в зависимости от решаемой задачи:






для 
регрессии
 
$G_M(\mathbf{x})$
G
M
​
(
x
)
 предсказывает регрессионный прогноз:


$\widehat{y}(\mathbf{x})=G_{M}(\mathbf{x})$
y
​
(
x
)
=
G
M
​
(
x
)






для 
бинарной классификации
 
$G_M(\mathbf{x})$
G
M
​
(
x
)
 представляет собой рейтинг положительного класса по сравнению с отрицательным. Итоговый прогноз 
$y\in\{-1,+1\}$
y
∈
{
−
1
,
+
1
}
 строится как функция взятия знака 
$G_M(\mathbf{x})$
G
M
​
(
x
)
 (+1 для положительных и -1 для отрицательных аргументов):


$\widehat{y}(\mathbf{x})=\text{sign}( G_{M}(\mathbf{x}) )$
y
​
(
x
)
=
sign
(
G
M
​
(
x
))






в 
многоклассовой классификации
 на 
$C$
C
 классов 
$G_M(\mathbf{x})=[G_M^1(\mathbf{x}),...G_M^C(\mathbf{x})]$
G
M
​
(
x
)
=
[
G
M
1
​
(
x
)
,
...
G
M
C
​
(
x
)]
 представляет собой вектор рейтингов для каждого класса, а прогноз строится по принципу назначения класса, обладающего максимальным рейтингом:


$\hat{y}=\arg\max_c \{G_{M}^1(\mathbf{x}),...G_{M}^C(\mathbf{x})\}$
y
^
​
=
ar
g
c
max
​
{
G
M
1
​
(
x
)
,
...
G
M
C
​
(
x
)}






Принцип построения ансамбля
​


Базовые модели, кроме начального приближения 
$f_0(\mathbf{x})$
f
0
​
(
x
)
, выбираются из одного класса, но неравнозначны между собой, поскольку 
настраиваются последовательно одна за другой
:






$f_0(\mathbf{x})$
f
0
​
(
x
)
 настраивается приближать целевую величину 
$y$
y
;






$c_1 f_1(\mathbf{x})$
c
1
​
f
1
​
(
x
)
 учится исправлять ошибки 
$G_0(\mathbf{x})=f_0(\mathbf{x})$
G
0
​
(
x
)
=
f
0
​
(
x
)
;






$c_2 f_2(\mathbf{x})$
c
2
​
f
2
​
(
x
)
 учится исправлять ошибки 
$G_1(\mathbf{x})=f_0(\mathbf{x})+c_1 f_1(\mathbf{x})$
G
1
​
(
x
)
=
f
0
​
(
x
)
+
c
1
​
f
1
​
(
x
)
;






$\cdots$
⋯






$c_M f_M(\mathbf{x})$
c
M
​
f
M
​
(
x
)
 учится исправлять ошибки 
$G_{M-1}(\mathbf{x})=f_0(\mathbf{x})+c_1 f_1(\mathbf{x})+...+c_{M-1}f_{M-1}(\mathbf{x})$
G
M
−
1
​
(
x
)
=
f
0
​
(
x
)
+
c
1
​
f
1
​
(
x
)
+
...
+
c
M
−
1
​
f
M
−
1
​
(
x
)
.






Более формально, решаются следующие задачи:






Настраиваем начальное приближение


$f_{0}(\mathbf{x})=\arg\min_{f}\sum_{n=1}^{N}\mathcal{L}(f(\mathbf{x}_{n}),y_{n})$
f
0
​
(
x
)
=
ar
g
f
min
​
n
=
1
∑
N
​
L
(
f
(
x
n
​
)
,
y
n
​
)






Для 
$m=1,2,...M$
m
=
1
,
2
,
...
M
:


находим коррекцию:


$(c_{m},f_{m}):=\arg\min_{f,c}\sum_{n=1}^{N}\mathcal{L}(G_{m-1}(\mathbf{x}_{n})+cf(\mathbf{x}_{n}),\,y_{n})$
(
c
m
​
,
f
m
​
)
:=
ar
g
f
,
c
min
​
n
=
1
∑
N
​
L
(
G
m
−
1
​
(
x
n
​
)
+
c
f
(
x
n
​
)
,
y
n
​
)


обновляем ансамбль:


$G_{m}(\mathbf{x}):=G_{m-1}(\mathbf{x})+c_{m}f_{m}(\mathbf{x})$
G
m
​
(
x
)
:=
G
m
−
1
​
(
x
)
+
c
m
​
f
m
​
(
x
)






Возвращаем 
$G_M(\mathbf{x})$
G
M
​
(
x
)
.






Описанная процедура также известна как forward stagewise additive modeling 
[2]
.




На шаге 2 часто коэффициент 
$c_m$
c
m
​
 не настраивается, а берётся малой константой, называемой 
шаг обучения
 (learning rate).




Особенности реализации
​


Для эффективности применения ансамбля усреднение должно происходить по многим базовым моделям, поэтому в бустинге их число измеряется сотнями и даже тысячами.


Для того, чтобы строить ансамбль из большого числа моделей, базовые модели 
не должны быть слишком точными
, чтобы оставлять пространство для дальнейших уточнений последующими уточняющими моделями. Для этого, в частности, используются следующие принципы:






Начальное приближение полагается тождественному нулю 
$f_0(\mathbf{x})\equiv 0$
f
0
​
(
x
)
≡
0
 либо находится как наилучший константный прогноз 
$f_0(\mathbf{x})\equiv c\in \mathbb{R}$
f
0
​
(
x
)
≡
c
∈
R
.






Последующие базовые модели 
$f_1(\mathbf{x}),...f_M(\mathbf{x})$
f
1
​
(
x
)
,
...
f
M
​
(
x
)
 берутся простыми и неточными. Чаще всего это 
решающие деревья
 небольшой глубины (~1-5) или с ограничением на максимальное число листьев (~2-32).


Какую модель получим, если будем строить бустинг над линейными моделями?
Комбинируя с весами линейные модели, мы снова получим линейную модель!
Поэтому бустинг над линейными моделями не используется.
Хотя можно взять линейную модель в качестве начального приближения,
а последующие базовые модели брать уже из другого семейства.






На каждой итерации настраивать модель 
$f_m(\mathbf{x})$
f
m
​
(
x
)
 и коэффициент 
$c_m$
c
m
​
 при ней можно неточно. Часто 
$c_m$
c
m
​
 просто берут малой константой, так как настройка 
$f_m(\mathbf{x})$
f
m
​
(
x
)
 уже настраивает общий масштаб изменения.






Литература
​






Wikipedia: boosting (machine learning).






Hastie T., Tibshirani R., Friedman J. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. – Springer Science & Business Media, 2009.




Предыдущая страница
Бустинг
Следующая страница
Сравнение бустинга с другими ансамблями моделей
Типы решаемых задач
Принцип построения ансамбля
Особенности реализации
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.

