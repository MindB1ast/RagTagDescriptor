





Обработка пропущенных значений | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Решающие деревья
Особенности прогнозов решающего дерева
Настройка решающего дерева
Функции неопределённости
Учёт пользовательской функции потерь
Обрезка решающих деревьев
Обработка пропущенных значений
Важность признаков
Анализ решающих деревьев
Обобщения решающих деревьев
Дополнительная литература
Вопросы
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Решающие деревья
Обработка пропущенных значений
Содержание этой страницы
Обработка пропущенных значений


Часто некоторые признаки в данных могут отсутствовать. Например, в медицинской диагностике пациент мог не проходить определённых обследований, при анализе анкет респондент мог не указать возраст, а при обработке данных домов может отсутствовать дата постройки.


Пропущенные значения можно заполнить одним из ранее изученных 
стандартных методов
. Однако специфика работы решающих деревьев позволяет обрабатывать пропуски по-особенному.


Если 
пропущенный признак присутствуют только в тестовых данных
 (но не в обучающих), то при проверке правила


$\text{признак} \le \text{порог}$
признак
≤
порог


объект можно направить в дочерний узел, содержащий больше объектов обучающей выборки, т.е. в априорно более вероятный.


Однако возможны разные стратегии, когда 
в обучающей выборке также присутствуют пропуски
.




В следующих двух способах предлагается настраивать дерево, используя только известные значения признаков.




Суррогатные разбиения
​


В классическом алгоритме CART 
[1]
 предлагалась процедура суррогатных разбиений (surrogate splits). Поскольку при 
выборе правила
 [признак
$\le$
≤
порог] перебираются все варианты признаков, то можно запомнить, какой другой признак обеспечивал наилучшее качество, а какой оказывался наилучшим на втором месте. Такой признак назовём суррогатным. При появлении пропуска в классическом дереве CART исходное правило заменяется на правило с суррогатным признаком (и соответствующим ему порогом). Если и суррогатный признак отсутствует, то применяется следующий суррогатный признак (уже третий по качеству) и т.д., пока мы не дойдёт до признака с известным значением.


Распределённая стратегия
​


Вместо того, чтобы направлять объект с пропущенным значением либо влево, либо вправо его можно направить все объекты с пропущенными значениями всегда в левый или правый дочерний узел, в зависимости от того, какой из способов приводит к большему уменьшению функции неопределённости на обучающей выборке.


Вместо того, чтобы направлять объекты с пропущенным признаком всегда влево или вправо, можно его направить одновременно и влево (получив прогноз 
$\hat{y}_{L}$
y
^
​
L
​
), и вправо (получив прогноз 
$\hat{y}_{R}$
y
^
​
R
​
), а в качестве итогового прогноза выдать


$\hat{y} = \frac{n_L}{n}\hat{y}_L + \frac{n_R}{n}\hat{y}_R,$
y
^
​
=
n
n
L
​
​
y
^
​
L
​
+
n
n
R
​
​
y
^
​
R
​
,


где 
$n$
n
 - число обучающих объектов, попавших в узел, в котором проверяется значение пропущенного признака, а 
$n_L$
n
L
​
 и 
$n_R$
n
R
​
 - количества обучающих объектов, спускающихся в левую и правую дочернюю вершину соответственно.




Представленные два способа опираются на предположение, что факт пропуска значения признака не влияет на его распределение. В реальности оно может быть не выполнено. Например, в анкете человек мог не указывать зарплату не потому что забыл, а потому что она аномальная малая или большая.


Далее будет описана стратегия, которая обрабатывает объекты с пропусками отдельно, обеспечивая учёт возможной специфики их распределения.




Отдельная обработка пропусков
​


При настройке решающего правила в каждом узле предлагается сравнить три стратегии по тому, какая из них приводит к наибольшему снижению 
функции неопределённости
:






когда все объекты с пропущенным значением идут влево, а с заполненным значением - вправо;






когда все объекты с пропуском идут влево;






когда все объекты с пропуском идут вправо.






Это замедляет настройку, зато по её итогам даёт чёткий алгоритм обработки пропущенных значений. Именно такая стратегия реализована в решающих деревьях библиотеки sklearn 
[2]
.


Литература
​




Breiman, L., Friedman, J., Olshen, R.A., & Stone, C.J. (1984). Classification and Regression Trees (1st ed.). Chapman and Hall/CRC.


Документация sklearn: missing values support.


Предыдущая страница
Обрезка решающих деревьев
Следующая страница
Важность признаков
Суррогатные разбиения
Распределённая стратегия
Отдельная обработка пропусков
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.

