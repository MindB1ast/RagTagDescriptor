





Выпуклость потерь | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Обучение с учителем
Настройка параметров модели
Выпуклость потерь
Регуляризация модели
Взвешенный учёт наблюдений
Связь с принципом максимального правдоподобия
Обобщающая способность
Оценка качества прогнозов
Этапы решения задачи машинного обучения
Обучение без учителя
Частичное обучение
Вопросы
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Основы машинного обучения
Выпуклость потерь
Содержание этой страницы
Выпуклость потерь


В машинном обучении приветствуется выбор 
выпуклых
 функций потерь (convex loss functions) от параметров (или весов) модели, т.е. таких функций, что


$L(a*\mathbf{w}+(1-a)\mathbf{w}')\le aL(\mathbf{w})+(1-a)L(\mathbf{w}')\quad \forall \mathbf{w},\mathbf{w}'\text{ и } a\in[0,1].$
L
(
a
∗
w
+
(
1
−
a
)
w
′
)
≤
a
L
(
w
)
+
(
1
−
a
)
L
(
w
′
)
∀
w
,
w
′
 
и
 
a
∈
[
0
,
1
]
.




Такие функции также называют 
выпуклыми вверх
, чтобы не путать с  
вогнутыми
 функциями (
выпуклыми вниз
), для которых выполнено неравенство в обратную сторону.




Неравенство выполнено для любых аргументов 
$\mathbf{w},\mathbf{w}'$
w
,
w
′
 из области определения функции, которое также должно быть выпуклым (т.е. если две точки принадлежат области определения, то и любая промежуточная точка на отрезке, их соединяющем, тоже принадлежит области определения функции). Геометрически определение выпуклой функции означает, что отрезок, соединяющий любые две точки на функции, нигде не может лежать ниже значений функции.


Пример выпуклой функции от одной переменной показан ниже:


[IMAGE]


Стоит отметить, что если потери на отдельном объекте 
$\mathcal{L}(f_{\mathbf{w}}(\mathbf{x}_{n}),y_{n})$
L
(
f
w
​
(
x
n
​
)
,
y
n
​
)
 выпуклы по 
$\mathbf{w}$
w
, то и потери по всей обучающей выборке (эмпирический риск) будут выпуклыми, т.к. усреднение выпуклых функций всегда будет тоже выпуклой функцией (докажите!).


Выпуклые функции удобны тем, что:




любой локальный минимум является 
глобальным
;


равенство нулю производной является не только необходимым, но и 
достаточным
 условием минимума.




Таким образом, найдя значение 
$\hat{\mathbf{w}}$
w
^
, в котором 
$\nabla L(\hat{\mathbf{w}})=0$
∇
L
(
w
^
)
=
0
, мы точно знаем, что это глобальный минимум.


Основные функции потерь машинного обучения для задач 
регрессии
 и 
классификации
 выпуклы.


Задача
Попробуйте доказать эти свойства. Для доказательства второго свойства пригодится использование другого критерия выпуклой функции, что она всегда лежит не ниже касательной, проведённой в любой точке.


Может ли у выпуклой функции не быть минимума?
Да, рассмотрите функцию 
$y=1/x$
y
=
1/
x
.


Может ли у выпуклой функции быть несколько минимумов?
Да, рассмотрите функцию 
$y=\max\{0,\vert x \vert-1\}$
y
=
max
{
0
,
∣
x
∣
−
1
}
.


Более полную информацию о выпуклых функциях вы можете прочитать в 
[1]
 и 
[2]
.


Литература
​






Wikipedia: convex function.






Bertsekas D. Convex optimization theory. – Athena Scientific, 2009. 




Предыдущая страница
Настройка параметров модели
Следующая страница
Регуляризация модели
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.

