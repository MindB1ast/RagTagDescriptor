





Метрические методы | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Метрические методы
Метод ближайших центроидов
Метод K ближайших соседей
Анализ метода K ближайших соседей
Обобщение метода K ближайших соседей с весами
Веса в метрических методах
Локально-постоянная регрессия
Функции расстояния
Вопросы
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Метрические методы прогнозирования
Метрические методы
Содержание этой страницы
Метрические методы


Метрические методы прогнозирования
 - это методы, прогнозы которых определяются только расстояниями между целевым объектом, для которого строится прогноз, и некоторыми другими объектами 
$z_1,...z_K$
z
1
​
,
...
z
K
​
, полученными из обучающей выборки. Таким образом, прогноз строится по общей формуле:


$\hat{y}(\mathbf{x}) = G(\rho(\mathbf{x},\mathbf{z}_1),y_1, \rho(\mathbf{x},\mathbf{z}_2),y_2, ... \rho(\mathbf{x},\mathbf{z}_K),y_K),$
y
^
​
(
x
)
=
G
(
ρ
(
x
,
z
1
​
)
,
y
1
​
,
ρ
(
x
,
z
2
​
)
,
y
2
​
,
...
ρ
(
x
,
z
K
​
)
,
y
K
​
)
,


где 
$\rho(\mathbf{x},\mathbf{z})$
ρ
(
x
,
z
)
 - функция, вычисляющая расстояние (измеряющее степень непохожести) между объектами 
$\mathbf{x}$
x
 и 
$\mathbf{z}$
z
, а 
$y_1,y_2,...y_K$
y
1
​
,
y
2
​
,
...
y
K
​
 - значения откликов на объектах 
$\mathbf{z}_1,\mathbf{z}_2,...\mathbf{z}_K$
z
1
​
,
z
2
​
,
...
z
K
​
.




По смыслу прогнозная функция 
$G$
G
 предсказывает отклик агрегацией откликов среди некоторых обучающих объектов, максимально похожих на целевой объект.




Базовое предположение метода
Ключевое предположение метрического метода - близким объектам соответствуют близкие отклики. Если отклик действительно определяется выбранными признаками и зависит от них непрерывным образом, то это предположение весьма естественно.


Недостатком метода является 
сложный способ вычисления прогноза
, если используется большой набор референсных объектов 
$\mathbf{z}_1,\mathbf{z}_2,...\mathbf{z}_K$
z
1
​
,
z
2
​
,
...
z
K
​
.


Достоинством метода является его 
обобщаемость на любую функцию расстояния
. Варьируя способ вычисления расстояния между объектами 
$\rho(\mathbf{x},\mathbf{z})$
ρ
(
x
,
z
)
, мы будем получать различные версии одного и того же метода!


Рассмотрим для примера две задачи с одинаковыми входными данными:






по фото человека определить, кто именно на нём изображён (независимо от позы);






по фото человека определить его позу (независимо от того, кого фотографировали).






Эти две противоположные во многом задачи можно решать одним и тем же методом, лишь варьируя функцию расстояния!


Более того, функцию расстояния можно параметризовать некоторым вектором параметров 
$\mathbf{\theta}$
θ
:


$\rho(\mathbf{x},\mathbf{z})\to\rho_\mathbf{\theta}(\mathbf{x},\mathbf{z}),$
ρ
(
x
,
z
)
→
ρ
θ
​
(
x
,
z
)
,


а дальше настраивать вид расстояния, который больше всего подходит под нашу задачу, что известно как 
обучение расстояния
 (metric learning). Существуют различные подходы обучения расстояний и даже специализированная python-бибилотека, которая их реализует 
[1]
.


Применимость методов
Обычные методы машинного обучения используют признаковое описание объектов в виде вектора признаков 
фиксированного размера
. Если сами объекты при этом могут иметь произвольный размер (например, тексты могут иметь произвольную длину, графы - произвольное число вершин и рёбер), то кодирование подобных объектов векторами фиксированного размера будет приводить к потере информации, что будет снижать точность прогнозов.
Если же мы определим функцию расстояния над 
исходным представлением объектов
 (а не сокращенным в виде вектора признаков), то сможем избежать потери информации, поскольку прогноз будет зависеть только от попарных расстояний между объектами. Например, мы можем определить расстояние между строками произвольной длины как минимальное число вставок/удалений и замен одного символа другим, необходимых для перевода одной строки в другую - так называемое 
редакторское расстояние
 или 
расстояние Левенштейна
 (edit distance, Levenstein distance - 
[2]
, 
[3]
). Его можно определить и для графов произвольного размера, а также для других типов данных.


Литература
​






Документация metric-learn.






Wikipedia: Levenshtein distance.






Левенштейн В. И. Двоичные коды с исправлением выпадений, вставок и замещений символов //Доклады Академии наук. – Российская академия наук, 1965. – Т. 163. – №. 4. – С. 845-848.




Предыдущая страница
Метрические методы прогнозирования
Следующая страница
Метод ближайших центроидов
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.

