





Эквивалентное определение AUC | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Базовые меры качества многоклассовой классификации
Специальные меры качества для бинарной классификации
Обобщение бинарных мер качества на многоклассовый случай
ROC-кривая
Лучший классификатор на ROC кривой
Эквивалентное определение AUC
Контроль качества предсказания вероятностей
Дополнительная литература
Вопросы
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Оценка качества классификации
Эквивалентное определение AUC
Содержание этой страницы
Эквивалентное определение AUC


Каждой точке на 
ROC-кривой
 будет соответствовать классификатор 
$\hat{y}(\mathbf{x}) = \text{sign}(g(\mathbf{x})-\alpha)$
y
^
​
(
x
)
=
sign
(
g
(
x
)
−
α
)
 со своим выбором 
$\alpha$
α
. Агрегированной мерой этого семейства классификаторов (при всевозможных значениях 
$\alpha$
α
) выступает 
площадь под ROC-кривой
 (area under curve, AUC).


Идеальный случай
​


Максимальное значение величины AUC=1 и, как следует из 
алгоритма построения ROC-кривой
, оно соответствует ROC-кривой, идущей в осях (FPR,TPR) из (0,0) в (0,1), а затем из (0,1) в (1,1). Классификатор в этом случае идеально упорядочит объекты так, что все объекты с низкими 
$g(\mathbf{x})$
g
(
x
)
 будут принадлежать отрицательному классу, а все объекты с высоким 
$g(\mathbf{x})$
g
(
x
)
 будут принадлежать положительному классу, как показано на рисунке:


[IMAGE]


Для безошибочной классификации достаточно лишь выбрать порог 
$\alpha$
α
, способный безошибочно разделять классы.


Общий случай
​


В общем случае 
$AUC\in [0,1]$
A
U
C
∈
[
0
,
1
]
 и мера AUC оценивает, насколько сильно ROC-кривая выпукла вверх, что соответствует качеству упорядочивания объектов вдоль оси 
$g(\mathbf{x})$
g
(
x
)
, когда объектам с более низкими 
$g(\mathbf{x})$
g
(
x
)
 соответствуют отрицательные классы, а с более высокими 
$g(\mathbf{x})$
g
(
x
)
 - положительные классы. Сформулируем это утверждение более формально.


AUC как качество упорядочивания объектов
​


Предположим для простоты, что каждому объекту соответствует своё 
уникальное
 значение относительной дискриминантной функции 
$g(\mathbf{x})$
g
(
x
)
.


Рассмотрим пару объектов 
$(\mathbf{x}_{i},y_{i}=-1)$
(
x
i
​
,
y
i
​
=
−
1
)
 и 
$(\mathbf{x}_{j},y_{j}=+1)$
(
x
j
​
,
y
j
​
=
+
1
)
 отрицательного и положительного классов. Такую пару будем называть:






верно упорядоченной
, если 
$g(\mathbf{x}_{i})<g(\mathbf{x}_{j})$
g
(
x
i
​
)
<
g
(
x
j
​
)
;






неверно упорядоченной
, если 
$g(\mathbf{x}_{i})>g(\mathbf{x}_{j})$
g
(
x
i
​
)
>
g
(
x
j
​
)
.






Если 
$N_+,N_-$
N
+
​
,
N
−
​
 - общее число объектов положительного и отрицательного класса, то общее количество пар объектов отрицательного и положительного классов будет 
$N_+\cdot N_-$
N
+
​
⋅
N
−
​
.


Справедливо следующее утверждение:




Площадь под ROC-кривой (AUC) равна доле верно упорядоченных пар объектов выборки:


$AUC=\frac{\sum_{(i,j):y_{i}=-1,y_{j}=1}\mathbb{I}\left[g(\mathbf{x}_{j})>g(\mathbf{x}_{i})\right]}{N_-\cdot N_+}$
A
U
C
=
N
−
​
⋅
N
+
​
∑
(
i
,
j
)
:
y
i
​
=
−
1
,
y
j
​
=
1
​
I
[
g
(
x
j
​
)
>
g
(
x
i
​
)
]
​




Доказательство
:  пусть 
$\mathbf{x}_{(1)},...\mathbf{x}_{(N)}$
x
(
1
)
​
,
...
x
(
N
)
​
 - объекты, упорядоченные по рейтингу:


$g\left(\mathbf{x}_{(1)}\right)<g\left(\mathbf{x}_{(2)}\right)<...<g\left(\mathbf{x}_{(N)}\right)$
g
(
x
(
1
)
​
)
<
g
(
x
(
2
)
​
)
<
...
<
g
(
x
(
N
)
​
)


Каждой точке на ROC-кривой будет соответствовать классификатор:


$\widehat{y}_{k}(\mathbf{x})=sign\left(g(\mathbf{x})\ge g(\mathbf{x}_{(k)})\right)$
y
​
k
​
(
x
)
=
s
i
g
n
(
g
(
x
)
≥
g
(
x
(
k
)
​
)
)


с показателями качества


$TPR_{k}=\frac{\sum_{n=k}^{N}\mathbb{I}[y_{(n)}=+1]}{N_{+}},~FPR_{k}=\frac{\sum_{n=k}^{N}\mathbb{I}[y_{(n)}=-1]}{N_{-}}$
TP
R
k
​
=
N
+
​
∑
n
=
k
N
​
I
[
y
(
n
)
​
=
+
1
]
​
,
 
FP
R
k
​
=
N
−
​
∑
n
=
k
N
​
I
[
y
(
n
)
​
=
−
1
]
​


Обратим внимание, что 
$TPR_{k},FRP_{k}$
TP
R
k
​
,
FR
P
k
​
 не возрастают по 
$k$
k
. Случаю 
$k=N$
k
=
N
 будет соответствовать первая точка на ROC-кривой, а случаю 
$k=1$
k
=
1
 - последняя.


Проинтегрируем справа налево площадь под ROC-кривой по 
формуле трапеций
:


$AUC=\sum_{k=1}^{N-1}\frac{TPR_{k+1}+TPR_{k}}{2}\left(FPR_{k}-FPR_{k+1}\right)\\=\sum_{k=1}^{N-1}\frac{\sum_{n=k+1}^{N}\mathbb{I}[y_{(n)}=+1]+\sum_{n=k}^{N}\mathbb{I}[y_{(n)}=+1]}{2N_{+}}\times\\\times\left(\sum_{n=k}^{N}\mathbb{I}[y_{(n)}=-1]-\sum_{n=k+1}^{N}\mathbb{I}[y_{(n)}=-1]\right)=\\=\sum_{k=1}^{N-1}\frac{\sum_{n=k+1}^{N}\mathbb{I}[y_{(n)}=+1]+\frac{1}{2}\mathbb{I}[y_{(k)}=+1]}{N_{+}}\cdot\frac{\mathit{\mathbb{I}}[y_{(k)}=-1]}{N_{-}}\\=\frac{1}{N_{+}N_{-}}\sum_{k=1}^{N-1}\sum_{n=k+1}^{N}\mathbb{I}[y_{(n)}=+1]\mathbb{I}[y_{(k)}=-1]=\frac{1}{N_{+}N_{-}}\sum_{k<n}\mathbb{I}[y_{(k)}<y_{(n)}]$
A
U
C
=
k
=
1
∑
N
−
1
​
2
TP
R
k
+
1
​
+
TP
R
k
​
​
(
FP
R
k
​
−
FP
R
k
+
1
​
)
=
k
=
1
∑
N
−
1
​
2
N
+
​
∑
n
=
k
+
1
N
​
I
[
y
(
n
)
​
=
+
1
]
+
∑
n
=
k
N
​
I
[
y
(
n
)
​
=
+
1
]
​
×
×
(
n
=
k
∑
N
​
I
[
y
(
n
)
​
=
−
1
]
−
n
=
k
+
1
∑
N
​
I
[
y
(
n
)
​
=
−
1
]
)
=
=
k
=
1
∑
N
−
1
​
N
+
​
∑
n
=
k
+
1
N
​
I
[
y
(
n
)
​
=
+
1
]
+
2
1
​
I
[
y
(
k
)
​
=
+
1
]
​
⋅
N
−
​
I
[
y
(
k
)
​
=
−
1
]
​
=
N
+
​
N
−
​
1
​
k
=
1
∑
N
−
1
​
n
=
k
+
1
∑
N
​
I
[
y
(
n
)
​
=
+
1
]
I
[
y
(
k
)
​
=
−
1
]
=
N
+
​
N
−
​
1
​
k
<
n
∑
​
I
[
y
(
k
)
​
<
y
(
n
)
​
]


Мы доказали, что 
площадь под ROC-кривой равна доле верно упорядоченных пар объектов
, в которых первый первый объект принадлежит отрицательному классу, а второй - положительному. Таким образом, мера 
AUC оценивает качество упорядочивания объектов
 вдоль значений относительной дискриминантной функции 
$g(\mathbf{x})$
g
(
x
)
.




Отсюда, в частности, следует, что величина AUC не будет изменяться при монотонно возрастающих преобразованиях относительной дискриминантной функции:


$g(x)\to F(g(x)), \text{где } F(\cdot) - \text{любая возрастающая функция.}$
g
(
x
)
→
F
(
g
(
x
))
,
где
 
F
(
⋅
)
−
любая
 
возрастающая
 
функция
.




Оптимизация AUC
​


Если AUC является конечным критерием качества, то разумно максимизировать именно её, а не другие меры качества. Для этого нужно применять 
численную оптимизацию
.


Сложность заключается в том, что поскольку AUC зависит от индикаторных функций:


$AUC=\frac{\sum_{(i,j):y_{i}=-1,y_{j}=1}\mathbb{I}\left[g(\mathbf{x}_{j})>g(\mathbf{x}_{i})\right]}{N_+\cdot N_-}$
A
U
C
=
N
+
​
⋅
N
−
​
∑
(
i
,
j
)
:
y
i
​
=
−
1
,
y
j
​
=
1
​
I
[
g
(
x
j
​
)
>
g
(
x
i
​
)
]
​


Поэтому она является является кусочно-постоянной, поэтому её нельзя оптимизировать градиентными методами оптимизации напрямую.


Зато мы можем приблизить каждый индикатор 
$\mathbb{I}\left[g(\mathbf{x}_{j})>g(\mathbf{x}_{i})\right]$
I
[
g
(
x
j
​
)
>
g
(
x
i
​
)
]
  сигмоидой 
$\sigma(\beta(g(\mathbf{x}_{j})-g(\mathbf{x}_{i})))$
σ
(
β
(
g
(
x
j
​
)
−
g
(
x
i
​
)))
, где 
$\sigma(u)=\frac{1}{1+e^{-u}}$
σ
(
u
)
=
1
+
e
−
u
1
​
 - сигмоидная функция (sigmoid), а 
$\beta>0$
β
>
0
 - гиперпараметр, выбираемый пользователем.


Оценка AUC при этом приближении будет иметь вид


$AUC \approx \frac{\sum_{(i,j):y_{i}=-1,y_{j}=1}\sigma(\beta(g(\mathbf{x}_{j})-g(\mathbf{x}_{i})))}{N_+\cdot N_-}$
A
U
C
≈
N
+
​
⋅
N
−
​
∑
(
i
,
j
)
:
y
i
​
=
−
1
,
y
j
​
=
1
​
σ
(
β
(
g
(
x
j
​
)
−
g
(
x
i
​
)))
​


Такая оценка уже будет дифференцируемой функцией, и её можно максимизировать напрямую 
градиентными методами
!




Чем 
$\beta$
β
 выше, тем точнее будет аппроксимация ступенчатой функции ценой более резких изменений производной и более нестабильного обучения.


Предыдущая страница
Лучший классификатор на ROC кривой
Следующая страница
Контроль качества предсказания вероятностей
Идеальный случай
Общий случай
AUC как качество упорядочивания объектов
Оптимизация AUC
© 2023-25 
Виктор Китов.
 
Новости проекта.

