





Интерпретация сложных моделей | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Интерпретация сложных моделей
Анализ ошибок модели
Прогнозы на типичных и нетипичных объектах
Влияние признаков на качество прогнозов
Значения Шепли
Локальное объяснение интерпретируемой моделью
Влияние фрагментов
Зависимость прогноза от признаков
Контрфактические объяснения
Влияние обучающих объектов
Вопросы
Заключение
Интерпретация сложных моделей
Интерпретация сложных моделей
Содержание этой страницы
Интерпретация сложных моделей


Если целью прогнозирования является построение максимально точных прогнозов, а не объяснение зависимости в простых терминах, то для этого используют 
сложные модели
 (black-box models), производящие большое число нелинейных операций над вектором признаков. Такие модели не обладают интерпретируемостью напрямую, но можно применить разнообразные опосредованные приёмы для их анализа и объяснения их прогнозов, которые мы рассмотрим в этом разделе.


Способы интерпретации
​


Анализировать сложную модель и её прогнозы можно, изучая:






изменение прогноза в зависимости от реального отклика
;






влияние признаков на прогнозы модели
;






поведение модели на типичных и нетипичных объектах выборки
;






вклад значений отдельных признаков в прогноз
;






изменение прогноза в зависимости от изменения отдельных признаков
;






максимально похожие объекты на заданный, для которых модель выдаёт другой прогноз
;






влияние отдельных объектов обучающей выборки на модель, которую мы в итоге обучим
;






влияние отдельных частей/характеристик объекта на прогноз модели
.






В последующих главах мы разберём эти подходы детальнее. Будут изучены подходы, применимые к самому широкому классу моделей. Во второй части учебника, посвящённой нейросетям, будет 
отдельная глава
 по интерпретации свёрточных нейросетей.


Корреляция, а не причинно-следственная связь
Важно помнить, что интерпретация методов машинного обучения 
показывает корреляцию, а не причинно-следственную связь
 (correlation does not imply causation).


Например, рассмотрим задачу прогнозирования количества атак акул на отдыхающих на морском курорте. Количество купленного мороженного может оказаться одним из самых важных признаков. Разумеется, это не значит, что эти величины связаны напрямую. Скорее, из-за благоприятной погоды больше людей начинают отдыхать на море, покупать мороженное и, как следствие, подвергаться эпизодическим атакам акул.


С другими примерами можно ознакомиться, например, в 
[1]
.


Литература
​




statology.org: correlation does not imply causation: 5 real-world examples.


Предыдущая страница
Интерпретация сложных моделей
Следующая страница
Анализ ошибок модели
Способы интерпретации
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.

