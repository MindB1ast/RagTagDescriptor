





Лучший классификатор на ROC кривой | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Базовые меры качества многоклассовой классификации
Специальные меры качества для бинарной классификации
Обобщение бинарных мер качества на многоклассовый случай
ROC-кривая
Лучший классификатор на ROC кривой
Эквивалентное определение AUC
Контроль качества предсказания вероятностей
Дополнительная литература
Вопросы
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Оценка качества классификации
Лучший классификатор на ROC кривой
Лучший классификатор на ROC кривой


ROC-кривая
 описывает семейство классификаторов, параметризованных параметром 
$\alpha\in \mathbb{R}$
α
∈
R
:


$\hat{y}(\mathbf{x}) = \text{sign}(g(\mathbf{x})-\alpha)  =
\begin{cases} 
+1, & g(\mathbf{x})\ge \alpha \\
-1, & g(\mathbf{x})< \alpha \\
\end{cases}$
y
^
​
(
x
)
=
sign
(
g
(
x
)
−
α
)
=
{
+
1
,
−
1
,
​
g
(
x
)
≥
α
g
(
x
)
<
α
​


Но как выбрать лучший экземпляр этого семейства?


В бинарной классификации 
$y\in\{+1,-1\}$
y
∈
{
+
1
,
−
1
}
, поэтому есть только два типа ошибок:






Назначить объекту положительного класса отрицательный класс
, что реализуется с вероятностью 
$p(\widehat{y}=-1|y=+1)=1-TPR$
p
(
y
​
=
−
1∣
y
=
+
1
)
=
1
−
TPR
. Обозначим штраф за такую ошибку 
$\lambda_+$
λ
+
​
.






Назначить объекту отрицательного класса положительный класс
, что реализуется с вероятностью 
$p(\widehat{y}=+1|y=-1)=FPR$
p
(
y
​
=
+
1∣
y
=
−
1
)
=
FPR
. Штраф за эту ошибку обозначим 
$\lambda_-$
λ
−
​
.






Тогда средние потери классификатора будут


$\begin{aligned}
L &= p(\hat{y}=-1,y=+1)\cdot\lambda_+ + p(\hat{y}=+1,y=-1)\cdot\lambda_-  \\
     &= p(y=+1)p(\widehat{y}=-1|y=+1)\cdot\lambda_{+}+p(y=-1)p(\widehat{y}=+1|y=-1)FPR\cdot\lambda_{-}  \\
     &= p(y=+1)(1-TPR)\cdot\lambda_{+}+p(y=-1)FPR\cdot\lambda_{-} 
\end{aligned}$
L
​
=
p
(
y
^
​
=
−
1
,
y
=
+
1
)
⋅
λ
+
​
+
p
(
y
^
​
=
+
1
,
y
=
−
1
)
⋅
λ
−
​
=
p
(
y
=
+
1
)
p
(
y
​
=
−
1∣
y
=
+
1
)
⋅
λ
+
​
+
p
(
y
=
−
1
)
p
(
y
​
=
+
1∣
y
=
−
1
)
FPR
⋅
λ
−
​
=
p
(
y
=
+
1
)
(
1
−
TPR
)
⋅
λ
+
​
+
p
(
y
=
−
1
)
FPR
⋅
λ
−
​
​


Отсюда в осях 
$FPR,TPR$
FPR
,
TPR
 можно получить 
изолинии потерь
 (loss isolines), т.е. множество точек (FPR,TPR), приводящих к одинаковому уровню средних потерь 
$L$
L
:


$TPR=1+\frac{\lambda_{-1}p(y=-1)FPR-L}{\lambda_{+1}p(y=+1)}$
TPR
=
1
+
λ
+
1
​
p
(
y
=
+
1
)
λ
−
1
​
p
(
y
=
−
1
)
FPR
−
L
​


Поскольку полученная зависимость TRP(FPR) линейна, то это будет прямая линия с положительным наклоном, а более высоким линиям будут отвечать более низкие ожидаемые потери, как показано на рисунке:


[IMAGE]


Отсюда следует, что оптимальным классификатором при заданных парамерах


$\lambda_-, p(y=-1) \text{ и }\lambda_+,p(y=+1)$
λ
−
​
,
p
(
y
=
−
1
)
 
и
 
λ
+
​
,
p
(
y
=
+
1
)


будет классификатор, соответствующий 
точке касания изолинии потерь и ROC-кривой
.


При изменении одного из этих параметров необязательно перенастраивать модель, а достаточно выбрать другую точку на ROC-кривой, т.е. взять классификатор с другим пороговым значением 
$\alpha$
α
.




Например, в задаче кредитного скоринга в кризис вероятность невозврата кредита 
$p(y=-1)$
p
(
y
=
−
1
)
 существенно вырастает, а для адаптации к этому изменению достаточно лишь изменить порог 
$\alpha$
α
.


Предыдущая страница
ROC-кривая
Следующая страница
Эквивалентное определение AUC
© 2023-25 
Виктор Китов.
 
Новости проекта.

