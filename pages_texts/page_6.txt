





Регуляризация модели | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Обучение с учителем
Настройка параметров модели
Выпуклость потерь
Регуляризация модели
Взвешенный учёт наблюдений
Связь с принципом максимального правдоподобия
Обобщающая способность
Оценка качества прогнозов
Этапы решения задачи машинного обучения
Обучение без учителя
Частичное обучение
Вопросы
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Основы машинного обучения
Регуляризация модели
Содержание этой страницы
Регуляризация модели


Регуляризация моделей
 (model regularization) - распространённый приём в машинном обучении, позволяющий контролировать 
сложность
 получаемой модели (model complexity) за счёт внесения ограничений в её настройку. Под сложностью модели в этой книге будет подразумеваться её гибкость, т.е. способность подстаиваться под наблюдения обучающей выборки. Например, полином - более сложная функция, чем линейная, поскольку за счёт большего числа настраиваемых коэффициентов способен гибче настраиваться на регрессионную зависимость.


Существуют разные способы регуляризации, но самый популярный - добавление регуляризующего слагаемого в минимизируемую функцию потерь:


$L(\mathbf{w}|X,Y)=\frac{1}{N}\sum_{n=1}^{N}\mathcal{L}(f_{\mathbf{w}}(\mathbf{x}_{n}),\,y_{n})+{\color{red}\lambda R(\mathbf{w})} \to \min_\mathbf{w}.$
L
(
w
∣
X
,
Y
)
=
N
1
​
n
=
1
∑
N
​
L
(
f
w
​
(
x
n
​
)
,
y
n
​
)
+
λ
R
(
w
)
→
w
min
​
.


Функция 
$R(\mathbf{w})\ge 0$
R
(
w
)
≥
0
 называется 
регуляризатором
 и штрафует параметры модели за излишнюю сложность. Гиперпараметр 
$\lambda\ge 0$
λ
≥
0
 выбирается пользователем и определяет, насколько важна точность по сравнению с простотой получаемой модели.


Почему 
$\lambda$
λ
 является именно гиперпараметром, т.е. почему её нельзя настраивать по обучающей выборке вместе с параметрами модели 
$\mathbf{w}$
w
?
При настройке 
$\lambda$
λ
 по критерию выше можно сразу сказать, чему равно его оптимальное значение: 
$\lambda=0$
λ
=
0
! Поскольку это соответствует удалению регуляризующего слагаемого из штрафа и настройке самой сложной (гибкой) модели, обеспечивающей наиболее точную подстройку под обучающие объекты. 
Но не обязательно под тестовые.
 То есть 
обобщающая способность
 модели на новых данных (generalization ability) может оказаться неоптимальной.


Популярные функции регуляризации
​


Популярными способами выбора 
$R(\mathbf{w})$
R
(
w
)
 являются:






L2-регуляризация


$R(\mathbf{w})=\| \mathbf{w} \|_2^2=\sum_{d=1}^D \mathbf{w}_d^2$
R
(
w
)
=
∥
w
∥
2
2
​
=
d
=
1
∑
D
​
w
d
2
​






L1-регуляризация






$R(\mathbf{w})=\| \mathbf{w} \|_1=\sum_{d=1}^D \vert \mathbf{w}_d \vert$
R
(
w
)
=
∥
w
∥
1
​
=
d
=
1
∑
D
​
∣
w
d
​
∣






ElasticNet-регуляризация


$R(\mathbf{w})=\alpha \| \mathbf{w} \|_2^2 +(1-\alpha) \| \mathbf{w} \|_1,\quad \alpha\in[0,1]$
R
(
w
)
=
α
∥
w
∥
2
2
​
+
(
1
−
α
)
∥
w
∥
1
​
,
α
∈
[
0
,
1
]






Все эти виды регуляризации поощряют выбор более малых по абсолютной величине весов в векторе 
$\mathbf{w}$
w
. Это ограничивает гибкость настройки весов и препятствует  переобучению модели под обучающую выборку.


ElasticNet требует спецификации дополнительного гиперпараметра 
$\alpha$
α
.


Преимущество L1-регуляризации
Особенностью L1-регуляризации является то, что она приводит к решению, в котором часть найденных весов может получаться 
в точности равной нулю
. Это достигается за счет слагаемого 
$\| \mathbf{w} \|_1$
∥
w
∥
1
​
 - см. 
обоснование
. Если в прогностической модели веса входят как мультипликативные множители при признаках (как, например, в линейных моделях или на первом слое нейросетей), то это приводит к 
отбору признаков
 (feature selection) - модель полностью перестаёт учитывать признаки, при которых получились нулевые веса! Это позволяет получать более эффективные и интерпретируемые модели и не собирать значения тех признаков, которые в конечном счёте не будут использоваться.


Преимущество L2-регуляризации
В L2-регуляризации штраф квадратично возрастает при увеличении веса. Если вес - коэффициент при признаке (как, например, в линейных моделях 
регрессии
 и 
классификации
 или на первом слое 
нейросетей
), то это приводит к более равномерному распределению весов по признакам, что способствует более полному учёту их значений. В частности, если два признака принимают в точности одинаковые значения, то вес при этих признаках L2-регуляризация распределит поровну, в то время как L1-регуляризация может их распределить произвольным образом.


Так как L1- и L2-регуляризации обладают разными достоинствами, для их совмещения и используется регуляризация ElasticNet.


Можно специфицировать и собственный вид регуляризатора 
$R(\mathbf{w})$
R
(
w
)
, исходя из логики решаемой задачи и представлений о том, модель с какими именно весами можно считать простой. Например, можно поощрять модели с более близкими весами друг к другу.


Другие виды регуляризации
​


Помимо дополнительного штрафа за величину весов, можно препятствовать переобучению моделей за счёт дополнительных ограничений на веса. Например, можно накладывать ограничения, что часть весов должны получаться неотрицательными. Или одни веса в точности совпадать по величине с другими.


Также можно ограничивать максимальное число итераций оптимизации при настройке функции потерь (early stopping). Это также препятствует переобучению модели под обучающую выборку.


Существуют и другие подходы к регуляризации. Особенно остро проблема переобучения стоит для нейросетей. Со всевозможными видами их регуляризации вы впоследствии 
познакомитесь
 в 
учебнике по глубокому обучению
.


Больше информации о регуляризации вы можете прочитать в 
[1]
 и 
[2]
.


Литература
​






Wikipedia: regularization (mathematics)
.






Мерков А. Б. Распознавание образов: введение в методы статистического обучения. // Москва: Едиториал УРСС. – 2010.




Предыдущая страница
Выпуклость потерь
Следующая страница
Взвешенный учёт наблюдений
Популярные функции регуляризации
Другие виды регуляризации
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.

