





Простая агрегация в ансамблях | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Ансамбли моделей
Математическое обоснование ансамблей
Простая агрегация в ансамблях
Методы построения базовых моделей
Настройка на разных фрагментах обучающей выборки
Ансамбли рандомизированных деревьев
Стэкинг
Дополнительная литература
Вопросы
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Ансамбли моделей
Простая агрегация в ансамблях
Содержание этой страницы
Простая агрегация в ансамблях


При борьбе с 
переобучением
 (overfitting) базовых моделей 
$f_1(\mathbf{x}),...f_M(\mathbf{x})$
f
1
​
(
x
)
,
...
f
M
​
(
x
)
 используются простые агрегирующие функции 
$G(\cdot)$
G
(
⋅
)
. Рассмотрим основные типы таких агрегаций для задач регрессии и классификации.


Регрессия
​


При решении задачи регрессии прогнозы базовых алгоритмов можно усреднять:


$\widehat{y}(\mathbf{x})=\frac{1}{M}\sum_{m=1}^{M}f_{m}(\mathbf{x})$
y
​
(
x
)
=
M
1
​
m
=
1
∑
M
​
f
m
​
(
x
)




Как вариант, среднее можно заменить на вычисление 
медианы
 прогнозов. Это имеет смысл при наличии выбросов в данных и использовании неустойчивых к выбросам моделей. Тогда, даже если одна из моделей выдаст аномально низкий или высокий прогноз, это не сильно изменит итоговый прогноз ансамбля.




Другим и гораздо более популярным вариантом усреднения является взвешенное среднее:


$\widehat{y}(\mathbf{x})=\frac{\sum_{m=1}^{M}w_{m}f_{m}(\mathbf{x})}{\sum_{m=1}^{M}w_{m}}$
y
​
(
x
)
=
∑
m
=
1
M
​
w
m
​
∑
m
=
1
M
​
w
m
​
f
m
​
(
x
)
​


Взвешенное среднее лучше, когда 
базовые модели сильно различаются по точности
. В этом случае целесообразно задать 
больший вес более точной модели
.


Усложнение взвешенного усреднения
При взвешенном усреднении веса могут быть не фиксированными константами, а функциями, зависящими от вектора признаков:
$\widehat{y}(\mathbf{x})=\frac{\sum_{m=1}^{M}w_{m}(\mathbf{x})\cdot f_{m}(\mathbf{x})}{\sum_{m=1}^{M}w_{m}(\mathbf{x})}$
y
​
(
x
)
=
∑
m
=
1
M
​
w
m
​
(
x
)
∑
m
=
1
M
​
w
m
​
(
x
)
⋅
f
m
​
(
x
)
​
Например, веса могут считаться как 
SoftMax преобразование
 от линейных функций от признаков. В этом случае разные модели будут более предпочтительными в разных участках признакового пространства. Этот подход называется 
смесь экспертов
 (mixture of experts 
[1]
).


Классификация
​


При агрегации прогнозов классификаторов необходимо различать три случая, когда классификаторы выдают:






вероятности классов,






метки классов






рейтинги классов (
дискриминантные функции
).






Рассмотрим агрегирование прогнозов для каждого из этих случаев.


Классификаторы выдают вероятности классов
​


В этом случае каждый классификатор выдаст вектор вероятностей классов, которые мы можем усреднить, чтобы получить итоговое распределение классов.


Вероятность класса 
$c$
c
 в этом случае будет средним по предсказанным вероятностям этого класса для всех классификаторов:


$p_{c}(\mathbf{x})=\frac{1}{M}\sum_{m=1}^{M}p_{c}^{m}(\mathbf{x}), \quad c=1,2,...C$
p
c
​
(
x
)
=
M
1
​
m
=
1
∑
M
​
p
c
m
​
(
x
)
,
c
=
1
,
2
,
...
C




Аналогично регрессии,  равномерное усреднение можно заменить взвешенным.




Классификаторы выдают метки классов
​


В этом случае в качестве агрегирующей функции можно взять 
голосование по большинству
 (majority vote), то есть назначать тот класс, за который проголосовало большинство базовых классификаторов.


Если классификаторы неравнозначны между собой (за счёт сильных различий в точности), то лучше использовать взвешенное голосование, при котором голоса более точных классификаторов учитываются с б
о
льшим весом.


Бинарная классификация
​


Когда классов всего два, то можно предсказывать положительный класс, когда этот класс предсказывают






все базовые классификаторы  (правило AND),






хотя бы один из классификаторов (правило OR),






по крайней мере K классификаторов (правило K-out-of-N).






Последнее правило обобщает стратегии AND и OR при K=N и K=1 соответственно. Правило OR используется при обнаружении аномалий отдельными классификаторами: если хотя бы один базовый классификатор увидел что-то необычное в объекте, то он считается аномалией.


Классификаторы выдают рейтинги
​


Как мы знаем, каждый классификатор внутри себя рассчитывает 
рейтинги классов
 при построении прогноза. Соответственно, можно извлекать не окончательные метки, а вектора рейтингов классов 
$\mathbf{g}^1(\mathbf{x}),...\mathbf{g}^M(\mathbf{x})\in\mathbb{R}^C$
g
1
(
x
)
,
...
g
M
(
x
)
∈
R
C
 для соответствующих базовых классификаторов 
$f_1(\mathbf{x}),...f_M(\mathbf{x})$
f
1
​
(
x
)
,
...
f
M
​
(
x
)
, после чего их усреднять:


$\mathbf{g}=\frac{1}{M}\sum_{m=1}^{M}\mathbf{g}^m \in \mathbb{R}^C,$
g
=
M
1
​
m
=
1
∑
M
​
g
m
∈
R
C
,


получая вектор рейтингов для ансамбля:


$\mathbf{g}=[g_1,...g_C]^T$
g
=
[
g
1
​
,
...
g
C
​
]
T


Далее, как обычно, прогнозируется класс, обладающий максимальным рейтингом:


$\hat{y}(\mathbf{x})=\arg\max_c g_c(\mathbf{x})$
y
^
​
(
x
)
=
ar
g
c
max
​
g
c
​
(
x
)


Ограничения подхода
Этот подход работает только для классификаторов из одного семейства, у которых рейтинги изменяются в одной шкале! Для моделей разных типов так делать нельзя, поскольку тогда ранжирование будет доминироваться классификатором с рейтингами, принимающими 
максимально широкий диапазон значений
.


Корректировка для классификаторов разных типов
​


В общем случае классификаторы разных типов выдают рейтинги в разном диапазоне, поэтому усреднять их нельзя, как показано в примере ниже:


$g_1(\mathbf{x})$
g
1
​
(
x
)
$g_2(\mathbf{x})$
g
2
​
(
x
)
$g_3(\mathbf{x})$
g
3
​
(
x
)
$g_4(\mathbf{x})$
g
4
​
(
x
)
$f_1(\mathbf{x})$
f
1
​
(
x
)
100
70
34
-25
$f_2(\mathbf{x})$
f
2
​
(
x
)
15
0
-14
-10
$f_3(\mathbf{x})$
f
3
​
(
x
)
0.05
0.6
0.2
0.15


Рейтинги первой модели имеют максимальный разброс значений, поэтому при усреднении в основном определять прогноз будут именно они! Чтобы такого не происходило, перед усреднением рейтингов их необходимо 
привести к единой шкале
.


Для этого применяется 
ранговое преобразование
, в котором новый рейтинг класса считается как количество других классов, которые рассматриваемый класс доминирует по рейтингу (принимая более высокое значение дискриминантной функции). Преобразованный рейтинги называется Borda counts 
[2]
.


В примере выше модели ранжируют классы следующим образом:


модель
ранжирование классов
$f_1(\mathbf{x})$
f
1
​
(
x
)
$1 \succ 2 \succ 3 \succ 4$
1
≻
2
≻
3
≻
4
$f_2(\mathbf{x})$
f
2
​
(
x
)
$1 \succ 2 \succ 4 \succ 3$
1
≻
2
≻
4
≻
3
$f_3(\mathbf{x})$
f
3
​
(
x
)
$2 \succ 3 \succ 4 \succ 1$
2 
≻
3
≻
4
≻
1


Преобразованные рейтинги будут:


$g_1'(\mathbf{x})$
g
1
′
​
(
x
)
$g_2'(\mathbf{x})$
g
2
′
​
(
x
)
$g_3'(\mathbf{x})$
g
3
′
​
(
x
)
$g_4'(\mathbf{x})$
g
4
′
​
(
x
)
$f_1(\mathbf{x})$
f
1
​
(
x
)
3
2
1
0
$f_2(\mathbf{x})$
f
2
​
(
x
)
3
2
0
1
$f_3(\mathbf{x})$
f
3
​
(
x
)
0
3
2
1


Они принадлежат уже 
одинаковой шкале значений
 
$\{0,1,2,3\}$
{
0
,
1
,
2
,
3
}
, поэтому их можно усреднять. В результате усреднения получим следующие рейтинги для ансамбля:


$g_1''(\mathbf{x})$
g
1
′′
​
(
x
)
$g_2''(\mathbf{x})$
g
2
′′
​
(
x
)
$g_3''(\mathbf{x})$
g
3
′′
​
(
x
)
$g_4''(\mathbf{x})$
g
4
′′
​
(
x
)
6/3
7/3
3/3
2/3


Далее, как обычно, назначается класс с максимальным средним рейтингом. Это будет класс 2.




Заметим, что прогноз отличается от прогноза голосованием по большинству, когда был назначен класс 1. Класс 2 победил новым способом, поскольку класс 2 считается вероятным всеми тремя классификаторами, а класс 1 считается самым маловероятным третьей моделью 
$f_3(\mathbf{x})$
f
3
​
(
x
)
.




Учёт классификаторов с разной степенью
Как и раньше, если классификаторы сильно различаются по точности, их рейтинги  можно усреднять не равномерно, а с весами, назначая более высокий вес более точным классификаторам.


Пример запуска в Python
​


Усредняющий ансамбль для классификации:


from
 sklearn
.
linear_model 
import
 LogisticRegression
from
 sklearn
.
tree 
import
 DecisionTreeClassifier
from
 sklearn
.
ensemble 
import
 VotingClassifier
from
 sklearn
.
metrics 
import
 accuracy_score
from
 sklearn
.
metrics 
import
 brier_score_loss
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_classification_data
(
)
# Инициализируем базовые модели и проверим их качество
log_model 
=
 LogisticRegression
(
)
   
# инициализация модели
log_model
.
fit
(
X_train
,
 Y_train
)
    
# обучение модели   
Y_hat 
=
 log_model
.
predict
(
X_test
)
  
# построение прогнозов
print
(
f'Точность LogisticRegression: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
  
tree_model 
=
 DecisionTreeClassifier
(
)
  
# инициализация дерева
tree_model
.
fit
(
X_train
,
 Y_train
)
       
# обучение модели   
Y_hat 
=
 tree_model
.
predict
(
X_test
)
     
# построение прогнозов
print
(
f'Точность DecisionTree: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
  
# Инициализируем ансамбль, усредняющий метки классов
ensemble 
=
 VotingClassifier
(
estimators
=
[
(
'logistic regression'
,
 log_model
)
,
 
                                        
(
'decision tree'
,
 tree_model
)
]
,
 
                            voting
=
'hard'
,
      
# усредняем метки классов
                            weights
=
[
0.5
,
0.5
]
)
  
# веса учёта базовых моделей
ensemble
.
fit
(
X_train
,
 Y_train
)
     
# обучение базовых моделей ансамбля
Y_hat 
=
 ensemble
.
predict
(
X_test
)
   
# построение прогнозов
print
(
f'Точность VotingClassifier: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
  
# Инициализируем ансамбль, усредняющий вероятности классов
ensemble 
=
 VotingClassifier
(
estimators
=
[
(
'logistic regression'
,
 log_model
)
,
 
                                        
(
'decision tree'
,
 tree_model
)
]
,
 
                            voting
=
'soft'
,
      
# усредняем вероятности классов
                            weights
=
[
0.5
,
0.5
]
)
  
# веса учёта базовых моделей
ensemble
.
fit
(
X_train
,
 Y_train
)
     
# обучение базовых моделей ансамбля
Y_hat 
=
 ensemble
.
predict
(
X_test
)
   
# построение прогнозов
print
(
f'Точность VotingClassifier: 
{
100
*
accuracy_score
(
Y_test
,
 Y_hat
)
:
.1f
}
%'
)
  
P_hat 
=
 ensemble
.
predict_proba
(
X_test
)
  
# можно предсказывать вероятности классов
loss 
=
 brier_score_loss
(
Y_test
,
 P_hat
[
:
,
1
]
)
  
# мера Бриера на вероятности положительного класса
print
(
f'Мера Бриера ошибки прогноза вероятностей: 
{
loss
:
.2f
}
'
)




Больше информации
. 
Полный код
.


Усредняющий ансамбль для регрессии:


from
 sklearn
.
neighbors 
import
 KNeighborsRegressor
from
 sklearn
.
tree 
import
 DecisionTreeRegressor
from
 sklearn
.
ensemble 
import
 VotingRegressor
from
 sklearn
.
metrics 
import
 mean_absolute_error
X_train
,
 X_test
,
 Y_train
,
 Y_test 
=
 get_demo_classification_data
(
)
# Инициализируем базовые модели и проверим их качество
knn 
=
 KNeighborsRegressor
(
n_neighbors
=
100
)
    
# инициализация модели
log_model
.
fit
(
X_train
,
 Y_train
)
     
# обучение модели   
Y_hat 
=
 log_model
.
predict
(
X_test
)
   
# построение прогнозов
print
(
f'Средний модуль ошибки (MAE): 
{
mean_absolute_error
(
Y_test
,
 Y_hat
)
:
.2f
}
'
)
   
tree_model 
=
 DecisionTreeRegressor
(
)
 
# инициализация дерева
tree_model
.
fit
(
X_train
,
 Y_train
)
     
# обучение модели   
Y_hat 
=
 tree_model
.
predict
(
X_test
)
   
# построение прогнозов
print
(
f'Средний модуль ошибки (MAE): 
{
mean_absolute_error
(
Y_test
,
 Y_hat
)
:
.2f
}
'
)
    
# Инициализируем усредняющий ансамбль
ensemble 
=
 VotingRegressor
(
estimators
=
[
(
'K nearest neighbours'
,
 knn
)
,
 
                                       
(
'decision tree'
,
 tree_model
)
]
,
 
                           weights
=
[
0.5
,
0.5
]
)
  
# веса учёта базовых моделей
ensemble
.
fit
(
X_train
,
 Y_train
)
     
# обучение базовых моделей ансамбля
Y_hat 
=
 ensemble
.
predict
(
X_test
)
   
# построение прогнозов
print
(
f'Средний модуль ошибки (MAE): 
{
mean_absolute_error
(
Y_test
,
 Y_hat
)
:
.2f
}
'
)
     




Больше информации
. 
Полный код
.


Также с примером работы усредняющего классификатора можно ознакомиться в 
[3]
.


Более подробно работа простых ансамблей описана в 
[4]
.


Литература
​






Wikipedia: Mixture of experts.






Wikipedia: Borda count.






Geeksforgeeks: Voting Classifier.






Webb A. R., Copsey K.D. Statistical pattern recognition. – John Wiley & Sons, 2011.




Предыдущая страница
Математическое обоснование ансамблей
Следующая страница
Методы построения базовых моделей
Регрессия
Классификация
Классификаторы выдают вероятности классов
Классификаторы выдают метки классов
Классификаторы выдают рейтинги
Пример запуска в Python
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.

