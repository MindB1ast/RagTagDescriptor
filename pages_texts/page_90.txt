





Доказательство разложения | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Сложность прогнозирующих моделей
Разложение на смещение и разброс
Доказательство разложения
Дополнительная литература
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Переобучение и недообучение
Доказательство разложения
Доказательство разложения


Докажем разложение на смещение и разброс:


$\begin{aligned}\mathbb{E}_{X,Y,\varepsilon}\{[\widehat{f}(\mathbf{x})-y(\mathbf{x})]^{2}\}=&\left(\mathbb{E}_{X,Y}\{\widehat{f}(\mathbf{x})\}-f(\mathbf{x})\right)^{2}\\&+\mathbb{E}_{X,Y}\left\{ [\widehat{f}(\mathbf{x})-\mathbb{E}_{X,Y}\widehat{f}(\mathbf{x})]^{2}\right\} +\mathbb{E}\varepsilon^{2}\end{aligned}$
E
X
,
Y
,
ε
​
{[
f
​
(
x
)
−
y
(
x
)
]
2
}
=
​
(
E
X
,
Y
​
{
f
​
(
x
)}
−
f
(
x
)
)
2
+
E
X
,
Y
​
{
[
f
​
(
x
)
−
E
X
,
Y
​
f
​
(
x
)
]
2
}
+
E
ε
2
​


Зафиксируем 
$\mathbf{x}$
x
, для которого строится прогноз. Далее везде в математических ожиданиях будет производиться усреднение 
по всевозможным реализациям обучающей выборки и случайного шума
, то есть


$\mathbb{E}\{\cdot\} = \mathbb{E}_{X,Y,\varepsilon}\{\cdot\}$
E
{
⋅
}
=
E
X
,
Y
,
ε
​
{
⋅
}


Для начала разложим следующее выражение:


$\begin{aligned}\mathbb{E}\left\{\left(\widehat{f}(\mathbf{x})-f(\mathbf{x})\right)^{2}\right\}&=
\mathbb{E}\left\{\left(\widehat{f}(\mathbf{x})-\mathbb{E}\widehat{f}(\mathbf{x})+\mathbb{E}\widehat{f}(\mathbf{x})-f(\mathbf{x})\right)^{2}\right\}\\
&=\mathbb{E}\left\{\left(\widehat{f}(\mathbf{x})-\mathbb{E}\widehat{f}(\mathbf{x})\right)^{2}\right\}+\mathbb{E}\left\{\left(\mathbb{E}\widehat{f}(\mathbf{x})-f(\mathbf{x})\right)^{2}\right\}\\&+2\cdot\mathbb{E}\left\{(\widehat{f}(\mathbf{x})-\mathbb{E}\widehat{f}(\mathbf{x}))(\mathbb{E}\widehat{f}(\mathbf{x})-f(\mathbf{x}))\right\}\\&=\mathbb{E}\left\{\left(\widehat{f}(\mathbf{x})-\mathbb{E}\widehat{f}(\mathbf{x})\right)^{2}\right\}+\left(\mathbb{E}\widehat{f}(\mathbf{x})-f(\mathbf{x})\right)^{2},\end{aligned}$
E
{
(
f
​
(
x
)
−
f
(
x
)
)
2
}
​
=
E
{
(
f
​
(
x
)
−
E
f
​
(
x
)
+
E
f
​
(
x
)
−
f
(
x
)
)
2
}
=
E
{
(
f
​
(
x
)
−
E
f
​
(
x
)
)
2
}
+
E
{
(
E
f
​
(
x
)
−
f
(
x
)
)
2
}
+
2
⋅
E
{
(
f
​
(
x
)
−
E
f
​
(
x
))
(
E
f
​
(
x
)
−
f
(
x
))
}
=
E
{
(
f
​
(
x
)
−
E
f
​
(
x
)
)
2
}
+
(
E
f
​
(
x
)
−
f
(
x
)
)
2
,
​


где мы воспользовались тем, что 
$(\mathbb{E}\widehat{f}(\mathbf{x})-f(\mathbf{x}))$
(
E
f
​
(
x
)
−
f
(
x
))
 - константа, а значит,


$\begin{aligned}
\mathbb{E}\{(\widehat{f}(\mathbf{x})-\mathbb{E}\widehat{f}(\mathbf{x}))(\mathbb{E}\widehat{f}(\mathbf{x})-f(\mathbf{x}))\}\\&=(\mathbb{E}\widehat{f}(\mathbf{x})-f(\mathbf{x}))\mathbb{E}\{\widehat{f}(\mathbf{x})-\mathbb{E}\widehat{f}(\mathbf{x})\}=0
\end{aligned}$
E
{(
f
​
(
x
)
−
E
f
​
(
x
))
(
E
f
​
(
x
)
−
f
(
x
))}
​
=
(
E
f
​
(
x
)
−
f
(
x
))
E
{
f
​
(
x
)
−
E
f
​
(
x
)}
=
0
​


Следовательно,


$\begin{aligned}
\mathbb{E}\left\{\left(\widehat{f}(\mathbf{x})-y\right)^{2}\right\} &=    
\mathbb{E}\left\{\left(\widehat{f}(\mathbf{x})-f(\mathbf{x})-\varepsilon\right)^{2}\right\}\\ 
&=\mathbb{E}\left\{\left(\widehat{f}(\mathbf{x})-f(\mathbf{x})\right)^{2}\right\}+\mathbb{E}\varepsilon^{2}-2\mathbb{E}\left[(\widehat{f}-f)\varepsilon\right] \\
&=    \mathbb{E}\left\{\left(\widehat{f}(\mathbf{x})-\mathbb{E}\widehat{f}(\mathbf{x})\right)^{2}\right\}+\left(\mathbb{E}\widehat{f}(\mathbf{x})-f(\mathbf{x})\right)^{2}+\mathbb{E}\varepsilon^{2}
\end{aligned}$
E
{
(
f
​
(
x
)
−
y
)
2
}
​
=
E
{
(
f
​
(
x
)
−
f
(
x
)
−
ε
)
2
}
=
E
{
(
f
​
(
x
)
−
f
(
x
)
)
2
}
+
E
ε
2
−
2
E
[
(
f
​
−
f
)
ε
]
=
E
{
(
f
​
(
x
)
−
E
f
​
(
x
)
)
2
}
+
(
E
f
​
(
x
)
−
f
(
x
)
)
2
+
E
ε
2
​


где, в силу независимости случайных величин 
$\hat{f}(\mathbf{x})$
f
^
​
(
x
)
 (которая зависит только от 
$X,Y$
X
,
Y
) и 
$\varepsilon$
ε
:


$\mathbb{E}\left\{(\widehat{f}(\mathbf{x})-f(\mathbf{x}))\varepsilon\right\}=\mathbb{E}\left\{(\widehat{f}(\mathbf{x})-f(\mathbf{x}))\right\} \cdot \mathbb{E}\varepsilon=0$
E
{
(
f
​
(
x
)
−
f
(
x
))
ε
}
=
E
{
(
f
​
(
x
)
−
f
(
x
))
}
⋅
E
ε
=
0
Предыдущая страница
Разложение на смещение и разброс
Следующая страница
Дополнительная литература
© 2023-25 
Виктор Китов.
 
Новости проекта.

