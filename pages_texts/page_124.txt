





Значения Шепли | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Интерпретация сложных моделей
Анализ ошибок модели
Прогнозы на типичных и нетипичных объектах
Влияние признаков на качество прогнозов
Значения Шепли
Локальное объяснение интерпретируемой моделью
Влияние фрагментов
Зависимость прогноза от признаков
Контрфактические объяснения
Влияние обучающих объектов
Вопросы
Заключение
Интерпретация сложных моделей
Значения Шепли
Содержание этой страницы
Значения Шепли


Значения Шепли
 (Shapley values 
[1]
) позволяют объяснить для выбранного объекта 
$\mathbf{x}$
x
 вклад значения каждого признака в прогноз модели 
$f\left(\mathbf{x}\right)$
f
(
x
)
. Оценка производится для конкретного объекта и конкретного значения выбранного признака. Вклад значений всех признаков и обеспечивает результирующий прогноз.


Рассмотрим в качестве примера задачу Titanic 
[2]
, в которой по описанию каждого  пассажира (включающему класс билета, пол, возраст и т.д.) нужно предсказать, выжил он в результате кораблекрушения или нет. На рисунке ниже 
[3]
 показано объяснение прогнозируемой вероятности выживания для одного из пассажиров:


[IMAGE]




Видно, что высокая вероятность прогнозируемого выживания 0.93 обеспечивается тем, что пассажир - женщина, которая не путешествовала третьим классом. Однако то, что она не путешествовала первым классом (в one-hot кодировании индикаторы класса - разные признаки) несколько снизило оцениваемую вероятность выжить.




Псевдокод для приближённого расчёта значения Шепли, измеряющего вклад 
$j$
j
-го признака в прогноз приведён ниже.


Результат:
 значение Шепли для значения 
$j$
j
-го признака


Параметры:
 количество итераций 
$M$
M
, исследуемый объект 
$\mathbf{x}$
x
, индекс признака 
$j$
j
, матрица данных 
$\mathbf{X}$
X
, модель машинного обучения 
$f$
f
.






Для всех 
$m = 1, \ldots, M$
m
=
1
,
…
,
M
:






Выбрать случайный объект 
$\mathbf{z}$
z
 из матрицы данных 
$\mathbf{X}$
X






Случайным образом выбрать перестановку 
$\mathbf{p}$
p
 признаков






Упорядочить объект 
$\mathbf{x}$
x
:  
$\mathbf{x}_{\mathbf{p}} = (x_{(1)}, \ldots, x_{(j)}, \ldots, x_{(D)})$
x
p
​
=
(
x
(
1
)
​
,
…
,
x
(
j
)
​
,
…
,
x
(
D
)
​
)






Упорядочить объект 
$\mathbf{z}$
z
:  
$\mathbf{z}_{\mathbf{p}} = (z_{(1)}, \ldots, z_{(j)}, \ldots, z_{(D)})$
z
p
​
=
(
z
(
1
)
​
,
…
,
z
(
j
)
​
,
…
,
z
(
D
)
​
)






Построить два новых объекта:




С признаком 
$j$
j
:  
$\mathbf{x}_{+j} = (x_{(1)}, \ldots, x_{(j-1)}, x_{(j)}, z_{(j+1)}, \ldots, z_{(D)})$
x
+
j
​
=
(
x
(
1
)
​
,
…
,
x
(
j
−
1
)
​
,
x
(
j
)
​
,
z
(
j
+
1
)
​
,
…
,
z
(
D
)
​
)


Без признака 
$j$
j
:    
$\mathbf{x}_{-j} = (x_{(1)}, \ldots, x_{(j-1)}, z_{(j)}, z_{(j+1)}, \ldots, z_{(D)})$
x
−
j
​
=
(
x
(
1
)
​
,
…
,
x
(
j
−
1
)
​
,
z
(
j
)
​
,
z
(
j
+
1
)
​
,
…
,
z
(
D
)
​
)








Вычислить маржинальный вклад:


$\phi_j^{(m)} = f(\mathbf{x}_{+j}) - f(\mathbf{x}_{-j})$
ϕ
j
(
m
)
​
=
f
(
x
+
j
​
)
−
f
(
x
−
j
​
)










Вычислить значение Шепли как среднее маржинальных вкладов:


$\phi_j(\mathbf{x}) = \frac{1}{M} \sum_{m=1}^M \phi_j^{(m)}$
ϕ
j
​
(
x
)
=
M
1
​
m
=
1
∑
M
​
ϕ
j
(
m
)
​






Число повторов 
$M$
M
 определяет точность полученной оценки: чем выше - тем она получится точнее.


По сути, происходит оценка, насколько в среднем вырастает прогноз, если оставить и заменить интересующее значение признака случайным значением из выборки при одновременной замене случайного подмножества других признаков. В итоге получим 
среднее изменение прогноза за счёт того, что интересующий признак принимает заданное значение
.


Таким образом, значения Шепли оценивают важность признаков в контексте заданного объекта 
$\mathbf{x}$
x
, а сумма их значений равна отклонению прогноза 
$f(\mathbf{x})$
f
(
x
)
 от среднего прогноза по всем объектам.


Недостатком метода, как для 
перестановочной важности признаков
, является 
усреднение по малореальным объектам
, поскольку в процедуре оценки генерируются синтетические объекты, для которых часть значений признаков взята из одного объекта, а другая часть - из другого, что может приводить к маловероятным комбинациям признаков, особенно когда признаки сильно скоррелированы.


Глобальная важность признака
С помощью значений Шепли можно вычислить и 
глобальную важность признака
. Для этого абсолютные значения Шепли для этого признака усредняются по всем объектам выборки:
$\text{Importance}(j)=\frac{1}{N}\sum_{n=1}^N |\phi_j(\mathbf{x}_n)|$
Importance
(
j
)
=
N
1
​
n
=
1
∑
N
​
∣
ϕ
j
​
(
x
n
​
)
∣




Детальнее о значениях Шепли, их теоретическом обосновании и свойствах можно прочитать в 
[4]
 и 
[5]
. Пример практического расчёта этих значений в python, используя библиотеку shap, доступен в 
[6]
.


Литература
​






Wikipedia: Shapley value.






openml.org: Titanic dataset.






Gosiewska A., Biecek P. IBreakDown: Uncertainty of model explanations for non-additive predictive models //arXiv preprint arXiv:1903.11420. – 2019.






Molnar C. Interpretable machine learning. – Lulu. com, 2020: Shapley values.






Molnar C. Interpretable machine learning. – Lulu. com, 2020: SHAP.






Документация shap: an introduction to explainable AI with Shapley values.




Предыдущая страница
Влияние признаков на качество прогнозов
Следующая страница
Локальное объяснение интерпретируемой моделью
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.

