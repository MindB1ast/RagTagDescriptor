





Отступ классификации | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Общий вид прогнозирующих функций
Отступ классификации
Предсказание вероятностей и преобразование SoftMax
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Классификаторы в общем виде
Отступ классификации
Содержание этой страницы
Отступ классификации


Введение
​


В регрессии (когда прогнозируем вещественное число) есть понятие 
величины ошибки
, характеризующей степень того, насколько мы ошиблись в прогнозе:


$\varepsilon = f_\mathbf{w}(\mathbf{x})-y$
ε
=
f
w
​
(
x
)
−
y


Соответственно, мы определяем функцию потерь от этой ошибки, характеризующую штраф за то или иное отклонение:


задача
название
формула
регрессия
квадрат ошибки (squared error)
$(f_\mathbf{w}(\mathbf{x})-y)^2$
(
f
w
​
(
x
)
−
y
)
2
регрессия
модуль ошибки (absolute error)
$\vert f_\mathbf{w}(\mathbf{x})-y \vert$
∣
f
w
​
(
x
)
−
y
∣
регрессия
$\alpha$
α
-нечувствительная, 
$\alpha>0$
α
>
0
$\max\{0,\vert f_\mathbf{w}(\mathbf{x})-y\vert-\alpha\}$
max
{
0
,
∣
f
w
​
(
x
)
−
y
∣
−
α
}


Проинтерпретируйте 
$\alpha$
α
-нечувствительные потери.
$\alpha$
α
-нечувствительные потери штрафуют отклонение пропорционально величине отклонения за вычетом 
$\alpha$
α
 и вообще не штрафуют, если отклонение оказалось по абсолютной величине меньше 
$\alpha$
α
. Это полезно в приложениях, где существует некоторый допустимый уровень ошибки, таких как прогноз погоды для бытовых нужд, когда разница в 
$\pm 1$
±
1
 градус несущественна.


Но как измерять степень рассогласованности классификационного прогноза с истинным значением? Можно смотреть на индикатор ошибки 
$\mathbb{I}\{f_\mathbf{w}(\mathbf{x})\ne y\}$
I
{
f
w
​
(
x
)

=
y
}
, однако эта величина принимает всего два дискретных значения: 0 для верного и 1 - для неверного прогноза! Индикатор не позволяет понять, 
насколько уверенно
 модель пыталась предсказать правильный отклик! Для этого используется понятие 
отступа
 (margin).


Отступ для многоклассовой классификации
​


Определение отступа
Отступ
 (margin) - непрерывная величина, измеряющая качество классификации по формуле:
$M(\mathbf{x},y)=g_y(\mathbf{x})-\max_{c\ne y}g_c(\mathbf{x}),$
M
(
x
,
y
)
=
g
y
​
(
x
)
−
c

=
y
max
​
g
c
​
(
x
)
,
где 
$g_y(\mathbf{x})$
g
y
​
(
x
)
 - рейтинг верного класса, а 
$\max_{c\ne y}g_c(\mathbf{x})$
max
c

=
y
​
g
c
​
(
x
)
 - максимальный рейтинг среди всех неверных.


Отступ по смыслу измеряет, насколько модель 
уверенно назначала верный класс по сравнению со всеми неверными
. Чем отступ выше, тем модель была более уверена в правильном прогнозе. Если 
$M(\mathbf{x},y)>0$
M
(
x
,
y
)
>
0
, то модель делает верный прогноз, а если 
$M(\mathbf{x},y)<0$
M
(
x
,
y
)
<
0
, то неверный.


Если применить модель ко всем объектам обучающей выборки, посчитать на них отступ и отсортировать по нему, то получим примерно такой график:


[IMAGE]


По величине отступа объекты делятся на следующие категории:






Надежно классифицированные объекты
 (обозначены светло-зелёным): отступ положительный и заметно больше нуля. При хорошей настройке модели большинство объектов будут принадлежать этой категории.






Объекты-эталоны
 (обозначены насыщенным зелёным): отступ положительный и большой. Объекты, лежащие в глубине своего класса и описывающие характерных представителей своего класса.






Пограничные объекты
 (обозначены оранжевым): отступ несильно отличается от нуля, объекты лежат на границе классов, и на таких объектах обычно достигается максимальное число ошибок.






Объекты-выбросы
 (обозначены красным): отступ отрицательный и большой по абсолютной величине. Объекты лежат в глубине чужого класса. На них модель уверена, что класс один, хотя на самом деле он совсем другой.






Для повышения точности настройки модели полезно отфильтровать объекты-выбросы, чтобы они не мешали её настройке.


При этом, если нужно сократить размер обучающей выборки для повышения эффективности обучения, то делать это можно взяв эталонные объекты (определяющие расположения классов) и пограничные (несущие более детальную информацию о границах между ними), добавляя в первую очередь те пограничные объекты, на которых отступ меньше, но которые всё ещё не являются выбросами. Уменьшение размера выборки известно в литературе как отбор прототипов (prototype selection). О более продвинутых подходах можно прочитать в 
[1]
.


Информацию об отступах объектов можно использовать и для более эффективного порядка обхода объектов в численных методах оптимизации модели методом 
стохастического градиентного спуска
 вместо выбора случайных групп объектов.


Отступ для бинарной классификации
​


В случае бинарной классификации формула для отступа упрощается:


$M(\mathbf{x},y)=g_y(\mathbf{x})-g_{-y}(\mathbf{x})=y(g_{+1}(\mathbf{x})-g_{-1}(\mathbf{x}))=yg(\mathbf{x}),$
M
(
x
,
y
)
=
g
y
​
(
x
)
−
g
−
y
​
(
x
)
=
y
(
g
+
1
​
(
x
)
−
g
−
1
​
(
x
))
=
y
g
(
x
)
,


где, как и раньше, 
$g(\mathbf{x})=g_{+1}(\mathbf{x})-g_{-1}(\mathbf{x})$
g
(
x
)
=
g
+
1
​
(
x
)
−
g
−
1
​
(
x
)
 определяет 
относительную дискриминантную функцию
.


Литература
​




Bien J., Tibshirani R. Prototype selection for interpretable classification. – 2011.


Предыдущая страница
Общий вид прогнозирующих функций
Следующая страница
Предсказание вероятностей и преобразование SoftMax
Введение
Отступ для многоклассовой классификации
Отступ для бинарной классификации
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.

