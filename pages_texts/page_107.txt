





Иллюстрация работы градиентного бустинга по шагам | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Бустинг
Сравнение бустинга с другими ансамблями моделей
Алгоритм AdaBoost
Градиентный бустинг
Алгоритм градиентного бустинга
Улучшения градиентного бустинга
Иллюстрация работы
Градиентный бустинг второго порядка
Популярные реализации
Точность градиентного бустинга
Дополнительная литература
Вопросы
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Бустинг
Иллюстрация работы
Содержание этой страницы
Иллюстрация работы градиентного бустинга по шагам


Рассмотрим визуализацию работы градиентного бустинга:


$G_m(\mathbf{x})=f_0(\mathbf{x})+\varepsilon f_1(\mathbf{x})+\varepsilon f_2(\mathbf{x})+...+\varepsilon f_m(\mathbf{x}),$
G
m
​
(
x
)
=
f
0
​
(
x
)
+
ε
f
1
​
(
x
)
+
ε
f
2
​
(
x
)
+
...
+
ε
f
m
​
(
x
)
,


$m=1,2,3,...,$
m
=
1
,
2
,
3
,
...
,


где






$f_0(\mathbf{x})\equiv 0$
f
0
​
(
x
)
≡
0
;






$f_1(\mathbf{x}),f_2(\mathbf{x}),...$
f
1
​
(
x
)
,
f
2
​
(
x
)
,
...
 - решающие деревья глубины 3;






$\varepsilon=0.3$
ε
=
0.3
.






Для простоты визуализации рассмотрим двумерное признаковое пространство


$\mathbf{x}=[x^1,x^2]$
x
=
[
x
1
,
x
2
]


Будем строить целевую зависимость 
$y(\mathbf{x})$
y
(
x
)
 и текущее приближение 
$G_m(\mathbf{x})$
G
m
​
(
x
)
 на левом графике, а ошибку 
$y(\mathbf{x})-G_m(\mathbf{x})$
y
(
x
)
−
G
m
​
(
x
)
 и следующую базовую модель 
$f_{m+1}(\mathbf{x})$
f
m
+
1
​
(
x
)
 - на правом.


$m=0:$
m
=
0
:


[IMAGE]


$m=1:$
m
=
1
:


[IMAGE]


$m=2:$
m
=
2
:


[IMAGE]


$m=3:$
m
=
3
:


[IMAGE]


$m=4:$
m
=
4
:


[IMAGE]


$m=5:$
m
=
5
:


[IMAGE]


$m=6:$
m
=
6
:


[IMAGE]


$m=7:$
m
=
7
:


[IMAGE]


$m=8:$
m
=
8
:


[IMAGE]


$m=9:$
m
=
9
:


[IMAGE]


$m=10:$
m
=
10
:


[IMAGE]


Как видим, с ростом 
$m$
m
 отклонение прогноза от истинного значения уменьшается и становится более шумным. Скачки в ошибке возникают на местах разбиения признакового пространства узлами деревьев.


Результаты работы были получены, используя интерактивный визуализатор Алексея Рогожникова 
[1]
, в котором можно отобразить работу бустинга и при других пользовательских настройках.


Литература
​




Brilliantly wrong: Gradient Boosting explained.


Предыдущая страница
Улучшения градиентного бустинга
Следующая страница
Градиентный бустинг второго порядка
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.

