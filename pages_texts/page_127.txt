





Зависимость прогноза от признаков | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Интерпретация простых моделей
Интерпретация сложных моделей
Интерпретация сложных моделей
Анализ ошибок модели
Прогнозы на типичных и нетипичных объектах
Влияние признаков на качество прогнозов
Значения Шепли
Локальное объяснение интерпретируемой моделью
Влияние фрагментов
Зависимость прогноза от признаков
Контрфактические объяснения
Влияние обучающих объектов
Вопросы
Заключение
Интерпретация сложных моделей
Зависимость прогноза от признаков
Содержание этой страницы
Зависимость прогноза от признаков


Сложные неинтерпретируемые модели (black-box models) можно анализировать, визуализируя 
зависимость их прогнозов от изменения отдельных входных признаков
. Тем самым можно выделить признаки, оказывающие наибольшее влияние на модель, а также оценить характер этого влияния и проверить, насколько это влияние согласуется с априорными знаниями.


График частичной зависимости
​


Определение
​


График частичной зависимости
 (partial dependence plot, PDP 
[1]
) показывает влияние выбранного признака 
$u$
u
 (например, первого) на прогноз модели 
$f\left(\mathbf{x}\right)=f\left([u,\mathbf{v}]\right)$
f
(
x
)
=
f
(
[
u
,
v
]
)
, где вектором 
$\mathbf{v}$
v
 обозначены все признаки, кроме выбранного (например, второй, третий и т.д.). Определим ожидаемое значение прогноза 
$g\left(u\right)$
g
(
u
)
, зафиксировав интересующий признак и усредняя по всем оставшимся:


$g_{u}\left(u\right)=\mathbb{E}_{\mathbf{v}}\left\{ f\left([u,\mathbf{v}]\right)\right\} =\int f\left([u,\mathbf{v}]\right)d\mathbb{P}\left(\mathbf{v}\right)$
g
u
​
(
u
)
=
E
v
​
{
f
(
[
u
,
v
]
)
}
=
∫
f
(
[
u
,
v
]
)
d
P
(
v
)


На практике распределение признаков неизвестно, поэтому используется численная оценка среднего по объектам выборки при фиксированном признаке 
$u$
u
:


$\widehat{g}_{u}\left(u\right)=\frac{1}{N}\sum_{n=1}^{N}f\left([u,\mathbf{v}_{n}]\right)$
g
​
u
​
(
u
)
=
N
1
​
n
=
1
∑
N
​
f
(
[
u
,
v
n
​
]
)




$[u,\mathbf{v}_{n}]$
[
u
,
v
n
​
]
 представляет собой объект 
$\mathbf{x}_{n}$
x
n
​
, у которого интересующий признак положен равным 
$u$
u
.




Примеры
​


Рассмотрим задачу BikeSharing 
[2]
, в которой прогнозируется число арендованных велосипедов по характеристикам дня (дата, температура, влажность и т.д.). График частичной зависимости для этой задачи показан на рисунке ниже для вещественных признаков слева, а для категориального признака (season) справа 
[3]
:


[IMAGE]


По графикам видно, что велосипедов арендуется меньше при низкой и высокой температуре. Снижает число аренд высокая влажность и скорость ветра. Это согласуется с общей логикой и свидетельствует в пользу того, что модель построена верно. Хотя зависимость от сезона оказалась не настолько ярко выражена.


Зависимость от двух признаков
​


Можно строить PDP-график зависимости 
сразу для пары признаков
. В этом случае он будет представлять собой тепловую карту (heatmap) изменений целевого значения от двух признаков, на которой будет видно их совместное воздействие на прогноз, как показано ниже на графике справа 
[4]
:


[IMAGE]


Зависимость такого рода позволит выявить более сложные виды 
совместного воздействия двух признаков
 на прогнозы модели.


Преимущества и недостатки метода
​


График частичной зависимости PDP интуитивен и его легко реализовать. Также эту зависимость можно строить не для одного, а сразу для двух признаков.


PDP - это метод глобальной интерпретации модели (без привязки к определённому объекту), показывающий общую зависимость прогнозов модели от признака. С другой стороны, вычисление PDP вычислительно трудоёмко - приходится проводить усреднение 
по всем объектам выборки
 для каждого значения признака (для больших выборок лучше считать приближённо по подвыборке). Также из-за усреднения по всем объектам мы можем потерять часть зависимостей.




Например, если для половины объектов признак положительно влияет на прогноз, а для другой половины - отрицательно, то при усреднении получим отсутствие связи!




В PDP предполагается, что интересующий признак 
$u$
u
 и остальные признаки 
$\mathbf{v}$
v
 
независимы
, поскольку при построении графика значение интересующего признака фиксируется, а остальные признаки берутся из выборки независимо. Если в действительности признаки сильно зависимы, это будет приводить к появлению малореалистичных объектов.




Например, при анализе данных пациентов больницы можно строить PDP для признака "рост". При этом скоррелированный признак "вес" будет браться независимо от роста, что будет приводить к появлению нереалистичных пациентов с детским ростом и взрослым весом.




График индивидуальных условных ожиданий
​


График индивидуальных условных ожиданий
 (Individual Conditional Expectation, ICE 
[5]
) показывает зависимость отклика от интересующего признака, не усредняя по остальным объектам, а для каждого объекта в отдельности. Разобьём, как и раньше, вектор признаков 
$\mathbf{x}$
x
 на интересующий признак 
$u$
u
 и все остальные признаки 
$\mathbf{v}$
v
. ICE график представляет 
собой совокупность графиков
 зависимостей прогноза от признака 
для каждого объекта валидационной выборки
 
$n=1,2,...N$
n
=
1
,
2
,
...
N
:


$\left\{ g_{un}\left(u\right)=f\left(u,v_{n}\right)\right\} _{n}$
{
g
u
n
​
(
u
)
=
f
(
u
,
v
n
​
)
}
n
​


и показан для задачи BikeSharing на рисунке ниже 
[6]
:


[IMAGE]


График ICE даёт более детальную картину: он показывает влияние интересующего признака на прогноз 
по каждому объекту в отдельности
, что позволяет увидеть, например, ситуацию, когда для половины объектов признак имеет положительное влияние, а для половины - отрицательное.


Недостатком подхода является перегруженная графиками иллюстрация, на которой сложно выделить основные тенденции, поэтому часто строят графики сдвинутых индивидуальных условных ожиданий (Centered ICE plot, c-ICE) по объектам, центрируя, чтобы все графики выходили из одной точки:


$\left\{ g_{un}\left(u\right)=f\left(u,\mathbf{v}_{n}\right)-f\left(u_{0},\mathbf{v}_{n}\right)\right\} _{n},\quad u_{0}-\text{референсное значение (гиперпараметр),}$
{
g
u
n
​
(
u
)
=
f
(
u
,
v
n
​
)
−
f
(
u
0
​
,
v
n
​
)
}
n
​
,
u
0
​
−
референсное
 
значение
 (
гиперпараметр
),


после чего отдельным цветом можно отобразить усреднённую по объектам зависимость для простоты визуализации, как показано ниже 
[6]
:


[IMAGE]




Усреднённая зависимость на графике (жёлтая), с точностью до сдвига, будет PDP-графиком.




Стоит отметить, что как графики ICE и c-ICE, точно так же, как PDP, опираются на предположение о 
независимости
 признака 
$u$
u
 от всех остальных, поскольку используют  сгенерированные объекты, где признаки меняются независимо от друга. Это может приводить использованию в вычислениях малореалистичных объектов.


Условный график
​


Условный график
 (marginal plot, M-plot 
[7]
) лишён недостатка PDP и ICE графиков, состоящего в усреднении по несуществующим малореальным объектам за счёт того, что там при каждом значении признака 
$u$
u
 происходит усреднение не по безусловному распределению оставшихся признаков 
$P\left(v\right)$
P
(
v
)
, а 
по условному
 
$P\left(v|\mathbf{u}\right)$
P
(
v
∣
u
)
.


Приведём иллюстрацию, на которой слева показано безусловное распределение 
$P\left(x^2\right)$
P
(
x
2
)
, а справа - условное распределение 
$P\left(x^2|x^1\right)$
P
(
x
2
∣
x
1
)
 
[7]
:


[IMAGE]


Формулой условный график запишется следующим образом:


$g_{u}\left(u\right)=\frac{1}{\left|N\left(k\right)\right|}\sum_{n:\mathbf{x}_{n}\in N\left(k\right)}f\left(u_{k},\mathbf{v}_{n}\right),$
g
u
​
(
u
)
=
∣
N
(
k
)
∣
1
​
n
:
x
n
​
∈
N
(
k
)
∑
​
f
(
u
k
​
,
v
n
​
)
,


где анализируемый признак 
$u$
u
 разбивается на полуинтервалы 
$\left(u_{k-1},u_{k}\right], k=1,2,...K$
(
u
k
−
1
​
,
u
k
​
]
,
k
=
1
,
2
,
...
K
, а 
$N\left(k\right)$
N
(
k
)
 - множество объектов, для которых значение признака 
$u$
u
 попало в 
$k$
k
-й интервал,  
$\left|N\left(k\right)\right|$
∣
N
(
k
)
∣
 обозначает мощность (число элементов) этого множества.


На условном графике, в отличие от графиков PDP и ICE, усреднение производится только по реалистичным объектам, однако при анализе признака, сильно связанного с другим признаком, график покажет 
совокупное влияние обоих скореллированных признаков, а не чистый эффект одного из них
.




В примере с пациентами больницы это будет совокупное влияние и роста, и веса пациента, а не только роста (или только веса) в чистом виде.






График аккумулированных локальных эффектов
​


График аккумулированных локальных эффектов
 (Accumulated Local Effects, ALE 
[8]
) повторяет методологию условного M-графика, но лишён недостатка, состоящего в том, что если два признака сильно скоррелированы, то будет показан совокупный эффект этих признаков, а не чистый эффект одного из них. ALE-график покажет именно 
чистый эффект интересующего признака
. При этом усреднение будет производиться только по реалистичным объектам.


Формула для расчёта графика аккумулированных локальных эффектов следующая:


$g_{u}\left(u\right)=\sum_{k=1}^{K}\frac{1}{\left|N\left(k\right)\right|}\sum_{n:~\mathbf{x}_{n}\in N\left(k\right)}\left[f\left(u_{k}, \mathbf{v}_{n}\right)-f\left(u_{k-1},\mathbf{v}_{n}\right)\right],$
g
u
​
(
u
)
=
k
=
1
∑
K
​
∣
N
(
k
)
∣
1
​
n
:
 
x
n
​
∈
N
(
k
)
∑
​
[
f
(
u
k
​
,
v
n
​
)
−
f
(
u
k
−
1
​
,
v
n
​
)
]
,


где обозначения такие же, как для условного графика M-plot.


Динамика зависимости от значения признака складывается из малых локальных изменений в областях полуинтервала значений признака 
$u\in\left(u_{k-1},u_{k}\right]$
u
∈
(
u
k
−
1
​
,
u
k
​
]
. Формула показывает изменения прогноза 
только за счёт интересующего признака
 
$u$
u
, когда прочие признаки не влияют, поскольку по ним происходит локальное усреднение вокруг значений признака, который мы анализируем.


Итоговый ALE-график - это аккумулированная сумма таких малых изменений по аналогии того как разность значений функции в двух точках - это интеграл от её производной между этими точками. Пример ALE-графика для задачи BikeSharing показан ниже 
[7]
:


[IMAGE]


Зависимость от двух признаков
Как и для PDP-графика, ALE-график можно строить сразу для пары признаков. В этом случае он будет представлять собой тепловую карту (heatmap) изменений целевого значения от двух признаков, на которой будет видно их 
совместное воздействие
 на прогноз.




Детальнее о PDP-графике можно прочитать в 
[3]
, о ICE-графике - в 
[4]
, а об условном и ALE-графике - в 
[7]
.


С кодом, реализующим построение PDP- и ICE-графиков с использованием библиотеки sklearn, можно ознакомиться в 
[4]
. Построение PDP- и ALE-графиков реализовано в библиотеках PiML 
[9]
 и effector 
[10]
.


Литература
​




Hastie T., Tibshirani R., Friedman J. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. – Springer Science & Business Media, 2009.


UC Irvine Machine Learning Repository: Bike Sharing dataset.


Molnar C. Interpretable machine learning. – Lulu. com, 2020: Partial Dependence Plot (PDP).


Документация sklearn: Partial Dependence and Individual Conditional Expectation plots.


Goldstein A. et al. Peeking inside the black box: Visualizing statistical learning with plots of individual conditional expectation //journal of Computational and Graphical Statistics. – 2015. – Т. 24. – №. 1. – С. 44-65.


Molnar C. Interpretable machine learning. – Lulu. com, 2020: Individual Conditional Expectation (ICE).


Molnar C. Interpretable machine learning. – Lulu. com, 2020: Accumulated Local Effects (ALE).


Apley D. W., Zhu J. Visualizing the effects of predictor variables in black box supervised learning models //Journal of the Royal Statistical Society Series B: Statistical Methodology. – 2020. – Т. 82. – №. 4. – С. 1059-1086.


Документация PiML.


Документация effector.


Предыдущая страница
Влияние фрагментов
Следующая страница
Контрфактические объяснения
График частичной зависимости
Определение
Примеры
Зависимость от двух признаков
Преимущества и недостатки метода
График индивидуальных условных ожиданий
Условный график
График аккумулированных локальных эффектов
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.

