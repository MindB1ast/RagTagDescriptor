





Градиентный бустинг | Машинное и глубокое обучение






[IMAGE]














Перейти к основному содержимому
[IMAGE]
Машинное обучение
Глубокое обучение
Обозначения
Лицензия
Машинное обучение
Введение
Основы машинного обучения
Подготовка данных
Классификаторы в общем виде
Метрические методы прогнозирования
Линейная регрессия и её обобщения
Оценка качества регрессии
Линейная классификация
Многоклассовая классификация набором бинарных классификаторов
Численная оптимизация
Оценка качества классификации
Решающие деревья
Переобучение и недообучение
Ансамбли моделей
Бустинг
Бустинг
Сравнение бустинга с другими ансамблями моделей
Алгоритм AdaBoost
Градиентный бустинг
Алгоритм градиентного бустинга
Улучшения градиентного бустинга
Иллюстрация работы
Градиентный бустинг второго порядка
Популярные реализации
Точность градиентного бустинга
Дополнительная литература
Вопросы
Интерпретация простых моделей
Интерпретация сложных моделей
Заключение
Бустинг
Градиентный бустинг
Содержание этой страницы
Градиентный бустинг


Градиентный бустинг
 (gradient boosting 
[1]
, предложен в 
[2]
) представляет собой приближение бустинга с использованием 
градиента функции потерь
. В отличие от 
AdaBoost
, он работает с произвольной дифференцируемой функцией потерь, а не только с экспоненциальной. В частности это позволяет решать не только задачу классификации, но и регрессии.


В качестве базовых моделей чаще всего используются 
решающие деревья
 небольшой глубины (gradient boosting over decision trees, GBDT).


Когда говорят о бустинге, то чаще всего имеют ввиду именно градиентный бустинг.


Идея метода
​


Если отвлечься от множителя при базовой функции, то в бустинге решается задача подбора оптимальной 
$f_{m+1}(\mathbf{x})$
f
m
+
1
​
(
x
)
 такой, что


$\mathcal{L}(f_{m})=\frac{1}{N}\sum_{n=1}^{N}\mathcal{L}\left(G_{m}(\mathbf{x}_{n})+f_{m}(\mathbf{x}_{n}),y_{n}\right)\to\min_{f_{m}}$
L
(
f
m
​
)
=
N
1
​
n
=
1
∑
N
​
L
(
G
m
​
(
x
n
​
)
+
f
m
​
(
x
n
​
)
,
y
n
​
)
→
f
m
​
min
​


Если вектор прогнозов функции 
$\left[f_{m}(\mathbf{x}_{1}),f_{m}(\mathbf{x}_{2}),...f_{m}(\mathbf{x}_{N})\right]$
[
f
m
​
(
x
1
​
)
,
f
m
​
(
x
2
​
)
,
...
f
m
​
(
x
N
​
)
]
 заменить на вектор вещественных чисел 
$\mathbf{u}=[u_{1},u_{2},...u_{N}]$
u
=
[
u
1
​
,
u
2
​
,
...
u
N
​
]
, то задача переформулируется в виде классической минимизации функции по аргументам:


$\mathcal{L}(\mathbf{u})=\mathcal{L}(u_{1},...u_{N})=\frac{1}{N}\sum_{n=1}^{N}\mathcal{L}\left(G_{m}(\mathbf{x}_{n})+u_{n},y_{n}\right)\to\min_{u_{1},u_{2},...u_{N}}$
L
(
u
)
=
L
(
u
1
​
,
...
u
N
​
)
=
N
1
​
n
=
1
∑
N
​
L
(
G
m
​
(
x
n
​
)
+
u
n
​
,
y
n
​
)
→
u
1
​
,
u
2
​
,
...
u
N
​
min
​


Используя идеологию 
градиентного спуска
, эту задачу в линейном приближении можно решить, положив


$\begin{aligned}
u_{1} &= -\frac{\partial\mathcal{L}(G_{m}(\mathbf{x}_{1}),y_{1})}{\partial G} \\
u_{2} &= -\frac{\partial\mathcal{L}(G_{m}(\mathbf{x}_{2}),y_{2})}{\partial G} \\
& \cdots \\
u_{N} &= -\frac{\partial\mathcal{L}(G_{m}(\mathbf{x}_{N}),y_{N})}{\partial G} \\
\end{aligned}$
u
1
​
u
2
​
u
N
​
​
=
−
∂
G
∂
L
(
G
m
​
(
x
1
​
)
,
y
1
​
)
​
=
−
∂
G
∂
L
(
G
m
​
(
x
2
​
)
,
y
2
​
)
​
⋯
=
−
∂
G
∂
L
(
G
m
​
(
x
N
​
)
,
y
N
​
)
​
​


Следовательно, в исходной постановке следует выбирать 
$f_{m}(\mathbf{x})$
f
m
​
(
x
)
 так, чтобы обеспечить


$\begin{aligned}
f_{m}(\mathbf{x}_{1}) &\approx -\frac{\partial\mathcal{L}(G_{m}(\mathbf{x}_{1}),y_{1})}{\partial G}\\
f_{m}(\mathbf{x}_{2}) &\approx -\frac{\partial\mathcal{L}(G_{m}(\mathbf{x}_{2}),y_{2})}{\partial G}\\
&\cdots \\ 
f_{m}(\mathbf{x}_{N}) &\approx -\frac{\partial\mathcal{L}(G_{m}(\mathbf{x}_{N}),y_{N})}{\partial G}
\end{aligned}$
f
m
​
(
x
1
​
)
f
m
​
(
x
2
​
)
f
m
​
(
x
N
​
)
​
≈
−
∂
G
∂
L
(
G
m
​
(
x
1
​
)
,
y
1
​
)
​
≈
−
∂
G
∂
L
(
G
m
​
(
x
2
​
)
,
y
2
​
)
​
⋯
≈
−
∂
G
∂
L
(
G
m
​
(
x
N
​
)
,
y
N
​
)
​
​


Реализация
На практике это означает обучение 
$f_m(\mathbf{x})$
f
m
​
(
x
)
 на обучающей выборке:
$\left\{ 
\left(\mathbf{x}_1,-\frac{\partial\mathcal{L}(G_{m}(\mathbf{x}_{1}),y_{1})}{\partial G}\right),
\left(\mathbf{x}_2,-\frac{\partial\mathcal{L}(G_{m}(\mathbf{x}_{2}),y_{2})}{\partial G}\right),
...
\left(\mathbf{x}_N,-\frac{\partial\mathcal{L}(G_{m}(\mathbf{x}_{N}),y_{N})}{\partial G}\right)
\right\}$
{
(
x
1
​
,
−
∂
G
∂
L
(
G
m
​
(
x
1
​
)
,
y
1
​
)
​
)
,
(
x
2
​
,
−
∂
G
∂
L
(
G
m
​
(
x
2
​
)
,
y
2
​
)
​
)
,
...
(
x
N
​
,
−
∂
G
∂
L
(
G
m
​
(
x
N
​
)
,
y
N
​
)
​
)
}


Алгоритм градиентного бустинга основан на итеративной оценке 
$f_m(\mathbf{x})$
f
m
​
(
x
)
 для 
$m=1,2,...M$
m
=
1
,
2
,
...
M
 и добавлении этих функций к ансамблю 
$G_m(\mathbf{x})$
G
m
​
(
x
)
.




Заметим, что в обучающей выборке для каждой базовой модели 
$f_m$
f
m
​
 вектора признаков будут одинаковыми, а целевые значения - разными, поскольку разными будут ошибки  
$G_m(\mathbf{x})$
G
m
​
(
x
)
, уточняемой на каждой итерации.




Настройка 
$f_m(\mathbf{x})$
f
m
​
(
x
)
 происходит по правилу:


$\sum_{n=1}^{N}\left(f_{m}(\mathbf{x}_{n})+\frac{\partial\mathcal{L}(G_{m-1}(\mathbf{x}_{n}),y_{n})}{\partial G}\right)^{2}\to\min_{f_{m}}$
n
=
1
∑
N
​
(
f
m
​
(
x
n
​
)
+
∂
G
∂
L
(
G
m
−
1
​
(
x
n
​
)
,
y
n
​
)
​
)
2
→
f
m
​
min
​




Заставить 
$f_m(\mathbf{x})$
f
m
​
(
x
)
 приближать антиградиент ансамбля можно, используя 
любую
 регрессионную функцию потерь. Квадратичные потери выше - просто наиболее типичный случай.




Тогда шагу градиентного спуска при минимизации 
$\mathcal{L}(\mathbf{u})$
L
(
u
)


$\mathbf{u}:=\mathbf{u}-\varepsilon\nabla\mathcal{L}(\mathbf{u})$
u
:=
u
−
ε
∇
L
(
u
)


будет приближённо соответствовать обновление ансамбля:


$G_{m}(\mathbf{x}):=G_{m-1}(\mathbf{x})+\varepsilon f_{m}(\mathbf{x}),$
G
m
​
(
x
)
:=
G
m
−
1
​
(
x
)
+
ε
f
m
​
(
x
)
,


где шаг обучения (learning rate) 
$\varepsilon>0$
ε
>
0
 выбирается пользователем (гиперпараметр).


Случай функции выигрыша
Если настройка ансамбля производится не 
минимизацией
 функции потерь, а  
максимизацией
 функции выигрыша, то 
$f_m(\mathbf{x})$
f
m
​
(
x
)
 нужно настраивать приближать не антиградиент потерь (градиент 
со знаком минус
), а градиент функции (
со знаком плюс
).


Примеры
​


Случай регресии
​


Рассмотрим задачу регрессии 
$y\in\mathbb{R}$
y
∈
R
 с функцией потерь:


$\mathcal{L}(G,y)=\frac{1}{2}\left(G-y\right)^{2}$
L
(
G
,
y
)
=
2
1
​
(
G
−
y
)
2


Тогда следующая базовая модель будет настраиваться приближать


$f(\mathbf{x})\approx-\frac{\partial\mathcal{L}(G,y)}{\partial G}=-(G-y)=(y-G)$
f
(
x
)
≈
−
∂
G
∂
L
(
G
,
y
)
​
=
−
(
G
−
y
)
=
(
y
−
G
)


Обновление базовой модели пройдёт по правилу


$\begin{aligned}
G_{m}(\mathbf{x}_{n})&:=G_{m-1}(\mathbf{x}_{n})+\varepsilon f(\mathbf{x}) \\
& \approx G_{m-1}(\mathbf{x}_{n})+\varepsilon (y_{n}-G_{m-1}(\mathbf{x}_{n}))
\end{aligned}$
G
m
​
(
x
n
​
)
​
:=
G
m
−
1
​
(
x
n
​
)
+
ε
f
(
x
)
≈
G
m
−
1
​
(
x
n
​
)
+
ε
(
y
n
​
−
G
m
−
1
​
(
x
n
​
))
​


То есть в каждой точке 
$\mathbf{x}_n$
x
n
​
 ансамбль будет корректироваться на величину недопрогноза 
$y_{n}-G_{m-1}(\mathbf{x}_{n})$
y
n
​
−
G
m
−
1
​
(
x
n
​
)
.


[IMAGE]


Случай бинарной классификации
​


Для бинарной классификации 
$y\in\{+1,-1\}$
y
∈
{
+
1
,
−
1
}
 зададим функцию потерь персептрона:


$\mathcal{L}(G,y) = \max\{-Gy,0\}$
L
(
G
,
y
)
=
max
{
−
G
y
,
0
}


Тогда следующая базовая модель будет настраиваться приближать


$f_{m}(\mathbf{x})\approx-\frac{\partial\mathcal{L}(G,y)}{\partial G}=\begin{cases}
y, & Gy<0\\
0, & Gy\ge0
\end{cases}$
f
m
​
(
x
)
≈
−
∂
G
∂
L
(
G
,
y
)
​
=
{
y
,
0
,
​
G
y
<
0
G
y
≥
0
​


$\begin{aligned}
G_{m}(\mathbf{x}_{n})&:=G_{m-1}(\mathbf{x}_{n})+\varepsilon f_{m}(\mathbf{x}) \\
& \approx G_{m-1}(\mathbf{x}_{n})+\begin{cases}
\varepsilon y_{n}, & G(\mathbf{x}_{n})y_{n} \le 0\\
0, & G(\mathbf{x}_{n})y_{n}>0
\end{cases}
\end{aligned}$
G
m
​
(
x
n
​
)
​
:=
G
m
−
1
​
(
x
n
​
)
+
ε
f
m
​
(
x
)
≈
G
m
−
1
​
(
x
n
​
)
+
{
ε
y
n
​
,
0
,
​
G
(
x
n
​
)
y
n
​
≤
0
G
(
x
n
​
)
y
n
​
>
0
​
​


В результате такого обновления ансамбль не изменяется для объектов, которые уже классифицируются корректно (
$G(\mathbf{x}_{n})$
G
(
x
n
​
)
 и 
$y_{n}$
y
n
​
 одного знака), и изменится на 
$\varepsilon$
ε
 в сторону 
$y_n$
y
n
​
 на неверно классифицированных объектах.


Это улучшает качество классификации неверно предсказанных объектов (повышает отступ), поскольку конечные прогнозы ансамбль выдаёт по правилу:


$\hat{y}(\mathbf{x})=
\begin{cases} 
+1, G_m(\mathbf{x})>0, \\
-1, G_m(\mathbf{x})<0.
\end{cases}$
y
^
​
(
x
)
=
{
+
1
,
G
m
​
(
x
)
>
0
,
−
1
,
G
m
​
(
x
)
<
0.
​


Это изменение проиллюстрировано ниже:


[IMAGE]


Как видим, при использовании функции потерь персептрона корректировка на 
$\varepsilon$
ε
 осуществляется только для ошибочно классифицированных объектов, у которых 
$y(\mathbf{x})$
y
(
x
)
 и 
$G_{m-1}(\mathbf{x})$
G
m
−
1
​
(
x
)
 разных знаков.


Случай многоклассовой классификации
​


Для многоклассовой классификации можно использовать методы 
один-против-одного
, 
один-против-всех
 и 
коды, исправляющие ошибки,
 которые решают многоклассовую классификацию с помощью набора бинарных классификаторов.


Альтернативно можно решать многоклассовую классификацию напрямую. В этом случае 
$G_{m-1}(\mathbf{x})\in\mathbb{R}^{C}$
G
m
−
1
​
(
x
)
∈
R
C
 будет представлять собой уже 
вектор из рейтингов
 для каждого из 
$C$
C
 классов, а в качестве прогноза будет назначаться класс, обладающий максимальным рейтингом:


$\hat{y} = \arg\max_{c\in\{1,2,...C\}} G_{m-1,c}(\mathbf{x})$
y
^
​
=
ar
g
c
∈
{
1
,
2
,
...
C
}
max
​
G
m
−
1
,
c
​
(
x
)


В случае минимизации потерь 
$\mathcal{L}(\cdot)$
L
(
⋅
)
:


$f_{m}(\mathbf{x}_{n})\approx-\frac{\partial\mathcal{L}(G_{m-1}(\mathbf{x}_{n}),y_{n})}{\partial G}\in\mathbb{R}^{C},$
f
m
​
(
x
n
​
)
≈
−
∂
G
∂
L
(
G
m
−
1
​
(
x
n
​
)
,
y
n
​
)
​
∈
R
C
,


то есть базовая базовая модель и целевая величина будут представлять собой 
$C$
C
-мерные векторы, сближаемые через 
векторную
 функцию потерь.




Далее мы рассмотрим 
алгоритм бустинга в общем виде
.


С частным случаем многоклассового бустинга при логистической функции потерь можно ознакомиться, например, в 
[3]
.


Литература
​






Wikipedia: gradient boosting.






Friedman J. H. Greedy function approximation: a gradient boosting machine //Annals of statistics. – 2001. – С. 1189-1232.






Мерков А. Б. Распознавание образов: введение в методы статистического обучения. // Москва: Едиториал УРСС. – 2019.




Предыдущая страница
Алгоритм AdaBoost
Следующая страница
Алгоритм градиентного бустинга
Идея метода
Примеры
Случай регресии
Случай бинарной классификации
Случай многоклассовой классификации
Литература
© 2023-25 
Виктор Китов.
 
Новости проекта.

